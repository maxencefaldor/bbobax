{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"BBOBax","text":"<p>BBOBax: Accelerated Black-Box Optimization Benchmark in JAX.</p> <p> </p> <p>A high-performance reimplementation of the COCO (COmparing Continuous Optimizers) test suite in JAX. BBOBax allows for massive parallelization of function evaluations on hardware accelerators (GPUs/TPUs), enabling efficient benchmarking of black-box optimization algorithms.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>JAX-based: Fully differentiable (where applicable) and JIT-compilable.</li> <li>Hardware Acceleration: Run benchmarks on GPUs and TPUs for massive speedups.</li> <li>Standard BBOB: Includes standard single-objective BBOB functions (noiseless).</li> <li>Noise Support: Configurable noise models (Gaussian, Uniform, Cauchy, etc.) for robust optimization benchmarking.</li> <li>Quality-Diversity (QD): Support for Quality-Diversity benchmarks with customizable descriptor functions.</li> <li>Flexible API: Easy integration with existing JAX-based evolutionary computation libraries (e.g., EvoJAX, evosax).</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>We recommend using uv for a fast and reliable installation, but standard <code>pip</code> is also supported.</p>"},{"location":"#using-uv-recommended","title":"Using uv (Recommended)","text":"<pre><code># Clone the repository\ngit clone https://github.com/maxencefaldor/bbobax.git\ncd bbobax\n\n# Create a virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Install dependencies and the package in editable mode\nuv pip install -e .\n</code></pre>"},{"location":"#using-pip","title":"Using pip","text":"<pre><code>pip install bbobax\n# Or install from source\npip install -e .\n</code></pre> <p>Note on JAX: You may need to install the specific version of JAX compatible with your CUDA/cuDNN version. Please refer to the JAX installation guide for details.</p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#basic-bbob-example","title":"Basic BBOB Example","text":"<p>Here is a minimal example of how to initialize a BBOB task, sample a problem instance, and evaluate a solution.</p> <pre><code>import jax\nfrom bbobax import BBOB\n\n# Initialize BBOB task with default functions\nbbob = BBOB.create_default(min_num_dims=2, max_num_dims=10)\n\n# Sample a task instance (function ID, dimensions, optimal values, etc.)\nkey = jax.random.key(0)\nkey_task, key_init, key_eval, key_x = jax.random.split(key, 4)\ntask_params = bbob.sample(key_task)\n\n# Initialize internal state (e.g., rotation matrices)\nstate = bbob.init(key_init, task_params)\n\n# Sample a random solution in the search space\nx = bbob.sample_x(key_x)\n\n# Evaluate the solution\n# Returns updated state and evaluation metrics (fitness)\nstate, eval_metrics = bbob.evaluate(key_eval, x, state, task_params)\n\nprint(f\"Function ID: {task_params.fn_id}\")\nprint(f\"Dimensions: {task_params.num_dims}\")\nprint(f\"Fitness: {eval_metrics.fitness}\")\n</code></pre>"},{"location":"#quality-diversity-qd-example","title":"Quality-Diversity (QD) Example","text":"<p>BBOBax also supports Quality-Diversity optimization tasks where solutions are evaluated based on both fitness and a behavior descriptor.</p> <pre><code>import jax\nfrom bbobax import QDBBOB, bbob_fns, get_random_projection_descriptor\n\n# Define descriptor functions (e.g., random projection)\ndescriptor_fns = [get_random_projection_descriptor]\n\n# Initialize QD-BBOB task\nqd_bbob = QDBBOB(\n    descriptor_fns=descriptor_fns,\n    fitness_fns=bbob_fns,\n    descriptor_size=2,\n    min_num_dims=10, \n    max_num_dims=10\n)\n\n# Sample task\nkey = jax.random.key(42)\nkey_task, key_init, key_eval, key_x = jax.random.split(key, 4)\ntask_params = qd_bbob.sample(key_task)\n\n# Initialize state\nstate = qd_bbob.init(key_init, task_params)\n\n# Sample solution\nx = qd_bbob.sample_x(key_x)\n\n# Evaluate\nstate, eval_metrics = qd_bbob.evaluate(key_eval, x, state, task_params)\n\nprint(f\"Fitness: {eval_metrics.fitness}\")\nprint(f\"Descriptor: {eval_metrics.descriptor}\")\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Full documentation is available at https://maxencefaldor.github.io/bbobax/.</p> <p>To build the documentation locally:</p> <pre><code># Install documentation dependencies\nuv pip install -e \".[docs]\"\n\n# Serve the documentation\nmkdocs serve\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>If you use BBOBax in your research, please cite it using the following metadata:</p> <pre><code>title: \"BBOBax\"\nabstract: \"BBOBax: Accelerated Black-Box Optimization Benchmark in JAX.\"\nauthors:\n  - family-names: \"Faldor\"\n    given-names: \"Maxence\"\n    orcid: \"https://orcid.org/0000-0003-4743-9494\"\nrepository-code: \"https://github.com/maxencefaldor/bbobax\"\ntype: software\n</code></pre>"},{"location":"#references","title":"References","text":"<p>This library is built upon the standard BBOB function definitions. Please verify the details in the provided documentation:</p> <ul> <li>Noiseless Functions: Hansen, N., Finck, S., Ros, R., &amp; Auger, A. (2009). Real-parameter black-box optimization benchmarking 2009: Noiseless functions definitions. PDF</li> <li>Noisy Functions: Hansen, N., Finck, S., Ros, R., &amp; Auger, A. (2009). Real-parameter black-box optimization benchmarking 2009: Noisy functions definitions. PDF</li> </ul>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2025 Maxence Faldor</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"notebooks/00_getting_started/","title":"Getting Started","text":"<p>In this notebook, we will cover how to:</p> <ul> <li>Instantiate a BBO function.</li> <li>Sample BBO parameters.</li> <li>Initialize BBO state.</li> <li>Sample a solution from the search space</li> <li>Evaluate a solution to get its fitness</li> <li>Plot the BBO function.</li> </ul> <p>You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"jax[cuda]\"\n</pre> %pip install -U \"jax[cuda]\" <p>Then, install bbobax from PyPi:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"bbobax[notebooks]\"\n</pre> %pip install -U \"bbobax[notebooks]\" In\u00a0[1]: Copied! <pre>import jax\nimport jax.numpy as jnp\n\nfrom bbobax import BBOB\n</pre> import jax import jax.numpy as jnp  from bbobax import BBOB In\u00a0[2]: Copied! <pre>seed = 0\n\nkey = jax.random.key(seed)\n</pre> seed = 0  key = jax.random.key(seed) In\u00a0[3]: Copied! <pre>from bbobax.fitness_fns import sphere\n\nbbob = BBOB(\n    fitness_fns=[sphere],\n    min_num_dims=2,\n    max_num_dims=2,\n    x_range=[-5, 5],\n    x_opt_range=[0, 0],\n    f_opt_range=[0, 0],\n    clip_x=False,\n    sample_rotation=False,\n    noise_config={\"noise_model_names\": [\"noiseless\"]},\n)\n</pre> from bbobax.fitness_fns import sphere  bbob = BBOB(     fitness_fns=[sphere],     min_num_dims=2,     max_num_dims=2,     x_range=[-5, 5],     x_opt_range=[0, 0],     f_opt_range=[0, 0],     clip_x=False,     sample_rotation=False,     noise_config={\"noise_model_names\": [\"noiseless\"]}, ) In\u00a0[4]: Copied! <pre>key, subkey = jax.random.split(key)\nparams = bbob.sample(subkey)\nparams\n</pre> key, subkey = jax.random.split(key) params = bbob.sample(subkey) params Out[4]: <pre>BBOBParams(fn_id=Array(0, dtype=int32), num_dims=Array(2, dtype=int32), x_opt=Array([0., 0.], dtype=float32), f_opt=Array(0., dtype=float32), noise_params=NoiseParams(noise_id=Array(0, dtype=int32), gaussian_beta=Array(0.36132753, dtype=float32), uniform_alpha=Array(0.44864777, dtype=float32), uniform_beta=Array(0.22577344, dtype=float32), cauchy_alpha=Array(0.1728976, dtype=float32), cauchy_p=Array(0.18512261, dtype=float32), additive_std=Array(0.04558092, dtype=float32)))</pre> In\u00a0[5]: Copied! <pre>key, subkey = jax.random.split(key)\nstate = bbob.init(subkey, params)\nstate\n</pre> key, subkey = jax.random.split(key) state = bbob.init(subkey, params) state Out[5]: <pre>BBOBState(r=Array([[1., 0.],\n       [0., 1.]], dtype=float32), q=Array([[1., 0.],\n       [0., 1.]], dtype=float32), counter=0)</pre> In\u00a0[6]: Copied! <pre>key, subkey = jax.random.split(key)\nx = bbob.sample_x(subkey)\n</pre> key, subkey = jax.random.split(key) x = bbob.sample_x(subkey) In\u00a0[7]: Copied! <pre>key, subkey = jax.random.split(key)\nstate, eval = bbob.evaluate(subkey, x, state, params)\nprint(f\"Fitness: {eval.fitness}\")\n</pre> key, subkey = jax.random.split(key) state, eval = bbob.evaluate(subkey, x, state, params) print(f\"Fitness: {eval.fitness}\") <pre>Fitness: 25.306095123291016\n</pre> In\u00a0[8]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Create a grid for plotting\nx_range = jnp.linspace(-5, 5, 100)\ny_range = jnp.linspace(-5, 5, 100)\nX, Y = jnp.meshgrid(x_range, y_range)\n\n# Evaluate the function on the grid\ngrid_points = jnp.stack([X.flatten(), Y.flatten()], axis=1)\n\n# Use vmap to vectorize the evaluation\nvmapped_evaluate = jax.vmap(\n    lambda point: bbob.evaluate(subkey, point, state, params)[1].fitness\n)\ngrid_fitness = vmapped_evaluate(grid_points).reshape(X.shape)\n\n# Create the plot\nplt.figure(figsize=(10, 8))\nplt.contourf(X, Y, grid_fitness, levels=50, cmap=\"viridis\")\nplt.colorbar(label=\"Fitness\")\n\n# Plot the optimal point\nplt.plot(params.x_opt[0], params.x_opt[1], \"r*\", markersize=15, label=\"x_opt\")\n\n# Plot the sampled point\nplt.plot(x[0], x[1], \"bo\", markersize=10, label=\"sampled x\")\n\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.title(\"BBOB Function Heatmap\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Create a grid for plotting x_range = jnp.linspace(-5, 5, 100) y_range = jnp.linspace(-5, 5, 100) X, Y = jnp.meshgrid(x_range, y_range)  # Evaluate the function on the grid grid_points = jnp.stack([X.flatten(), Y.flatten()], axis=1)  # Use vmap to vectorize the evaluation vmapped_evaluate = jax.vmap(     lambda point: bbob.evaluate(subkey, point, state, params)[1].fitness ) grid_fitness = vmapped_evaluate(grid_points).reshape(X.shape)  # Create the plot plt.figure(figsize=(10, 8)) plt.contourf(X, Y, grid_fitness, levels=50, cmap=\"viridis\") plt.colorbar(label=\"Fitness\")  # Plot the optimal point plt.plot(params.x_opt[0], params.x_opt[1], \"r*\", markersize=15, label=\"x_opt\")  # Plot the sampled point plt.plot(x[0], x[1], \"bo\", markersize=10, label=\"sampled x\")  plt.xlabel(\"x1\") plt.ylabel(\"x2\") plt.title(\"BBOB Function Heatmap\") plt.legend() plt.grid(True, alpha=0.3) plt.show() In\u00a0[9]: Copied! <pre>from bbobax.fitness_fns import rosenbrock\n\nbbob = BBOB(\n    fitness_fns=[rosenbrock],\n    min_num_dims=2,\n    max_num_dims=2,\n    x_range=[-5, 5],\n    x_opt_range=[0, 0],\n    f_opt_range=[0, 0],\n    clip_x=False,\n    sample_rotation=False,\n    noise_config={\"noise_model_names\": [\"noiseless\"]},\n)\n</pre> from bbobax.fitness_fns import rosenbrock  bbob = BBOB(     fitness_fns=[rosenbrock],     min_num_dims=2,     max_num_dims=2,     x_range=[-5, 5],     x_opt_range=[0, 0],     f_opt_range=[0, 0],     clip_x=False,     sample_rotation=False,     noise_config={\"noise_model_names\": [\"noiseless\"]}, ) In\u00a0[10]: Copied! <pre>key, subkey = jax.random.split(key)\nparams = bbob.sample(subkey)\nparams\n</pre> key, subkey = jax.random.split(key) params = bbob.sample(subkey) params Out[10]: <pre>BBOBParams(fn_id=Array(0, dtype=int32), num_dims=Array(2, dtype=int32), x_opt=Array([0., 0.], dtype=float32), f_opt=Array(0., dtype=float32), noise_params=NoiseParams(noise_id=Array(0, dtype=int32), gaussian_beta=Array(0.70297843, dtype=float32), uniform_alpha=Array(0.23709728, dtype=float32), uniform_beta=Array(0.4198368, dtype=float32), cauchy_alpha=Array(0.8532587, dtype=float32), cauchy_p=Array(0.15531364, dtype=float32), additive_std=Array(0.06283038, dtype=float32)))</pre> In\u00a0[11]: Copied! <pre>key, subkey = jax.random.split(key)\nstate = bbob.init(subkey, params)\nstate\n</pre> key, subkey = jax.random.split(key) state = bbob.init(subkey, params) state Out[11]: <pre>BBOBState(r=Array([[1., 0.],\n       [0., 1.]], dtype=float32), q=Array([[1., 0.],\n       [0., 1.]], dtype=float32), counter=0)</pre> In\u00a0[12]: Copied! <pre>key, subkey = jax.random.split(key)\nx = bbob.sample_x(subkey)\n</pre> key, subkey = jax.random.split(key) x = bbob.sample_x(subkey) In\u00a0[13]: Copied! <pre>key, subkey = jax.random.split(key)\nstate, eval = bbob.evaluate(subkey, x, state, params)\nprint(f\"Fitness: {eval.fitness}\")\n</pre> key, subkey = jax.random.split(key) state, eval = bbob.evaluate(subkey, x, state, params) print(f\"Fitness: {eval.fitness}\") <pre>Fitness: 764.84423828125\n</pre> In\u00a0[14]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Create a grid for plotting\nx_range = jnp.linspace(-5, 5, 100)\ny_range = jnp.linspace(-5, 5, 100)\nX, Y = jnp.meshgrid(x_range, y_range)\n\n# Evaluate the function on the grid\ngrid_points = jnp.stack([X.flatten(), Y.flatten()], axis=1)\n\n# Use vmap to vectorize the evaluation\nvmapped_evaluate = jax.vmap(\n    lambda point: bbob.evaluate(subkey, point, state, params)[1].fitness\n)\ngrid_fitness = vmapped_evaluate(grid_points).reshape(X.shape)\n\n# Apply log transformation for better visualization\n# Add a small constant to avoid log(0) issues\nlog_fitness = jnp.log(grid_fitness + 1e-8)\n\n# Create the plot\nplt.figure(figsize=(10, 8))\nplt.contourf(X, Y, log_fitness, levels=50, cmap=\"viridis\")\nplt.colorbar(label=\"Log Fitness\")\n\n# Plot the optimal point\nplt.plot(params.x_opt[0], params.x_opt[1], \"r*\", markersize=15, label=\"x_opt\")\n\n# Plot the sampled point\nplt.plot(x[0], x[1], \"bo\", markersize=10, label=\"sampled x\")\n\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.title(\"BBOB Function Heatmap (Log Scale)\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Create a grid for plotting x_range = jnp.linspace(-5, 5, 100) y_range = jnp.linspace(-5, 5, 100) X, Y = jnp.meshgrid(x_range, y_range)  # Evaluate the function on the grid grid_points = jnp.stack([X.flatten(), Y.flatten()], axis=1)  # Use vmap to vectorize the evaluation vmapped_evaluate = jax.vmap(     lambda point: bbob.evaluate(subkey, point, state, params)[1].fitness ) grid_fitness = vmapped_evaluate(grid_points).reshape(X.shape)  # Apply log transformation for better visualization # Add a small constant to avoid log(0) issues log_fitness = jnp.log(grid_fitness + 1e-8)  # Create the plot plt.figure(figsize=(10, 8)) plt.contourf(X, Y, log_fitness, levels=50, cmap=\"viridis\") plt.colorbar(label=\"Log Fitness\")  # Plot the optimal point plt.plot(params.x_opt[0], params.x_opt[1], \"r*\", markersize=15, label=\"x_opt\")  # Plot the sampled point plt.plot(x[0], x[1], \"bo\", markersize=10, label=\"sampled x\")  plt.xlabel(\"x1\") plt.ylabel(\"x2\") plt.title(\"BBOB Function Heatmap (Log Scale)\") plt.legend() plt.grid(True, alpha=0.3) plt.show() In\u00a0[15]: Copied! <pre>from bbobax.fitness_fns import rosenbrock_rotated\n\nbbob = BBOB(\n    fitness_fns=[rosenbrock_rotated],\n    min_num_dims=2,\n    max_num_dims=2,\n    x_range=[-5, 5],\n    x_opt_range=[-4, 4],  # x_opt is sampled randomly\n    f_opt_range=[0, 100],  # f_opt is sampled randomly\n    sample_rotation=True,  # sample rotation matrix\n    noise_config={\"noise_model_names\": [\"noiseless\"]},\n)\n</pre> from bbobax.fitness_fns import rosenbrock_rotated  bbob = BBOB(     fitness_fns=[rosenbrock_rotated],     min_num_dims=2,     max_num_dims=2,     x_range=[-5, 5],     x_opt_range=[-4, 4],  # x_opt is sampled randomly     f_opt_range=[0, 100],  # f_opt is sampled randomly     sample_rotation=True,  # sample rotation matrix     noise_config={\"noise_model_names\": [\"noiseless\"]}, ) In\u00a0[16]: Copied! <pre>key, subkey = jax.random.split(key)\nparams = bbob.sample(subkey)\nparams\n</pre> key, subkey = jax.random.split(key) params = bbob.sample(subkey) params Out[16]: <pre>BBOBParams(fn_id=Array(0, dtype=int32), num_dims=Array(2, dtype=int32), x_opt=Array([-3.1669483,  0.2918682], dtype=float32), f_opt=Array(2.1997094, dtype=float32), noise_params=NoiseParams(noise_id=Array(0, dtype=int32), gaussian_beta=Array(0.9812749, dtype=float32), uniform_alpha=Array(0.2676749, dtype=float32), uniform_beta=Array(0.1289506, dtype=float32), cauchy_alpha=Array(0.82406837, dtype=float32), cauchy_p=Array(0.19496787, dtype=float32), additive_std=Array(0.04585386, dtype=float32)))</pre> In\u00a0[17]: Copied! <pre>key, subkey = jax.random.split(key)\nstate = bbob.init(subkey, params)\nstate\n</pre> key, subkey = jax.random.split(key) state = bbob.init(subkey, params) state Out[17]: <pre>BBOBState(r=Array([[-0.93561584,  0.3530194 ],\n       [-0.35301942, -0.935616  ]], dtype=float32), q=Array([[ 0.7502459 , -0.66115886],\n       [ 0.66115886,  0.7502459 ]], dtype=float32), counter=0)</pre> In\u00a0[18]: Copied! <pre>key, subkey = jax.random.split(key)\nx = bbob.sample_x(subkey)\n</pre> key, subkey = jax.random.split(key) x = bbob.sample_x(subkey) In\u00a0[19]: Copied! <pre>key, subkey = jax.random.split(key)\nstate, eval = bbob.evaluate(subkey, x, state, params)\nprint(f\"Fitness: {eval.fitness}\")\n</pre> key, subkey = jax.random.split(key) state, eval = bbob.evaluate(subkey, x, state, params) print(f\"Fitness: {eval.fitness}\") <pre>Fitness: 717.5936279296875\n</pre> In\u00a0[20]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Create a grid for plotting\nx_range = jnp.linspace(-5, 5, 100)\ny_range = jnp.linspace(-5, 5, 100)\nX, Y = jnp.meshgrid(x_range, y_range)\n\n# Evaluate the function on the grid\ngrid_points = jnp.stack([X.flatten(), Y.flatten()], axis=1)\n\n# Use vmap to vectorize the evaluation\nvmapped_evaluate = jax.vmap(\n    lambda point: bbob.evaluate(subkey, point, state, params)[1].fitness\n)\ngrid_fitness = vmapped_evaluate(grid_points).reshape(X.shape)\n\n# Apply log transformation for better visualization\n# Add a small constant to avoid log(0) issues\nlog_fitness = jnp.log(grid_fitness + 1e-8)\n\n# Create the plot\nplt.figure(figsize=(10, 8))\nplt.contourf(X, Y, log_fitness, levels=50, cmap=\"viridis\")\nplt.colorbar(label=\"Log Fitness\")\n\n# Plot the optimal point\nplt.plot(params.x_opt[0], params.x_opt[1], \"r*\", markersize=15, label=\"x_opt\")\n\n# Plot the sampled point\nplt.plot(x[0], x[1], \"bo\", markersize=10, label=\"sampled x\")\n\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.title(\"BBOB Function Heatmap (Log Scale)\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Create a grid for plotting x_range = jnp.linspace(-5, 5, 100) y_range = jnp.linspace(-5, 5, 100) X, Y = jnp.meshgrid(x_range, y_range)  # Evaluate the function on the grid grid_points = jnp.stack([X.flatten(), Y.flatten()], axis=1)  # Use vmap to vectorize the evaluation vmapped_evaluate = jax.vmap(     lambda point: bbob.evaluate(subkey, point, state, params)[1].fitness ) grid_fitness = vmapped_evaluate(grid_points).reshape(X.shape)  # Apply log transformation for better visualization # Add a small constant to avoid log(0) issues log_fitness = jnp.log(grid_fitness + 1e-8)  # Create the plot plt.figure(figsize=(10, 8)) plt.contourf(X, Y, log_fitness, levels=50, cmap=\"viridis\") plt.colorbar(label=\"Log Fitness\")  # Plot the optimal point plt.plot(params.x_opt[0], params.x_opt[1], \"r*\", markersize=15, label=\"x_opt\")  # Plot the sampled point plt.plot(x[0], x[1], \"bo\", markersize=10, label=\"sampled x\")  plt.xlabel(\"x1\") plt.ylabel(\"x2\") plt.title(\"BBOB Function Heatmap (Log Scale)\") plt.legend() plt.grid(True, alpha=0.3) plt.show()"},{"location":"notebooks/00_getting_started/#getting-started","title":"Getting Started \u00b6","text":""},{"location":"notebooks/00_getting_started/#install","title":"Install\u00b6","text":""},{"location":"notebooks/00_getting_started/#import","title":"Import\u00b6","text":""},{"location":"notebooks/00_getting_started/#sphere","title":"Sphere\u00b6","text":""},{"location":"notebooks/00_getting_started/#instantiate-bbob","title":"Instantiate BBOB\u00b6","text":""},{"location":"notebooks/00_getting_started/#sample-bbob-parameters","title":"Sample BBOB parameters\u00b6","text":""},{"location":"notebooks/00_getting_started/#initialize-bbob-state","title":"Initialize BBOB state\u00b6","text":""},{"location":"notebooks/00_getting_started/#sample-solution","title":"Sample solution\u00b6","text":""},{"location":"notebooks/00_getting_started/#evaluate","title":"Evaluate\u00b6","text":""},{"location":"notebooks/00_getting_started/#plot","title":"Plot\u00b6","text":""},{"location":"notebooks/00_getting_started/#rosenbrock","title":"Rosenbrock\u00b6","text":""},{"location":"notebooks/00_getting_started/#instantiate-bbob","title":"Instantiate BBOB\u00b6","text":""},{"location":"notebooks/00_getting_started/#sample-bbob-parameters","title":"Sample BBOB parameters\u00b6","text":""},{"location":"notebooks/00_getting_started/#initialize-bbob-state","title":"Initialize BBOB state\u00b6","text":""},{"location":"notebooks/00_getting_started/#sample-solution","title":"Sample solution\u00b6","text":""},{"location":"notebooks/00_getting_started/#evaluate","title":"Evaluate\u00b6","text":""},{"location":"notebooks/00_getting_started/#plot","title":"Plot\u00b6","text":""},{"location":"notebooks/00_getting_started/#rosenbrock-with-randomness","title":"Rosenbrock with randomness\u00b6","text":""},{"location":"notebooks/00_getting_started/#instantiate-bbob","title":"Instantiate BBOB\u00b6","text":""},{"location":"notebooks/00_getting_started/#sample-bbob-parameters","title":"Sample BBOB parameters\u00b6","text":""},{"location":"notebooks/00_getting_started/#initialize-bbob-state","title":"Initialize BBOB state\u00b6","text":""},{"location":"notebooks/00_getting_started/#sample-solution","title":"Sample solution\u00b6","text":""},{"location":"notebooks/00_getting_started/#evaluate","title":"Evaluate\u00b6","text":""},{"location":"notebooks/00_getting_started/#plot","title":"Plot\u00b6","text":""},{"location":"notebooks/01_bbob/","title":"Black-Box Optimization Benchmarking","text":"<p>In this notebook, we will simply visualize the 24 BBOB functions.</p> <p>You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"jax[cuda]\"\n</pre> %pip install -U \"jax[cuda]\" <p>Then, install bbobax from PyPi:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"bbobax[notebooks]\"\n</pre> %pip install -U \"bbobax[notebooks]\" In\u00a0[\u00a0]: Copied! <pre>import jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\n\nfrom bbobax import BBOB\nfrom bbobax.fitness_fns import bbob_fns\n</pre> import jax import jax.numpy as jnp import matplotlib.pyplot as plt  from bbobax import BBOB from bbobax.fitness_fns import bbob_fns In\u00a0[3]: Copied! <pre>seed = 0\n\nkey = jax.random.key(seed)\n</pre> seed = 0  key = jax.random.key(seed) In\u00a0[\u00a0]: Copied! <pre>def visualize_3d(bbob, params, state, key, ax=None, logscale=False, title=None):\n    \"\"\"Visualize optimization problem in 3D.\"\"\"\n    x = jnp.linspace(bbob.x_range[0], bbob.x_range[1], 100)\n    y = jnp.linspace(bbob.x_range[0], bbob.x_range[1], 100)\n    X, Y = jnp.meshgrid(x, y)\n\n    # Convert to JAX arrays and reshape for evaluation\n    grid = jnp.stack([X.flatten(), Y.flatten()], axis=-1)\n\n    # Evaluate the function at each point\n    def eval_fn(x_input):\n        # evaluate returns (new_state, eval_result)\n        _, res = bbob.evaluate(key, x_input, state, params)\n        return res.fitness\n\n    values = jax.vmap(eval_fn)(grid)\n    Z = jnp.array(values).reshape(X.shape)\n\n    if logscale:\n        # Shift to avoid log(negative) or log(0)\n        Z = Z - jnp.min(Z) + 1.0\n        Z = jnp.log(Z)\n\n    # Create figure and axes if not provided\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(6, 5), subplot_kw={\"projection\": \"3d\"})\n        created_fig = True\n    else:\n        fig = ax.figure\n        created_fig = False\n\n    # Plot the surface with viridis colormap (reversed so small values are yellow)\n    ax.plot_surface(X, Y, Z, cmap=\"viridis_r\", antialiased=True, alpha=0.8)\n\n    # Set labels and title\n    ax.set_xlabel(\"x_1\")\n    ax.set_ylabel(\"x_2\")\n    if title:\n        ax.set_title(title)\n\n    # Set the axis limits to match x_range\n    ax.set_xlim(bbob.x_range[0], bbob.x_range[1])\n    ax.set_ylim(bbob.x_range[0], bbob.x_range[1])\n\n    # Use scientific notation for z-axis\n    ax.ticklabel_format(axis=\"z\", style=\"sci\", scilimits=(0, 0))\n\n    if created_fig:\n        plt.tight_layout()\n        plt.close()\n\n    return fig\n</pre> def visualize_3d(bbob, params, state, key, ax=None, logscale=False, title=None):     \"\"\"Visualize optimization problem in 3D.\"\"\"     x = jnp.linspace(bbob.x_range[0], bbob.x_range[1], 100)     y = jnp.linspace(bbob.x_range[0], bbob.x_range[1], 100)     X, Y = jnp.meshgrid(x, y)      # Convert to JAX arrays and reshape for evaluation     grid = jnp.stack([X.flatten(), Y.flatten()], axis=-1)      # Evaluate the function at each point     def eval_fn(x_input):         # evaluate returns (new_state, eval_result)         _, res = bbob.evaluate(key, x_input, state, params)         return res.fitness      values = jax.vmap(eval_fn)(grid)     Z = jnp.array(values).reshape(X.shape)      if logscale:         # Shift to avoid log(negative) or log(0)         Z = Z - jnp.min(Z) + 1.0         Z = jnp.log(Z)      # Create figure and axes if not provided     if ax is None:         fig, ax = plt.subplots(figsize=(6, 5), subplot_kw={\"projection\": \"3d\"})         created_fig = True     else:         fig = ax.figure         created_fig = False      # Plot the surface with viridis colormap (reversed so small values are yellow)     ax.plot_surface(X, Y, Z, cmap=\"viridis_r\", antialiased=True, alpha=0.8)      # Set labels and title     ax.set_xlabel(\"x_1\")     ax.set_ylabel(\"x_2\")     if title:         ax.set_title(title)      # Set the axis limits to match x_range     ax.set_xlim(bbob.x_range[0], bbob.x_range[1])     ax.set_ylim(bbob.x_range[0], bbob.x_range[1])      # Use scientific notation for z-axis     ax.ticklabel_format(axis=\"z\", style=\"sci\", scilimits=(0, 0))      if created_fig:         plt.tight_layout()         plt.close()      return fig In\u00a0[9]: Copied! <pre>num_dims = 2\n\n# Instantiates all BBOB problems\nproblems = {}\nfor name, fn in bbob_fns.items():\n    problems[name] = BBOB(\n        fitness_fns=[fn],\n        min_num_dims=num_dims,\n        max_num_dims=num_dims,\n        x_opt_range=[0.0, 0.0],\n        f_opt_range=[0.0, 0.0],\n        sample_rotation=False,\n        noise_config={\"noise_model_names\": [\"noiseless\"]},\n    )\n\n# List of functions to use logscale for\nlogscale_functions = [\n    \"rosenbrock\",\n    \"rosenbrock_rotated\",\n    \"different_powers\",\n    \"schaffers_f7\",\n    \"schaffers_f7_ill_conditioned\",\n    \"schwefel\",\n    \"katsuura\",\n]\n\n# Create a figure with 6 rows and 4 columns\n# 24 plots for ~24 functions\nfig, axes = plt.subplots(6, 4, figsize=(16, 24), subplot_kw={\"projection\": \"3d\"})\naxes = axes.flatten()\n\n# Loop through all BBOB functions\nfor i, (fn_name, problem) in enumerate(problems.items()):\n    if i &gt;= len(axes):\n        break\n\n    # Sample params and state for this problem instance\n    key, subkey = jax.random.split(key)\n    params = problem.sample(subkey)\n    state = problem.init(subkey, params)\n\n    # Plot the function on the corresponding axis\n    visualize_3d(\n        problem,\n        params,\n        state,\n        subkey,\n        ax=axes[i],\n        logscale=fn_name in logscale_functions,\n        title=fn_name,\n    )\n\n    # Remove some elements to make the grid cleaner\n    axes[i].set_xlabel(\"\")\n    axes[i].set_ylabel(\"\")\n    axes[i].set_zlabel(\"\")\n    axes[i].set_xticklabels([])\n    axes[i].set_yticklabels([])\n    axes[i].set_zticklabels([])\n\n# Hide any unused subplots\nfor j in range(i + 1, len(axes)):\n    axes[j].axis(\"off\")\n\nplt.show()\n</pre> num_dims = 2  # Instantiates all BBOB problems problems = {} for name, fn in bbob_fns.items():     problems[name] = BBOB(         fitness_fns=[fn],         min_num_dims=num_dims,         max_num_dims=num_dims,         x_opt_range=[0.0, 0.0],         f_opt_range=[0.0, 0.0],         sample_rotation=False,         noise_config={\"noise_model_names\": [\"noiseless\"]},     )  # List of functions to use logscale for logscale_functions = [     \"rosenbrock\",     \"rosenbrock_rotated\",     \"different_powers\",     \"schaffers_f7\",     \"schaffers_f7_ill_conditioned\",     \"schwefel\",     \"katsuura\", ]  # Create a figure with 6 rows and 4 columns # 24 plots for ~24 functions fig, axes = plt.subplots(6, 4, figsize=(16, 24), subplot_kw={\"projection\": \"3d\"}) axes = axes.flatten()  # Loop through all BBOB functions for i, (fn_name, problem) in enumerate(problems.items()):     if i &gt;= len(axes):         break      # Sample params and state for this problem instance     key, subkey = jax.random.split(key)     params = problem.sample(subkey)     state = problem.init(subkey, params)      # Plot the function on the corresponding axis     visualize_3d(         problem,         params,         state,         subkey,         ax=axes[i],         logscale=fn_name in logscale_functions,         title=fn_name,     )      # Remove some elements to make the grid cleaner     axes[i].set_xlabel(\"\")     axes[i].set_ylabel(\"\")     axes[i].set_zlabel(\"\")     axes[i].set_xticklabels([])     axes[i].set_yticklabels([])     axes[i].set_zticklabels([])  # Hide any unused subplots for j in range(i + 1, len(axes)):     axes[j].axis(\"off\")  plt.show()"},{"location":"notebooks/01_bbob/#black-box-optimization-benchmarking","title":"Black-Box Optimization Benchmarking \u00b6","text":""},{"location":"notebooks/01_bbob/#install","title":"Install\u00b6","text":""},{"location":"notebooks/01_bbob/#import","title":"Import\u00b6","text":""},{"location":"notebooks/01_bbob/#visualize-bbob-functions","title":"Visualize BBOB functions\u00b6","text":""},{"location":"notebooks/02_bbo/","title":"Black-Box Optimization","text":"<p>In this notebook, we show how to do black-box optimization on bbobax using Evolution Strategies.</p> <p>You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"jax[cuda]\"\n</pre> %pip install -U \"jax[cuda]\" <p>Then, install bbobax from PyPi:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"bbobax[notebooks]\"\n</pre> %pip install -U \"bbobax[notebooks]\" In\u00a0[1]: Copied! <pre>import jax\nimport jax.numpy as jnp\n\nfrom bbobax import BBOB\n</pre> import jax import jax.numpy as jnp  from bbobax import BBOB In\u00a0[2]: Copied! <pre>seed = 0\n\nkey = jax.random.key(seed)\n</pre> seed = 0  key = jax.random.key(seed) In\u00a0[3]: Copied! <pre>from bbobax.fitness_fns import schaffers_f7\n\nbbob = BBOB(\n    fitness_fns=[schaffers_f7],\n    min_num_dims=2,\n    max_num_dims=2,\n    x_range=[-5, 5],\n    x_opt_range=[0, 0],\n    f_opt_range=[0, 0],\n    clip_x=False,\n    sample_rotation=False,\n    noise_config={\"noise_model_names\": [\"noiseless\"]},\n)\n</pre> from bbobax.fitness_fns import schaffers_f7  bbob = BBOB(     fitness_fns=[schaffers_f7],     min_num_dims=2,     max_num_dims=2,     x_range=[-5, 5],     x_opt_range=[0, 0],     f_opt_range=[0, 0],     clip_x=False,     sample_rotation=False,     noise_config={\"noise_model_names\": [\"noiseless\"]}, ) In\u00a0[4]: Copied! <pre>key, subkey = jax.random.split(key)\nbbob_params = bbob.sample(subkey)\n\nkey, subkey = jax.random.split(key)\nbbob_state = bbob.init(subkey, bbob_params)\n\nkey, subkey = jax.random.split(key)\nx = bbob.sample_x(subkey)\n</pre> key, subkey = jax.random.split(key) bbob_params = bbob.sample(subkey)  key, subkey = jax.random.split(key) bbob_state = bbob.init(subkey, bbob_params)  key, subkey = jax.random.split(key) x = bbob.sample_x(subkey) In\u00a0[5]: Copied! <pre>from evosax.algorithms import CMA_ES as ES\n\npopulation_size = 128\n\n\ndef metrics_fn(key, population, fitness, state, params):\n    \"\"\"Compute metrics for evolution strategy.\"\"\"\n    idx = jnp.argmin(fitness)\n    return {\"best_fitness\": fitness[idx], \"mean\": state.mean}\n\n\nes = ES(\n    population_size=population_size,\n    solution=x,\n    metrics_fn=metrics_fn,\n)\n\nes_params = es.default_params\n\nkey, subkey = jax.random.split(key)\nes_state = es.init(subkey, x, es_params)\n</pre> from evosax.algorithms import CMA_ES as ES  population_size = 128   def metrics_fn(key, population, fitness, state, params):     \"\"\"Compute metrics for evolution strategy.\"\"\"     idx = jnp.argmin(fitness)     return {\"best_fitness\": fitness[idx], \"mean\": state.mean}   es = ES(     population_size=population_size,     solution=x,     metrics_fn=metrics_fn, )  es_params = es.default_params  key, subkey = jax.random.split(key) es_state = es.init(subkey, x, es_params) In\u00a0[17]: Copied! <pre>def step(carry, key):\n    \"\"\"One step of the optimization loop.\"\"\"\n    es_state, es_params, bbob_state = carry\n    key_ask, key_eval, key_tell = jax.random.split(key, 3)\n\n    population, es_state = es.ask(key_ask, es_state, es_params)\n    population = jnp.clip(population, -5, 5)\n\n    fitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None))\n    keys = jax.random.split(key_eval, population.shape[0])\n    bbob_state, bbob_eval = fitness_fn(keys, population, bbob_state, bbob_params)\n    bbob_state = jax.tree.map(lambda x: x[0], bbob_state)\n\n    fitness = bbob_eval.fitness\n    es_state, metrics = es.tell(key_tell, population, fitness, es_state, es_params)\n\n    return (es_state, es_params, bbob_state), metrics\n</pre> def step(carry, key):     \"\"\"One step of the optimization loop.\"\"\"     es_state, es_params, bbob_state = carry     key_ask, key_eval, key_tell = jax.random.split(key, 3)      population, es_state = es.ask(key_ask, es_state, es_params)     population = jnp.clip(population, -5, 5)      fitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None))     keys = jax.random.split(key_eval, population.shape[0])     bbob_state, bbob_eval = fitness_fn(keys, population, bbob_state, bbob_params)     bbob_state = jax.tree.map(lambda x: x[0], bbob_state)      fitness = bbob_eval.fitness     es_state, metrics = es.tell(key_tell, population, fitness, es_state, es_params)      return (es_state, es_params, bbob_state), metrics In\u00a0[15]: Copied! <pre>num_generations = 64\n\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, num_generations)\n_, metrics = jax.lax.scan(\n    step,\n    (es_state, es_params, bbob_state),\n    keys,\n)\n</pre> num_generations = 64  key, subkey = jax.random.split(key) keys = jax.random.split(subkey, num_generations) _, metrics = jax.lax.scan(     step,     (es_state, es_params, bbob_state),     keys, ) In\u00a0[21]: Copied! <pre>import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(metrics[\"best_fitness\"], linewidth=2)\n\nplt.xlabel(\"Generation\")\nplt.ylabel(\"Best Fitness\")\n\nplt.title(\"Evolution Strategy Optimization Progress\")\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt  plt.figure(figsize=(10, 6))  plt.plot(metrics[\"best_fitness\"], linewidth=2)  plt.xlabel(\"Generation\") plt.ylabel(\"Best Fitness\")  plt.title(\"Evolution Strategy Optimization Progress\") plt.grid(True, alpha=0.3)  plt.tight_layout() plt.show()"},{"location":"notebooks/02_bbo/#black-box-optimization","title":"Black-Box Optimization \u00b6","text":""},{"location":"notebooks/02_bbo/#install","title":"Install\u00b6","text":""},{"location":"notebooks/02_bbo/#import","title":"Import\u00b6","text":""},{"location":"notebooks/02_bbo/#initialize-bbo-problem","title":"Initialize BBO Problem\u00b6","text":""},{"location":"notebooks/02_bbo/#initialize-optimizer","title":"Initialize Optimizer\u00b6","text":""},{"location":"notebooks/02_bbo/#run","title":"Run\u00b6","text":""},{"location":"notebooks/02_bbo/#visualize","title":"Visualize\u00b6","text":""},{"location":"notebooks/03_meta_bbo/","title":"Meta-Black-Box Optimization","text":"<p>In this notebook, we show how to do meta-black-box optimization on bbobax using Evolution Strategies.</p> <p>You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"jax[cuda]\"\n</pre> %pip install -U \"jax[cuda]\" <p>Then, install bbobax from PyPi:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"bbobax[notebooks]\"\n</pre> %pip install -U \"bbobax[notebooks]\" In\u00a0[\u00a0]: Copied! <pre>import jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport optax\nfrom evosax.algorithms import algorithms\n\nfrom bbobax import BBOB\nfrom bbobax.fitness_fns import bbob_fns\n</pre> import jax import jax.numpy as jnp import matplotlib.pyplot as plt import optax from evosax.algorithms import algorithms  from bbobax import BBOB from bbobax.fitness_fns import bbob_fns In\u00a0[\u00a0]: Copied! <pre>fn_names = [\n    \"sphere\",\n    \"ellipsoidal\",\n    \"rastrigin\",\n    \"bueche_rastrigin\",\n    \"linear_slope\",\n    \"attractive_sector\",\n    \"step_ellipsoidal\",\n    \"rosenbrock\",\n    \"rosenbrock_rotated\",\n    \"ellipsoidal_rotated\",\n    \"discus\",\n    \"bent_cigar\",\n    \"sharp_ridge\",\n    \"different_powers\",\n    \"rastrigin_rotated\",\n    \"weierstrass\",\n    \"schaffers_f7\",\n    \"schaffers_f7_ill_conditioned\",\n    \"griewank_rosenbrock\",\n    \"katsuura\",\n    \"lunacek\",\n]\n\n# Map function names to callables\nfitness_fns = [bbob_fns[fn_name] for fn_name in fn_names]\n\nbbob = BBOB(\n    fitness_fns=fitness_fns,\n    min_num_dims=2,\n    max_num_dims=16,\n    x_range=[-5.0, 5.0],\n    x_opt_range=[-4.0, 4.0],\n    f_opt_range=[0.0, 0.0],  # Force optimal fitness to 0.0\n)\n</pre> fn_names = [     \"sphere\",     \"ellipsoidal\",     \"rastrigin\",     \"bueche_rastrigin\",     \"linear_slope\",     \"attractive_sector\",     \"step_ellipsoidal\",     \"rosenbrock\",     \"rosenbrock_rotated\",     \"ellipsoidal_rotated\",     \"discus\",     \"bent_cigar\",     \"sharp_ridge\",     \"different_powers\",     \"rastrigin_rotated\",     \"weierstrass\",     \"schaffers_f7\",     \"schaffers_f7_ill_conditioned\",     \"griewank_rosenbrock\",     \"katsuura\",     \"lunacek\", ]  # Map function names to callables fitness_fns = [bbob_fns[fn_name] for fn_name in fn_names]  bbob = BBOB(     fitness_fns=fitness_fns,     min_num_dims=2,     max_num_dims=16,     x_range=[-5.0, 5.0],     x_opt_range=[-4.0, 4.0],     f_opt_range=[0.0, 0.0],  # Force optimal fitness to 0.0 ) In\u00a0[\u00a0]: Copied! <pre>num_generations = 8_192\npopulation_size = 1_024\nnum_tasks = 128\nkey = jax.random.key(0)\n\nes_dict = {\n    \"SimpleES\": {},\n    \"PGPE\": {},\n    \"Open_ES\": {\"optimizer\": optax.adam(1e-3)},\n    \"SNES\": {},\n    \"Sep_CMA_ES\": {},\n    \"CMA_ES\": {},\n}\n\n# Dictionary to store results for each ES\nresults = {}\n\n# Sample BBOB tasks (params and state shared across all ES runs)\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, num_tasks)\nbbob_params = jax.vmap(bbob.sample)(keys)\n\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, num_tasks)\nbbob_state = jax.vmap(bbob.init)(keys, bbob_params)\n\n# Sample initial solutions for each task (to be used by all ES)\nkey, subkey = jax.random.split(key)\nx = bbob.sample_x(subkey)  # Dummy solution for ES init\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, num_tasks)\nsolutions = jax.vmap(bbob.sample_x)(keys)\nsolutions = jnp.clip(solutions, -4.0, 4.0)\n\n\n# Loop over the selected ES algorithms\nfor es_name in es_dict:\n    print(f\"Running {es_name}...\")\n\n    # Get the ES class from the algorithms dictionary\n    ES = algorithms[es_name]\n\n    # Initialize the ES\n    es = ES(\n        population_size=population_size,\n        solution=x,\n        **es_dict[es_name],\n    )\n\n    es_params = es.default_params\n\n    # Define the step function for the scan\n    def step(carry, key):\n        \"\"\"One step of the optimization loop.\"\"\"\n        es_state, es_params, bbob_state, bbob_params = carry\n        key_ask, key_eval, key_tell = jax.random.split(key, 3)\n\n        # Ask\n        population, es_state = es.ask(key_ask, es_state, es_params)\n        population = jnp.clip(population, -5.0, 5.0)\n\n        # Eval (vectorized over population)\n        fitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None))\n        keys_eval = jax.random.split(key_eval, population.shape[0])\n        bbob_state, bbob_eval = fitness_fn(\n            keys_eval, population, bbob_state, bbob_params\n        )\n        # bbob_state is updated (counter +1), same for all individuals in pop\n        bbob_state = jax.tree.map(lambda x: x[0], bbob_state)\n        fitness = bbob_eval.fitness\n\n        # Tell\n        es_state, metrics = es.tell(key_tell, population, fitness, es_state, es_params)\n\n        return (es_state, es_params, bbob_state, bbob_params), (es_state, metrics)\n\n    @jax.jit\n    def run_es_eval(key, solution, es_params, bbob_state, bbob_params):\n        \"\"\"Run ES on a single task.\"\"\"\n        # Init ES state with the specific solution for this task\n        key, subkey = jax.random.split(key)\n        es_state = es.init(subkey, solution, es_params)\n\n        # Scan\n        keys = jax.random.split(subkey, num_generations)\n        (es_state, es_params, bbob_state, bbob_params), (es_states, metrics) = (\n            jax.lax.scan(\n                step,\n                (es_state, es_params, bbob_state, bbob_params),\n                keys,\n                length=num_generations,\n            )\n        )\n\n        return metrics, es_states.mean[-1]\n\n    # Run evaluation across all tasks\n    key, subkey = jax.random.split(key)\n    keys = jax.random.split(subkey, num_tasks)\n    metrics_batch, final_means = jax.vmap(run_es_eval, in_axes=(0, 0, None, 0, 0))(\n        keys, solutions, es_params, bbob_state, bbob_params\n    )\n\n    # Average metrics across tasks\n    metrics = jax.tree.map(lambda x: jnp.mean(x, axis=0), metrics_batch)\n\n    # Store the results\n    results[es_name] = metrics\n</pre> num_generations = 8_192 population_size = 1_024 num_tasks = 128 key = jax.random.key(0)  es_dict = {     \"SimpleES\": {},     \"PGPE\": {},     \"Open_ES\": {\"optimizer\": optax.adam(1e-3)},     \"SNES\": {},     \"Sep_CMA_ES\": {},     \"CMA_ES\": {}, }  # Dictionary to store results for each ES results = {}  # Sample BBOB tasks (params and state shared across all ES runs) key, subkey = jax.random.split(key) keys = jax.random.split(subkey, num_tasks) bbob_params = jax.vmap(bbob.sample)(keys)  key, subkey = jax.random.split(key) keys = jax.random.split(subkey, num_tasks) bbob_state = jax.vmap(bbob.init)(keys, bbob_params)  # Sample initial solutions for each task (to be used by all ES) key, subkey = jax.random.split(key) x = bbob.sample_x(subkey)  # Dummy solution for ES init key, subkey = jax.random.split(key) keys = jax.random.split(subkey, num_tasks) solutions = jax.vmap(bbob.sample_x)(keys) solutions = jnp.clip(solutions, -4.0, 4.0)   # Loop over the selected ES algorithms for es_name in es_dict:     print(f\"Running {es_name}...\")      # Get the ES class from the algorithms dictionary     ES = algorithms[es_name]      # Initialize the ES     es = ES(         population_size=population_size,         solution=x,         **es_dict[es_name],     )      es_params = es.default_params      # Define the step function for the scan     def step(carry, key):         \"\"\"One step of the optimization loop.\"\"\"         es_state, es_params, bbob_state, bbob_params = carry         key_ask, key_eval, key_tell = jax.random.split(key, 3)          # Ask         population, es_state = es.ask(key_ask, es_state, es_params)         population = jnp.clip(population, -5.0, 5.0)          # Eval (vectorized over population)         fitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None))         keys_eval = jax.random.split(key_eval, population.shape[0])         bbob_state, bbob_eval = fitness_fn(             keys_eval, population, bbob_state, bbob_params         )         # bbob_state is updated (counter +1), same for all individuals in pop         bbob_state = jax.tree.map(lambda x: x[0], bbob_state)         fitness = bbob_eval.fitness          # Tell         es_state, metrics = es.tell(key_tell, population, fitness, es_state, es_params)          return (es_state, es_params, bbob_state, bbob_params), (es_state, metrics)      @jax.jit     def run_es_eval(key, solution, es_params, bbob_state, bbob_params):         \"\"\"Run ES on a single task.\"\"\"         # Init ES state with the specific solution for this task         key, subkey = jax.random.split(key)         es_state = es.init(subkey, solution, es_params)          # Scan         keys = jax.random.split(subkey, num_generations)         (es_state, es_params, bbob_state, bbob_params), (es_states, metrics) = (             jax.lax.scan(                 step,                 (es_state, es_params, bbob_state, bbob_params),                 keys,                 length=num_generations,             )         )          return metrics, es_states.mean[-1]      # Run evaluation across all tasks     key, subkey = jax.random.split(key)     keys = jax.random.split(subkey, num_tasks)     metrics_batch, final_means = jax.vmap(run_es_eval, in_axes=(0, 0, None, 0, 0))(         keys, solutions, es_params, bbob_state, bbob_params     )      # Average metrics across tasks     metrics = jax.tree.map(lambda x: jnp.mean(x, axis=0), metrics_batch)      # Store the results     results[es_name] = metrics In\u00a0[\u00a0]: Copied! <pre># Plot the fitness over generations for each ES\nplt.figure(figsize=(10, 6))\n\nfor es_name, metrics in results.items():\n    plt.plot(metrics[\"best_fitness\"], label=es_name)\n\nplt.title(f\"Evolution Strategies Comparison on {num_tasks} Sampled BBOB Functions\")\nplt.xlabel(\"Generations\")\nplt.ylabel(\"Fitness\")\nplt.yscale(\"log\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> # Plot the fitness over generations for each ES plt.figure(figsize=(10, 6))  for es_name, metrics in results.items():     plt.plot(metrics[\"best_fitness\"], label=es_name)  plt.title(f\"Evolution Strategies Comparison on {num_tasks} Sampled BBOB Functions\") plt.xlabel(\"Generations\") plt.ylabel(\"Fitness\") plt.yscale(\"log\") plt.legend() plt.grid(True) plt.show()"},{"location":"notebooks/03_meta_bbo/#meta-black-box-optimization","title":"Meta-Black-Box Optimization \u00b6","text":""},{"location":"notebooks/03_meta_bbo/#install","title":"Install\u00b6","text":""},{"location":"notebooks/03_meta_bbo/#import","title":"Import\u00b6","text":""},{"location":"notebooks/03_meta_bbo/#initialize-bbo-problem","title":"Initialize BBO Problem\u00b6","text":""},{"location":"notebooks/03_meta_bbo/#es-comparison-across-many-bbo-problems","title":"ES Comparison across many BBO problems\u00b6","text":""},{"location":"notebooks/03_meta_bbo/#visualize","title":"Visualize\u00b6","text":""},{"location":"notebooks/04_qd/","title":"Quality-Diversity","text":"<p>In this notebook, we show how to do black-box optimization on bbobax using Quality-Diversity.</p> <p>You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"jax[cuda]\"\n</pre> %pip install -U \"jax[cuda]\" <p>Then, install bbobax from PyPi:</p> In\u00a0[\u00a0]: Copied! <pre>%pip install -U \"bbobax[notebooks]\"\n</pre> %pip install -U \"bbobax[notebooks]\" In\u00a0[\u00a0]: Copied! <pre>from functools import partial\nfrom typing import Any\n\nimport flax.struct\nimport jax\nimport jax.numpy as jnp\nfrom numpy.random import RandomState\nfrom sklearn.cluster import KMeans\n\n# Types\ntype Genotype = Any\ntype Fitness = jax.Array\ntype Descriptor = jax.Array\ntype RNGKey = jax.Array\ntype Centroid = jax.Array\n</pre> from functools import partial from typing import Any  import flax.struct import jax import jax.numpy as jnp from numpy.random import RandomState from sklearn.cluster import KMeans  # Types type Genotype = Any type Fitness = jax.Array type Descriptor = jax.Array type RNGKey = jax.Array type Centroid = jax.Array In\u00a0[\u00a0]: Copied! <pre>def novelty_and_dominated_novelty(\n    fitness, descriptor, novelty_k=3, dominated_novelty_k=3\n):\n    \"\"\"Compute novelty and dominated novelty.\"\"\"\n    valid = fitness != -jnp.inf\n\n    # Neighbors\n    neighbor = valid[:, None] &amp; valid[None, :]\n    neighbor = jnp.fill_diagonal(neighbor, False, inplace=False)\n\n    # Fitter\n    fitter = fitness[:, None] &lt;= fitness[None, :]\n    fitter = jnp.where(neighbor, fitter, False)\n\n    # Distance to neighbors\n    distance = jnp.linalg.norm(descriptor[:, None, :] - descriptor[None, :, :], axis=-1)\n    distance = jnp.where(neighbor, distance, jnp.inf)\n\n    # Distance to fitter neighbors\n    distance_fitter = jnp.where(fitter, distance, jnp.inf)\n\n    # Novelty - distance to k-nearest neighbors\n    values, indices = jax.vmap(partial(jax.lax.top_k, k=novelty_k))(-distance)\n    novelty = jnp.mean(\n        -values, axis=-1, where=jnp.take_along_axis(neighbor, indices, axis=-1)\n    )\n\n    # Dominated Novelty - distance to k-fitter-nearest neighbors\n    values, indices = jax.vmap(partial(jax.lax.top_k, k=dominated_novelty_k))(\n        -distance_fitter\n    )\n    dominated_novelty = jnp.mean(\n        -values, axis=-1, where=jnp.take_along_axis(fitter, indices, axis=-1)\n    )  # only max fitness individual should be nan\n\n    return novelty, dominated_novelty\n\n\ndef metrics_fn(\n    key: RNGKey,\n    population: Genotype,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: \"QDState\",\n    params: \"QDParams\",\n) -&gt; dict:\n    \"\"\"Compute QD metrics.\"\"\"\n    k = 3\n    novelty, dominated_novelty = novelty_and_dominated_novelty(\n        fitness,\n        descriptor,\n        novelty_k=k,\n        dominated_novelty_k=k,\n    )\n    dominated_novelty = jnp.where(\n        jnp.isposinf(dominated_novelty), jnp.nan, dominated_novelty\n    )\n\n    return {\n        \"fitness\": fitness,\n        \"descriptor\": descriptor,\n        \"novelty\": novelty,\n        \"dominated_novelty\": dominated_novelty,\n    }\n\n\n@jax.jit\ndef metrics_agg_fn(metrics: dict) -&gt; dict:\n    \"\"\"Aggregate QD metrics.\"\"\"\n    valid = metrics[\"fitness\"] != -jnp.inf\n\n    descriptor_mean = jnp.mean(metrics[\"descriptor\"], axis=-2, where=valid[..., None])\n    distance_to_mean = jnp.linalg.norm(\n        metrics[\"descriptor\"] - descriptor_mean[..., None, :], axis=-1\n    )\n    descriptor_std = jnp.std(distance_to_mean, axis=-1, where=valid)\n\n    return {\n        \"population_size\": jnp.sum(valid, axis=-1),\n        \"fitness_max\": jnp.max(\n            metrics[\"fitness\"], axis=-1, initial=-jnp.inf, where=valid\n        ),\n        \"fitness_mean\": jnp.mean(metrics[\"fitness\"], axis=-1, where=valid),\n        \"novelty_mean\": jnp.mean(metrics[\"novelty\"], axis=-1, where=valid),\n        \"dominated_novelty_mean\": jnp.nanmean(\n            metrics[\"dominated_novelty\"], axis=-1, where=valid\n        ),\n        \"descriptor_std\": descriptor_std,\n    }\n</pre> def novelty_and_dominated_novelty(     fitness, descriptor, novelty_k=3, dominated_novelty_k=3 ):     \"\"\"Compute novelty and dominated novelty.\"\"\"     valid = fitness != -jnp.inf      # Neighbors     neighbor = valid[:, None] &amp; valid[None, :]     neighbor = jnp.fill_diagonal(neighbor, False, inplace=False)      # Fitter     fitter = fitness[:, None] &lt;= fitness[None, :]     fitter = jnp.where(neighbor, fitter, False)      # Distance to neighbors     distance = jnp.linalg.norm(descriptor[:, None, :] - descriptor[None, :, :], axis=-1)     distance = jnp.where(neighbor, distance, jnp.inf)      # Distance to fitter neighbors     distance_fitter = jnp.where(fitter, distance, jnp.inf)      # Novelty - distance to k-nearest neighbors     values, indices = jax.vmap(partial(jax.lax.top_k, k=novelty_k))(-distance)     novelty = jnp.mean(         -values, axis=-1, where=jnp.take_along_axis(neighbor, indices, axis=-1)     )      # Dominated Novelty - distance to k-fitter-nearest neighbors     values, indices = jax.vmap(partial(jax.lax.top_k, k=dominated_novelty_k))(         -distance_fitter     )     dominated_novelty = jnp.mean(         -values, axis=-1, where=jnp.take_along_axis(fitter, indices, axis=-1)     )  # only max fitness individual should be nan      return novelty, dominated_novelty   def metrics_fn(     key: RNGKey,     population: Genotype,     fitness: Fitness,     descriptor: Descriptor,     state: \"QDState\",     params: \"QDParams\", ) -&gt; dict:     \"\"\"Compute QD metrics.\"\"\"     k = 3     novelty, dominated_novelty = novelty_and_dominated_novelty(         fitness,         descriptor,         novelty_k=k,         dominated_novelty_k=k,     )     dominated_novelty = jnp.where(         jnp.isposinf(dominated_novelty), jnp.nan, dominated_novelty     )      return {         \"fitness\": fitness,         \"descriptor\": descriptor,         \"novelty\": novelty,         \"dominated_novelty\": dominated_novelty,     }   @jax.jit def metrics_agg_fn(metrics: dict) -&gt; dict:     \"\"\"Aggregate QD metrics.\"\"\"     valid = metrics[\"fitness\"] != -jnp.inf      descriptor_mean = jnp.mean(metrics[\"descriptor\"], axis=-2, where=valid[..., None])     distance_to_mean = jnp.linalg.norm(         metrics[\"descriptor\"] - descriptor_mean[..., None, :], axis=-1     )     descriptor_std = jnp.std(distance_to_mean, axis=-1, where=valid)      return {         \"population_size\": jnp.sum(valid, axis=-1),         \"fitness_max\": jnp.max(             metrics[\"fitness\"], axis=-1, initial=-jnp.inf, where=valid         ),         \"fitness_mean\": jnp.mean(metrics[\"fitness\"], axis=-1, where=valid),         \"novelty_mean\": jnp.mean(metrics[\"novelty\"], axis=-1, where=valid),         \"dominated_novelty_mean\": jnp.nanmean(             metrics[\"dominated_novelty\"], axis=-1, where=valid         ),         \"descriptor_std\": descriptor_std,     } In\u00a0[\u00a0]: Copied! <pre>@flax.struct.dataclass\nclass QDState:\n    \"\"\"State for QD algorithms.\"\"\"\n\n    population: Genotype\n    fitness: Fitness\n    descriptor: Descriptor\n\n    generation_counter: int\n\n\n@flax.struct.dataclass\nclass QDParams:\n    \"\"\"Parameters for QD algorithms.\"\"\"\n\n    mutation_sigma: float = 0.1\n</pre> @flax.struct.dataclass class QDState:     \"\"\"State for QD algorithms.\"\"\"      population: Genotype     fitness: Fitness     descriptor: Descriptor      generation_counter: int   @flax.struct.dataclass class QDParams:     \"\"\"Parameters for QD algorithms.\"\"\"      mutation_sigma: float = 0.1 In\u00a0[\u00a0]: Copied! <pre>def gaussian_mutation(key: RNGKey, genotype: Genotype, sigma: float) -&gt; Genotype:\n    \"\"\"Apply Gaussian mutation to the genotype.\"\"\"\n    return jax.tree.map(lambda x: x + sigma * jax.random.normal(key, x.shape), genotype)\n</pre> def gaussian_mutation(key: RNGKey, genotype: Genotype, sigma: float) -&gt; Genotype:     \"\"\"Apply Gaussian mutation to the genotype.\"\"\"     return jax.tree.map(lambda x: x + sigma * jax.random.normal(key, x.shape), genotype) In\u00a0[\u00a0]: Copied! <pre>class QDAlgorithm:\n    \"\"\"Base class for Quality-Diversity algorithms.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        fitness_shaping_fn,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize the QD Algorithm.\"\"\"\n        self.population_size = population_size\n        self.solution = solution\n        self.fitness_shaping_fn = fitness_shaping_fn\n        self.metrics_fn = metrics_fn\n        self.descriptor_size = descriptor_size\n\n    @partial(jax.jit, static_argnames=(\"self\",))\n    def init(\n        self,\n        key: jax.Array,\n        population: Genotype,\n        fitness: Fitness,\n        descriptor: Descriptor,\n        params: QDParams,\n    ) -&gt; QDState:\n        \"\"\"Initialize evolutionary algorithm.\"\"\"\n        state = self._init(key, params)\n        state, _ = self.tell(key, population, fitness, descriptor, state, params)\n        return state\n\n    @partial(jax.jit, static_argnames=(\"self\",))\n    def ask(\n        self,\n        key: jax.Array,\n        state: QDState,\n        params: QDParams,\n    ) -&gt; tuple[Genotype, QDState]:\n        \"\"\"Ask evolutionary algorithm for new candidate solutions.\"\"\"\n        return self._ask(key, state, params)\n\n    @property\n    def default_params(self) -&gt; QDParams:\n        \"\"\"Return default parameters for the algorithm.\"\"\"\n        return QDParams()\n\n    def tell(\n        self,\n        key: RNGKey,\n        population: Genotype,\n        fitness: Fitness,\n        descriptor: Descriptor,\n        state: QDState,\n        params: QDParams,\n    ) -&gt; tuple[QDState, dict]:\n        \"\"\"Tell Fitness and Descriptors.\"\"\"\n        # Concatenate\n        all_genotype = jax.tree.map(\n            lambda x, y: jnp.concatenate([x, y], axis=0),\n            state.population,\n            population,\n        )\n        all_fitness = jnp.concatenate([state.fitness, fitness], axis=0)\n        all_descriptor = jnp.concatenate([state.descriptor, descriptor], axis=0)\n\n        # Compute competition fitness\n        key_shaping, key_metrics = jax.random.split(key)\n        shaped_fitness = self.fitness_shaping_fn(\n            key_shaping,\n            all_fitness,\n            all_descriptor,\n            state,\n            params,\n        )\n\n        # Sort by competition fitness\n        indices = jnp.argsort(shaped_fitness, descending=True)\n        indices = indices[: self.population_size]\n\n        # Keep best\n        new_genotype = jax.tree.map(lambda x: x[indices], all_genotype)\n        new_fitness = all_fitness[indices]\n        new_descriptor = all_descriptor[indices]\n\n        # Mark invalid individuals as -inf\n        is_valid = shaped_fitness[indices] != -jnp.inf\n        new_fitness = jnp.where(is_valid, new_fitness, -jnp.inf)\n        new_descriptor = jnp.where(is_valid[:, None], new_descriptor, jnp.nan)\n\n        state = state.replace(\n            population=new_genotype,\n            fitness=new_fitness,\n            descriptor=new_descriptor,\n            generation_counter=state.generation_counter + 1,\n        )\n\n        # Metrics\n        metrics = self.metrics_fn(\n            key_metrics,\n            state.population,\n            state.fitness,\n            state.descriptor,\n            state,\n            params,\n        )\n        metrics[\"generation\"] = state.generation_counter\n\n        return state, metrics\n\n    def _init(self, key: RNGKey, params: QDParams) -&gt; QDState:\n        genotype = jax.tree.map(\n            lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),\n            self.solution,\n        )\n        fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)\n        descriptor = jnp.full(\n            (self.population_size, self.descriptor_size), fill_value=jnp.nan\n        )\n\n        state = QDState(\n            population=genotype,\n            fitness=fitness,\n            descriptor=descriptor,\n            generation_counter=0,\n        )\n        return state\n\n    def _ask(\n        self, key: RNGKey, state: QDState, params: QDParams\n    ) -&gt; tuple[Genotype, QDState]:\n        \"\"\"Ask for new candidate solutions.\"\"\"\n        # Simple Selection -&gt; Mutation\n        valid = state.fitness != -jnp.inf\n\n        p = valid / jnp.sum(valid)\n        p = jnp.where(jnp.isnan(p), 1.0 / self.population_size, p)\n\n        population = jax.tree.map(\n            lambda x: jax.random.choice(key, x, shape=(self.population_size,), p=p),\n            state.population,\n        )\n\n        population = gaussian_mutation(key, population, params.mutation_sigma)\n\n        return population, state\n</pre> class QDAlgorithm:     \"\"\"Base class for Quality-Diversity algorithms.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         fitness_shaping_fn,         descriptor_size: int = 2,     ):         \"\"\"Initialize the QD Algorithm.\"\"\"         self.population_size = population_size         self.solution = solution         self.fitness_shaping_fn = fitness_shaping_fn         self.metrics_fn = metrics_fn         self.descriptor_size = descriptor_size      @partial(jax.jit, static_argnames=(\"self\",))     def init(         self,         key: jax.Array,         population: Genotype,         fitness: Fitness,         descriptor: Descriptor,         params: QDParams,     ) -&gt; QDState:         \"\"\"Initialize evolutionary algorithm.\"\"\"         state = self._init(key, params)         state, _ = self.tell(key, population, fitness, descriptor, state, params)         return state      @partial(jax.jit, static_argnames=(\"self\",))     def ask(         self,         key: jax.Array,         state: QDState,         params: QDParams,     ) -&gt; tuple[Genotype, QDState]:         \"\"\"Ask evolutionary algorithm for new candidate solutions.\"\"\"         return self._ask(key, state, params)      @property     def default_params(self) -&gt; QDParams:         \"\"\"Return default parameters for the algorithm.\"\"\"         return QDParams()      def tell(         self,         key: RNGKey,         population: Genotype,         fitness: Fitness,         descriptor: Descriptor,         state: QDState,         params: QDParams,     ) -&gt; tuple[QDState, dict]:         \"\"\"Tell Fitness and Descriptors.\"\"\"         # Concatenate         all_genotype = jax.tree.map(             lambda x, y: jnp.concatenate([x, y], axis=0),             state.population,             population,         )         all_fitness = jnp.concatenate([state.fitness, fitness], axis=0)         all_descriptor = jnp.concatenate([state.descriptor, descriptor], axis=0)          # Compute competition fitness         key_shaping, key_metrics = jax.random.split(key)         shaped_fitness = self.fitness_shaping_fn(             key_shaping,             all_fitness,             all_descriptor,             state,             params,         )          # Sort by competition fitness         indices = jnp.argsort(shaped_fitness, descending=True)         indices = indices[: self.population_size]          # Keep best         new_genotype = jax.tree.map(lambda x: x[indices], all_genotype)         new_fitness = all_fitness[indices]         new_descriptor = all_descriptor[indices]          # Mark invalid individuals as -inf         is_valid = shaped_fitness[indices] != -jnp.inf         new_fitness = jnp.where(is_valid, new_fitness, -jnp.inf)         new_descriptor = jnp.where(is_valid[:, None], new_descriptor, jnp.nan)          state = state.replace(             population=new_genotype,             fitness=new_fitness,             descriptor=new_descriptor,             generation_counter=state.generation_counter + 1,         )          # Metrics         metrics = self.metrics_fn(             key_metrics,             state.population,             state.fitness,             state.descriptor,             state,             params,         )         metrics[\"generation\"] = state.generation_counter          return state, metrics      def _init(self, key: RNGKey, params: QDParams) -&gt; QDState:         genotype = jax.tree.map(             lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),             self.solution,         )         fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)         descriptor = jnp.full(             (self.population_size, self.descriptor_size), fill_value=jnp.nan         )          state = QDState(             population=genotype,             fitness=fitness,             descriptor=descriptor,             generation_counter=0,         )         return state      def _ask(         self, key: RNGKey, state: QDState, params: QDParams     ) -&gt; tuple[Genotype, QDState]:         \"\"\"Ask for new candidate solutions.\"\"\"         # Simple Selection -&gt; Mutation         valid = state.fitness != -jnp.inf          p = valid / jnp.sum(valid)         p = jnp.where(jnp.isnan(p), 1.0 / self.population_size, p)          population = jax.tree.map(             lambda x: jax.random.choice(key, x, shape=(self.population_size,), p=p),             state.population,         )          population = gaussian_mutation(key, population, params.mutation_sigma)          return population, state In\u00a0[\u00a0]: Copied! <pre>def random_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n) -&gt; Fitness:\n    \"\"\"Random Fitness.\"\"\"\n    random_fitness = jax.random.uniform(key, fitness.shape)\n    valid = fitness != -jnp.inf\n    return jnp.where(valid, random_fitness, -jnp.inf)\n</pre> def random_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams, ) -&gt; Fitness:     \"\"\"Random Fitness.\"\"\"     random_fitness = jax.random.uniform(key, fitness.shape)     valid = fitness != -jnp.inf     return jnp.where(valid, random_fitness, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>class RandomSearch(QDAlgorithm):\n    \"\"\"Random Search: replaces individuals randomly.\"\"\"\n\n    def __init__(\n        self, population_size: int, solution: Genotype, descriptor_size: int = 2\n    ):\n        \"\"\"Initialize Random Search.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=random_fitness_shaping,\n            descriptor_size=descriptor_size,\n        )\n</pre> class RandomSearch(QDAlgorithm):     \"\"\"Random Search: replaces individuals randomly.\"\"\"      def __init__(         self, population_size: int, solution: Genotype, descriptor_size: int = 2     ):         \"\"\"Initialize Random Search.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=random_fitness_shaping,             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre>def identity_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n) -&gt; Fitness:\n    \"\"\"Raw Fitness.\"\"\"\n    return fitness\n</pre> def identity_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams, ) -&gt; Fitness:     \"\"\"Raw Fitness.\"\"\"     return fitness In\u00a0[\u00a0]: Copied! <pre>class GeneticAlgorithm(QDAlgorithm):\n    \"\"\"Genetic Algorithm: Standard unstructured population with identity fitness.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        fitness_shaping_fn=identity_fitness_shaping,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize Genetic Algorithm.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=fitness_shaping_fn,\n            descriptor_size=descriptor_size,\n        )\n</pre> class GeneticAlgorithm(QDAlgorithm):     \"\"\"Genetic Algorithm: Standard unstructured population with identity fitness.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         fitness_shaping_fn=identity_fitness_shaping,         descriptor_size: int = 2,     ):         \"\"\"Initialize Genetic Algorithm.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=fitness_shaping_fn,             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre>def novelty_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n    novelty_k: int = 3,\n) -&gt; Fitness:\n    \"\"\"Novelty Score.\"\"\"\n    novelty, _ = novelty_and_dominated_novelty(\n        fitness,\n        descriptor,\n        novelty_k=novelty_k,\n    )\n    valid = fitness != -jnp.inf\n    return jnp.where(valid, novelty, -jnp.inf)\n</pre> def novelty_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams,     novelty_k: int = 3, ) -&gt; Fitness:     \"\"\"Novelty Score.\"\"\"     novelty, _ = novelty_and_dominated_novelty(         fitness,         descriptor,         novelty_k=novelty_k,     )     valid = fitness != -jnp.inf     return jnp.where(valid, novelty, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>class NoveltySearch(QDAlgorithm):\n    \"\"\"Novelty Search Algorithm.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        novelty_k: int = 3,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize Novelty Search.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=partial(novelty_fitness_shaping, novelty_k=novelty_k),\n            descriptor_size=descriptor_size,\n        )\n</pre> class NoveltySearch(QDAlgorithm):     \"\"\"Novelty Search Algorithm.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         novelty_k: int = 3,         descriptor_size: int = 2,     ):         \"\"\"Initialize Novelty Search.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=partial(novelty_fitness_shaping, novelty_k=novelty_k),             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre>def dominated_novelty_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n    novelty_k: int = 3,\n) -&gt; Fitness:\n    \"\"\"Dominated Novelty Score.\"\"\"\n    _, dominated_novelty = novelty_and_dominated_novelty(\n        fitness,\n        descriptor,\n        dominated_novelty_k=novelty_k,\n    )\n    valid = fitness != -jnp.inf\n    return jnp.where(valid, dominated_novelty, -jnp.inf)\n</pre> def dominated_novelty_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams,     novelty_k: int = 3, ) -&gt; Fitness:     \"\"\"Dominated Novelty Score.\"\"\"     _, dominated_novelty = novelty_and_dominated_novelty(         fitness,         descriptor,         dominated_novelty_k=novelty_k,     )     valid = fitness != -jnp.inf     return jnp.where(valid, dominated_novelty, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>class DominatedNoveltySearch(QDAlgorithm):\n    \"\"\"Dominated Novelty Search Algorithm.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        novelty_k: int = 3,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize Dominated Novelty Search.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=partial(\n                dominated_novelty_fitness_shaping, novelty_k=novelty_k\n            ),\n            descriptor_size=descriptor_size,\n        )\n</pre> class DominatedNoveltySearch(QDAlgorithm):     \"\"\"Dominated Novelty Search Algorithm.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         novelty_k: int = 3,         descriptor_size: int = 2,     ):         \"\"\"Initialize Dominated Novelty Search.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=partial(                 dominated_novelty_fitness_shaping, novelty_k=novelty_k             ),             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre>def get_centroid_indices(descriptors: Descriptor, centroids: Centroid) -&gt; jax.Array:\n    \"\"\"Assign descriptors to their closest centroid and return centroid indices.\"\"\"\n\n    def _get_centroid_indices(descriptor: Descriptor) -&gt; jax.Array:\n        return jnp.argmin(jnp.linalg.norm(descriptor - centroids, axis=-1))\n\n    indices = jax.vmap(_get_centroid_indices)(descriptors)\n    return indices\n\n\ndef get_centroids(\n    num_centroids: int,\n    descriptor_size: int,\n    descriptor_min: float | list[float],\n    descriptor_max: float | list[float],\n    num_init_cvt_samples: int,\n    key: RNGKey,\n) -&gt; jax.Array:\n    \"\"\"Compute centroids using CVT (Centroidal Voronoi Tessellation).\"\"\"\n    descriptor_min = jnp.array(descriptor_min)\n    descriptor_max = jnp.array(descriptor_max)\n\n    # Sample x uniformly in [0, 1]\n    key_x, key_kmeans = jax.random.split(key)\n    x = jax.random.uniform(key_x, (num_init_cvt_samples, descriptor_size))\n\n    # Generate an integer seed for RandomState\n    seed = jax.random.randint(key_kmeans, (), 0, 2**30, dtype=jnp.int32)\n\n    def _kmeans_host_fn(x_np, seed_np):\n        rs = RandomState(int(seed_np))\n        kmeans = KMeans(\n            init=\"k-means++\",\n            n_clusters=num_centroids,\n            n_init=1,\n            random_state=rs,\n        )\n        kmeans.fit(x_np)\n        return kmeans.cluster_centers_.astype(x_np.dtype)\n\n    # Call host function\n    centroids = jax.pure_callback(\n        _kmeans_host_fn,\n        jax.ShapeDtypeStruct((num_centroids, descriptor_size), x.dtype),\n        x,\n        seed,\n    )\n\n    # Rescale\n    return descriptor_min + (descriptor_max - descriptor_min) * centroids\n\n\ndef segment_argmax(data, segment_ids, num_segments):\n    \"\"\"Compute the argmax of data for each segment.\"\"\"\n    return jnp.argmax(\n        jax.vmap(lambda i: jnp.where(i == segment_ids, data, -jnp.inf))(\n            jnp.arange(num_segments)\n        ),\n        axis=1,\n    )\n</pre> def get_centroid_indices(descriptors: Descriptor, centroids: Centroid) -&gt; jax.Array:     \"\"\"Assign descriptors to their closest centroid and return centroid indices.\"\"\"      def _get_centroid_indices(descriptor: Descriptor) -&gt; jax.Array:         return jnp.argmin(jnp.linalg.norm(descriptor - centroids, axis=-1))      indices = jax.vmap(_get_centroid_indices)(descriptors)     return indices   def get_centroids(     num_centroids: int,     descriptor_size: int,     descriptor_min: float | list[float],     descriptor_max: float | list[float],     num_init_cvt_samples: int,     key: RNGKey, ) -&gt; jax.Array:     \"\"\"Compute centroids using CVT (Centroidal Voronoi Tessellation).\"\"\"     descriptor_min = jnp.array(descriptor_min)     descriptor_max = jnp.array(descriptor_max)      # Sample x uniformly in [0, 1]     key_x, key_kmeans = jax.random.split(key)     x = jax.random.uniform(key_x, (num_init_cvt_samples, descriptor_size))      # Generate an integer seed for RandomState     seed = jax.random.randint(key_kmeans, (), 0, 2**30, dtype=jnp.int32)      def _kmeans_host_fn(x_np, seed_np):         rs = RandomState(int(seed_np))         kmeans = KMeans(             init=\"k-means++\",             n_clusters=num_centroids,             n_init=1,             random_state=rs,         )         kmeans.fit(x_np)         return kmeans.cluster_centers_.astype(x_np.dtype)      # Call host function     centroids = jax.pure_callback(         _kmeans_host_fn,         jax.ShapeDtypeStruct((num_centroids, descriptor_size), x.dtype),         x,         seed,     )      # Rescale     return descriptor_min + (descriptor_max - descriptor_min) * centroids   def segment_argmax(data, segment_ids, num_segments):     \"\"\"Compute the argmax of data for each segment.\"\"\"     return jnp.argmax(         jax.vmap(lambda i: jnp.where(i == segment_ids, data, -jnp.inf))(             jnp.arange(num_segments)         ),         axis=1,     ) In\u00a0[\u00a0]: Copied! <pre>def map_elites_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n) -&gt; Fitness:\n    \"\"\"Grid Fitness.\"\"\"\n    centroids = state.centroids\n\n    # Get centroid assignments\n    centroid_indices = get_centroid_indices(descriptor, centroids)\n    num_centroids = centroids.shape[0]\n    best_index_per_centroid = segment_argmax(fitness, centroid_indices, num_centroids)\n\n    # Check which centroids have assigned individuals\n    centroid_assigned = jnp.isin(jnp.arange(num_centroids), centroid_indices)\n\n    # Handle empty centroids to avoid collision at index 0\n    best_index_per_centroid = jnp.where(\n        centroid_assigned,\n        best_index_per_centroid,\n        fitness.shape[0],  # if centroid not used, put the best index out of bounds\n    )\n\n    # Create mask for individuals that are the best in their assigned cell\n    best_index = (\n        jnp.zeros_like(fitness, dtype=bool).at[best_index_per_centroid].set(True)\n    )\n\n    return jnp.where(best_index, fitness, -jnp.inf)\n</pre> def map_elites_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams, ) -&gt; Fitness:     \"\"\"Grid Fitness.\"\"\"     centroids = state.centroids      # Get centroid assignments     centroid_indices = get_centroid_indices(descriptor, centroids)     num_centroids = centroids.shape[0]     best_index_per_centroid = segment_argmax(fitness, centroid_indices, num_centroids)      # Check which centroids have assigned individuals     centroid_assigned = jnp.isin(jnp.arange(num_centroids), centroid_indices)      # Handle empty centroids to avoid collision at index 0     best_index_per_centroid = jnp.where(         centroid_assigned,         best_index_per_centroid,         fitness.shape[0],  # if centroid not used, put the best index out of bounds     )      # Create mask for individuals that are the best in their assigned cell     best_index = (         jnp.zeros_like(fitness, dtype=bool).at[best_index_per_centroid].set(True)     )      return jnp.where(best_index, fitness, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>@flax.struct.dataclass\nclass MAPElitesState(QDState):\n    \"\"\"State for MAP-Elites algorithm.\"\"\"\n\n    centroids: Centroid\n\n\nclass MAPElites(QDAlgorithm):\n    \"\"\"MAP-Elites Algorithm.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        descriptor_size: int,\n        descriptor_min: float | list[float],\n        descriptor_max: float | list[float],\n        num_init_cvt_samples: int = 10000,\n    ):\n        \"\"\"Initialize MAP-Elites.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=map_elites_fitness_shaping,\n            descriptor_size=descriptor_size,\n        )\n        self.descriptor_min = descriptor_min\n        self.descriptor_max = descriptor_max\n        self.num_init_cvt_samples = num_init_cvt_samples\n\n    def _init(self, key: RNGKey, params: QDParams) -&gt; MAPElitesState:\n        genotype = jax.tree.map(\n            lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),\n            self.solution,\n        )\n        fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)\n        descriptor = jnp.full(\n            (self.population_size, self.descriptor_size), fill_value=jnp.nan\n        )\n\n        centroids = get_centroids(\n            num_centroids=self.population_size,\n            descriptor_size=self.descriptor_size,\n            descriptor_min=self.descriptor_min,\n            descriptor_max=self.descriptor_max,\n            num_init_cvt_samples=self.num_init_cvt_samples,\n            key=key,\n        )\n\n        state = MAPElitesState(\n            population=genotype,\n            fitness=fitness,\n            descriptor=descriptor,\n            centroids=centroids,\n            generation_counter=0,\n        )\n        return state\n</pre> @flax.struct.dataclass class MAPElitesState(QDState):     \"\"\"State for MAP-Elites algorithm.\"\"\"      centroids: Centroid   class MAPElites(QDAlgorithm):     \"\"\"MAP-Elites Algorithm.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         descriptor_size: int,         descriptor_min: float | list[float],         descriptor_max: float | list[float],         num_init_cvt_samples: int = 10000,     ):         \"\"\"Initialize MAP-Elites.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=map_elites_fitness_shaping,             descriptor_size=descriptor_size,         )         self.descriptor_min = descriptor_min         self.descriptor_max = descriptor_max         self.num_init_cvt_samples = num_init_cvt_samples      def _init(self, key: RNGKey, params: QDParams) -&gt; MAPElitesState:         genotype = jax.tree.map(             lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),             self.solution,         )         fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)         descriptor = jnp.full(             (self.population_size, self.descriptor_size), fill_value=jnp.nan         )          centroids = get_centroids(             num_centroids=self.population_size,             descriptor_size=self.descriptor_size,             descriptor_min=self.descriptor_min,             descriptor_max=self.descriptor_max,             num_init_cvt_samples=self.num_init_cvt_samples,             key=key,         )          state = MAPElitesState(             population=genotype,             fitness=fitness,             descriptor=descriptor,             centroids=centroids,             generation_counter=0,         )         return state In\u00a0[\u00a0]: Copied! <pre>from bbobax import QDBBOB\nfrom bbobax.descriptor_fns import get_random_projection_descriptor\nfrom bbobax.fitness_fns import bbob_fns\n\n# Configuration\nseed = 1\npop_size = 1024\nnum_generations = 100\ndim = 2\n\n# Setup Task\nbbob = QDBBOB(\n    min_num_dims=dim,\n    max_num_dims=dim,\n    fitness_fns=[bbob_fns[\"sphere\"]],\n    descriptor_fns=[get_random_projection_descriptor()],\n    descriptor_size=2,\n)\n\nkey = jax.random.key(seed)\nkey_bbob, key_init, key_qd, key_pop = jax.random.split(key, 4)\n\nbbob_params = bbob.sample(key_bbob)\nbbob_state = bbob.init(key_init, bbob_params)\n\n# Solution template\nsolution_template = jnp.zeros((dim,))\n\n# Sample initial population from task\nkeys = jax.random.split(key_pop, pop_size)\ninitial_population = jax.vmap(bbob.sample_x)(keys)\n\n# Evaluate initial population to get fitness/descriptor for init\nfitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None))\neval_keys = jax.random.split(key_pop, pop_size)\n\nbbob_state_batch, bbob_eval = fitness_fn(\n    eval_keys, initial_population, bbob_state, bbob_params\n)\nbbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)\n\n# Algorithms to test\nalgorithms = {\n    \"Random\": RandomSearch(pop_size, solution_template),\n    \"GA\": GeneticAlgorithm(pop_size, solution_template),\n    \"NoveltySearch\": NoveltySearch(pop_size, solution_template),\n    \"DominatedNoveltySearch\": DominatedNoveltySearch(pop_size, solution_template),\n    \"MAP-Elites\": MAPElites(\n        pop_size,\n        solution_template,\n        descriptor_size=2,\n        descriptor_min=[-3.0, -3.0],\n        descriptor_max=[3.0, 3.0],\n    ),\n}\n\nprint(f\"Starting benchmark on Sphere (dim={dim}) for {num_generations} generations...\")\n\nfor name, qd in algorithms.items():\n    print(f\"\\n--- {name} ---\")\n\n    # Init Algorithm\n    qd_params = qd.default_params\n\n    # Initialize with the sampled population\n    qd_state = qd.init(\n        key_qd,\n        population=initial_population,\n        fitness=-bbob_eval.fitness,\n        descriptor=bbob_eval.descriptor,\n        params=qd_params,\n    )\n\n    # Loop\n    for gen in range(num_generations):\n        key_qd, key_ask, key_eval, key_tell = jax.random.split(key_qd, 4)\n\n        # Ask\n        population, qd_state = qd.ask(key_ask, qd_state, qd_params)\n\n        # Evaluate\n        eval_keys = jax.random.split(key_eval, pop_size)\n        bbob_state_batch, bbob_eval_gen = fitness_fn(\n            eval_keys, population, bbob_state, bbob_params\n        )\n        bbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)\n\n        # Tell\n        qd_state, metrics = qd.tell(\n            key_tell,\n            population,\n            -bbob_eval_gen.fitness,\n            bbob_eval_gen.descriptor,\n            qd_state,\n            qd_params,\n        )\n\n        if gen % 20 == 0:\n            # Aggregate metrics for display\n            agg = metrics_agg_fn(metrics)\n            print(\n                f\"Generation {gen:03d}: \"\n                f\"population_size={agg['population_size']:.0f}, \"\n                f\"fitness_max={agg['fitness_max']:.4f}, \"\n                f\"novelty_mean={agg['novelty_mean']:.4f}, \"\n                f\"dominated_novelty_mean={agg['dominated_novelty_mean']:.4f}\"\n            )\n</pre> from bbobax import QDBBOB from bbobax.descriptor_fns import get_random_projection_descriptor from bbobax.fitness_fns import bbob_fns  # Configuration seed = 1 pop_size = 1024 num_generations = 100 dim = 2  # Setup Task bbob = QDBBOB(     min_num_dims=dim,     max_num_dims=dim,     fitness_fns=[bbob_fns[\"sphere\"]],     descriptor_fns=[get_random_projection_descriptor()],     descriptor_size=2, )  key = jax.random.key(seed) key_bbob, key_init, key_qd, key_pop = jax.random.split(key, 4)  bbob_params = bbob.sample(key_bbob) bbob_state = bbob.init(key_init, bbob_params)  # Solution template solution_template = jnp.zeros((dim,))  # Sample initial population from task keys = jax.random.split(key_pop, pop_size) initial_population = jax.vmap(bbob.sample_x)(keys)  # Evaluate initial population to get fitness/descriptor for init fitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None)) eval_keys = jax.random.split(key_pop, pop_size)  bbob_state_batch, bbob_eval = fitness_fn(     eval_keys, initial_population, bbob_state, bbob_params ) bbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)  # Algorithms to test algorithms = {     \"Random\": RandomSearch(pop_size, solution_template),     \"GA\": GeneticAlgorithm(pop_size, solution_template),     \"NoveltySearch\": NoveltySearch(pop_size, solution_template),     \"DominatedNoveltySearch\": DominatedNoveltySearch(pop_size, solution_template),     \"MAP-Elites\": MAPElites(         pop_size,         solution_template,         descriptor_size=2,         descriptor_min=[-3.0, -3.0],         descriptor_max=[3.0, 3.0],     ), }  print(f\"Starting benchmark on Sphere (dim={dim}) for {num_generations} generations...\")  for name, qd in algorithms.items():     print(f\"\\n--- {name} ---\")      # Init Algorithm     qd_params = qd.default_params      # Initialize with the sampled population     qd_state = qd.init(         key_qd,         population=initial_population,         fitness=-bbob_eval.fitness,         descriptor=bbob_eval.descriptor,         params=qd_params,     )      # Loop     for gen in range(num_generations):         key_qd, key_ask, key_eval, key_tell = jax.random.split(key_qd, 4)          # Ask         population, qd_state = qd.ask(key_ask, qd_state, qd_params)          # Evaluate         eval_keys = jax.random.split(key_eval, pop_size)         bbob_state_batch, bbob_eval_gen = fitness_fn(             eval_keys, population, bbob_state, bbob_params         )         bbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)          # Tell         qd_state, metrics = qd.tell(             key_tell,             population,             -bbob_eval_gen.fitness,             bbob_eval_gen.descriptor,             qd_state,             qd_params,         )          if gen % 20 == 0:             # Aggregate metrics for display             agg = metrics_agg_fn(metrics)             print(                 f\"Generation {gen:03d}: \"                 f\"population_size={agg['population_size']:.0f}, \"                 f\"fitness_max={agg['fitness_max']:.4f}, \"                 f\"novelty_mean={agg['novelty_mean']:.4f}, \"                 f\"dominated_novelty_mean={agg['dominated_novelty_mean']:.4f}\"             )"},{"location":"notebooks/04_qd/#quality-diversity","title":"Quality-Diversity \u00b6","text":""},{"location":"notebooks/04_qd/#install","title":"Install\u00b6","text":""},{"location":"notebooks/04_qd/#import","title":"Import\u00b6","text":""},{"location":"notebooks/04_qd/#metrics","title":"Metrics\u00b6","text":""},{"location":"notebooks/04_qd/#algorithms","title":"Algorithms\u00b6","text":""},{"location":"notebooks/04_qd/#random-search","title":"Random Search\u00b6","text":""},{"location":"notebooks/04_qd/#genetic-algorithm","title":"Genetic Algorithm\u00b6","text":""},{"location":"notebooks/04_qd/#novelty-search","title":"Novelty Search\u00b6","text":""},{"location":"notebooks/04_qd/#dominated-novelty-search","title":"Dominated Novelty Search\u00b6","text":""},{"location":"notebooks/04_qd/#map-elites","title":"MAP-Elites\u00b6","text":""},{"location":"notebooks/04_qd/#grid-helpers","title":"Grid helpers\u00b6","text":""},{"location":"notebooks/04_qd/#run","title":"Run\u00b6","text":""},{"location":"notebooks/qd/","title":"Qd","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Quality-Diversity Algorithms.\"\"\"\n</pre> \"\"\"Quality-Diversity Algorithms.\"\"\" In\u00a0[\u00a0]: Copied! <pre>from functools import partial\nfrom typing import Any\n</pre> from functools import partial from typing import Any In\u00a0[\u00a0]: Copied! <pre>import flax.struct\nimport jax\nimport jax.numpy as jnp\nfrom numpy.random import RandomState\nfrom sklearn.cluster import KMeans\n</pre> import flax.struct import jax import jax.numpy as jnp from numpy.random import RandomState from sklearn.cluster import KMeans In\u00a0[\u00a0]: Copied! <pre># Types\ntype Genotype = Any\ntype Fitness = jax.Array\ntype Descriptor = jax.Array\ntype RNGKey = jax.Array\ntype Centroid = jax.Array\n</pre> # Types type Genotype = Any type Fitness = jax.Array type Descriptor = jax.Array type RNGKey = jax.Array type Centroid = jax.Array In\u00a0[\u00a0]: Copied! <pre># --- Metrics ---\ndef novelty_and_dominated_novelty(\n    fitness, descriptor, novelty_k=3, dominated_novelty_k=3\n):\n    \"\"\"Compute novelty and dominated novelty.\"\"\"\n    valid = fitness != -jnp.inf\n\n    # Neighbors\n    neighbor = valid[:, None] &amp; valid[None, :]\n    neighbor = jnp.fill_diagonal(neighbor, False, inplace=False)\n\n    # Fitter\n    fitter = fitness[:, None] &lt;= fitness[None, :]\n    fitter = jnp.where(neighbor, fitter, False)\n\n    # Distance to neighbors\n    distance = jnp.linalg.norm(descriptor[:, None, :] - descriptor[None, :, :], axis=-1)\n    distance = jnp.where(neighbor, distance, jnp.inf)\n\n    # Distance to fitter neighbors\n    distance_fitter = jnp.where(fitter, distance, jnp.inf)\n\n    # Novelty - distance to k-nearest neighbors\n    values, indices = jax.vmap(partial(jax.lax.top_k, k=novelty_k))(-distance)\n    novelty = jnp.mean(\n        -values, axis=-1, where=jnp.take_along_axis(neighbor, indices, axis=-1)\n    )\n\n    # Dominated Novelty - distance to k-fitter-nearest neighbors\n    values, indices = jax.vmap(partial(jax.lax.top_k, k=dominated_novelty_k))(\n        -distance_fitter\n    )\n    dominated_novelty = jnp.mean(\n        -values, axis=-1, where=jnp.take_along_axis(fitter, indices, axis=-1)\n    )  # only max fitness individual should be nan\n\n    return novelty, dominated_novelty\n</pre> # --- Metrics --- def novelty_and_dominated_novelty(     fitness, descriptor, novelty_k=3, dominated_novelty_k=3 ):     \"\"\"Compute novelty and dominated novelty.\"\"\"     valid = fitness != -jnp.inf      # Neighbors     neighbor = valid[:, None] &amp; valid[None, :]     neighbor = jnp.fill_diagonal(neighbor, False, inplace=False)      # Fitter     fitter = fitness[:, None] &lt;= fitness[None, :]     fitter = jnp.where(neighbor, fitter, False)      # Distance to neighbors     distance = jnp.linalg.norm(descriptor[:, None, :] - descriptor[None, :, :], axis=-1)     distance = jnp.where(neighbor, distance, jnp.inf)      # Distance to fitter neighbors     distance_fitter = jnp.where(fitter, distance, jnp.inf)      # Novelty - distance to k-nearest neighbors     values, indices = jax.vmap(partial(jax.lax.top_k, k=novelty_k))(-distance)     novelty = jnp.mean(         -values, axis=-1, where=jnp.take_along_axis(neighbor, indices, axis=-1)     )      # Dominated Novelty - distance to k-fitter-nearest neighbors     values, indices = jax.vmap(partial(jax.lax.top_k, k=dominated_novelty_k))(         -distance_fitter     )     dominated_novelty = jnp.mean(         -values, axis=-1, where=jnp.take_along_axis(fitter, indices, axis=-1)     )  # only max fitness individual should be nan      return novelty, dominated_novelty In\u00a0[\u00a0]: Copied! <pre>def metrics_fn(\n    key: RNGKey,\n    population: Genotype,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: \"QDState\",\n    params: \"QDParams\",\n) -&gt; dict:\n    \"\"\"Compute QD metrics.\"\"\"\n    k = 3\n    novelty, dominated_novelty = novelty_and_dominated_novelty(\n        fitness,\n        descriptor,\n        novelty_k=k,\n        dominated_novelty_k=k,\n    )\n    dominated_novelty = jnp.where(\n        jnp.isposinf(dominated_novelty), jnp.nan, dominated_novelty\n    )\n\n    return {\n        \"fitness\": fitness,\n        \"descriptor\": descriptor,\n        \"novelty\": novelty,\n        \"dominated_novelty\": dominated_novelty,\n    }\n</pre> def metrics_fn(     key: RNGKey,     population: Genotype,     fitness: Fitness,     descriptor: Descriptor,     state: \"QDState\",     params: \"QDParams\", ) -&gt; dict:     \"\"\"Compute QD metrics.\"\"\"     k = 3     novelty, dominated_novelty = novelty_and_dominated_novelty(         fitness,         descriptor,         novelty_k=k,         dominated_novelty_k=k,     )     dominated_novelty = jnp.where(         jnp.isposinf(dominated_novelty), jnp.nan, dominated_novelty     )      return {         \"fitness\": fitness,         \"descriptor\": descriptor,         \"novelty\": novelty,         \"dominated_novelty\": dominated_novelty,     } In\u00a0[\u00a0]: Copied! <pre>@jax.jit\ndef metrics_agg_fn(metrics: dict) -&gt; dict:\n    \"\"\"Aggregate QD metrics.\"\"\"\n    valid = metrics[\"fitness\"] != -jnp.inf\n\n    descriptor_mean = jnp.mean(metrics[\"descriptor\"], axis=-2, where=valid[..., None])\n    distance_to_mean = jnp.linalg.norm(\n        metrics[\"descriptor\"] - descriptor_mean[..., None, :], axis=-1\n    )\n    descriptor_std = jnp.std(distance_to_mean, axis=-1, where=valid)\n\n    return {\n        \"population_size\": jnp.sum(valid, axis=-1),\n        \"fitness_max\": jnp.max(\n            metrics[\"fitness\"], axis=-1, initial=-jnp.inf, where=valid\n        ),\n        \"fitness_mean\": jnp.mean(metrics[\"fitness\"], axis=-1, where=valid),\n        \"novelty_mean\": jnp.mean(metrics[\"novelty\"], axis=-1, where=valid),\n        \"dominated_novelty_mean\": jnp.nanmean(\n            metrics[\"dominated_novelty\"], axis=-1, where=valid\n        ),\n        \"descriptor_std\": descriptor_std,\n    }\n</pre> @jax.jit def metrics_agg_fn(metrics: dict) -&gt; dict:     \"\"\"Aggregate QD metrics.\"\"\"     valid = metrics[\"fitness\"] != -jnp.inf      descriptor_mean = jnp.mean(metrics[\"descriptor\"], axis=-2, where=valid[..., None])     distance_to_mean = jnp.linalg.norm(         metrics[\"descriptor\"] - descriptor_mean[..., None, :], axis=-1     )     descriptor_std = jnp.std(distance_to_mean, axis=-1, where=valid)      return {         \"population_size\": jnp.sum(valid, axis=-1),         \"fitness_max\": jnp.max(             metrics[\"fitness\"], axis=-1, initial=-jnp.inf, where=valid         ),         \"fitness_mean\": jnp.mean(metrics[\"fitness\"], axis=-1, where=valid),         \"novelty_mean\": jnp.mean(metrics[\"novelty\"], axis=-1, where=valid),         \"dominated_novelty_mean\": jnp.nanmean(             metrics[\"dominated_novelty\"], axis=-1, where=valid         ),         \"descriptor_std\": descriptor_std,     } In\u00a0[\u00a0]: Copied! <pre># --- QD Algorithm ---\n@flax.struct.dataclass\nclass QDState:\n    \"\"\"State for QD algorithms.\"\"\"\n\n    population: Genotype\n    fitness: Fitness\n    descriptor: Descriptor\n\n    generation_counter: int\n</pre> # --- QD Algorithm --- @flax.struct.dataclass class QDState:     \"\"\"State for QD algorithms.\"\"\"      population: Genotype     fitness: Fitness     descriptor: Descriptor      generation_counter: int In\u00a0[\u00a0]: Copied! <pre>@flax.struct.dataclass\nclass QDParams:\n    \"\"\"Parameters for QD algorithms.\"\"\"\n\n    mutation_sigma: float = 0.1\n</pre> @flax.struct.dataclass class QDParams:     \"\"\"Parameters for QD algorithms.\"\"\"      mutation_sigma: float = 0.1 In\u00a0[\u00a0]: Copied! <pre>def gaussian_mutation(key: RNGKey, genotype: Genotype, sigma: float) -&gt; Genotype:\n    \"\"\"Apply Gaussian mutation to the genotype.\"\"\"\n    return jax.tree.map(lambda x: x + sigma * jax.random.normal(key, x.shape), genotype)\n</pre> def gaussian_mutation(key: RNGKey, genotype: Genotype, sigma: float) -&gt; Genotype:     \"\"\"Apply Gaussian mutation to the genotype.\"\"\"     return jax.tree.map(lambda x: x + sigma * jax.random.normal(key, x.shape), genotype) In\u00a0[\u00a0]: Copied! <pre>class QDAlgorithm:\n    \"\"\"Base class for Quality-Diversity algorithms.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        fitness_shaping_fn,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize the QD Algorithm.\"\"\"\n        self.population_size = population_size\n        self.solution = solution\n        self.fitness_shaping_fn = fitness_shaping_fn\n        self.metrics_fn = metrics_fn\n        self.descriptor_size = descriptor_size\n\n    @partial(jax.jit, static_argnames=(\"self\",))\n    def init(\n        self,\n        key: jax.Array,\n        population: Genotype,\n        fitness: Fitness,\n        descriptor: Descriptor,\n        params: QDParams,\n    ) -&gt; QDState:\n        \"\"\"Initialize evolutionary algorithm.\"\"\"\n        state = self._init(key, params)\n        state, _ = self.tell(key, population, fitness, descriptor, state, params)\n        return state\n\n    @partial(jax.jit, static_argnames=(\"self\",))\n    def ask(\n        self,\n        key: jax.Array,\n        state: QDState,\n        params: QDParams,\n    ) -&gt; tuple[Genotype, QDState]:\n        \"\"\"Ask evolutionary algorithm for new candidate solutions.\"\"\"\n        return self._ask(key, state, params)\n\n    @property\n    def default_params(self) -&gt; QDParams:\n        \"\"\"Return default parameters for the algorithm.\"\"\"\n        return QDParams()\n\n    def tell(\n        self,\n        key: RNGKey,\n        population: Genotype,\n        fitness: Fitness,\n        descriptor: Descriptor,\n        state: QDState,\n        params: QDParams,\n    ) -&gt; tuple[QDState, dict]:\n        \"\"\"Tell Fitness and Descriptors.\"\"\"\n        # Concatenate\n        all_genotype = jax.tree.map(\n            lambda x, y: jnp.concatenate([x, y], axis=0),\n            state.population,\n            population,\n        )\n        all_fitness = jnp.concatenate([state.fitness, fitness], axis=0)\n        all_descriptor = jnp.concatenate([state.descriptor, descriptor], axis=0)\n\n        # Compute competition fitness\n        key_shaping, key_metrics = jax.random.split(key)\n        shaped_fitness = self.fitness_shaping_fn(\n            key_shaping,\n            all_fitness,\n            all_descriptor,\n            state,\n            params,\n        )\n\n        # Sort by competition fitness\n        indices = jnp.argsort(shaped_fitness, descending=True)\n        indices = indices[: self.population_size]\n\n        # Keep best\n        new_genotype = jax.tree.map(lambda x: x[indices], all_genotype)\n        new_fitness = all_fitness[indices]\n        new_descriptor = all_descriptor[indices]\n\n        # Mark invalid individuals as -inf\n        is_valid = shaped_fitness[indices] != -jnp.inf\n        new_fitness = jnp.where(is_valid, new_fitness, -jnp.inf)\n        new_descriptor = jnp.where(is_valid[:, None], new_descriptor, jnp.nan)\n\n        state = state.replace(\n            population=new_genotype,\n            fitness=new_fitness,\n            descriptor=new_descriptor,\n            generation_counter=state.generation_counter + 1,\n        )\n\n        # Metrics\n        metrics = self.metrics_fn(\n            key_metrics,\n            state.population,\n            state.fitness,\n            state.descriptor,\n            state,\n            params,\n        )\n        metrics[\"generation\"] = state.generation_counter\n\n        return state, metrics\n\n    def _init(self, key: RNGKey, params: QDParams) -&gt; QDState:\n        genotype = jax.tree.map(\n            lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),\n            self.solution,\n        )\n        fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)\n        descriptor = jnp.full(\n            (self.population_size, self.descriptor_size), fill_value=jnp.nan\n        )\n\n        state = QDState(\n            population=genotype,\n            fitness=fitness,\n            descriptor=descriptor,\n            generation_counter=0,\n        )\n        return state\n\n    def _ask(\n        self, key: RNGKey, state: QDState, params: QDParams\n    ) -&gt; tuple[Genotype, QDState]:\n        \"\"\"Ask for new candidate solutions.\"\"\"\n        # Simple Selection -&gt; Mutation\n        valid = state.fitness != -jnp.inf\n\n        p = valid / jnp.sum(valid)\n        p = jnp.where(jnp.isnan(p), 1.0 / self.population_size, p)\n\n        population = jax.tree.map(\n            lambda x: jax.random.choice(key, x, shape=(self.population_size,), p=p),\n            state.population,\n        )\n\n        population = gaussian_mutation(key, population, params.mutation_sigma)\n\n        return population, state\n</pre> class QDAlgorithm:     \"\"\"Base class for Quality-Diversity algorithms.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         fitness_shaping_fn,         descriptor_size: int = 2,     ):         \"\"\"Initialize the QD Algorithm.\"\"\"         self.population_size = population_size         self.solution = solution         self.fitness_shaping_fn = fitness_shaping_fn         self.metrics_fn = metrics_fn         self.descriptor_size = descriptor_size      @partial(jax.jit, static_argnames=(\"self\",))     def init(         self,         key: jax.Array,         population: Genotype,         fitness: Fitness,         descriptor: Descriptor,         params: QDParams,     ) -&gt; QDState:         \"\"\"Initialize evolutionary algorithm.\"\"\"         state = self._init(key, params)         state, _ = self.tell(key, population, fitness, descriptor, state, params)         return state      @partial(jax.jit, static_argnames=(\"self\",))     def ask(         self,         key: jax.Array,         state: QDState,         params: QDParams,     ) -&gt; tuple[Genotype, QDState]:         \"\"\"Ask evolutionary algorithm for new candidate solutions.\"\"\"         return self._ask(key, state, params)      @property     def default_params(self) -&gt; QDParams:         \"\"\"Return default parameters for the algorithm.\"\"\"         return QDParams()      def tell(         self,         key: RNGKey,         population: Genotype,         fitness: Fitness,         descriptor: Descriptor,         state: QDState,         params: QDParams,     ) -&gt; tuple[QDState, dict]:         \"\"\"Tell Fitness and Descriptors.\"\"\"         # Concatenate         all_genotype = jax.tree.map(             lambda x, y: jnp.concatenate([x, y], axis=0),             state.population,             population,         )         all_fitness = jnp.concatenate([state.fitness, fitness], axis=0)         all_descriptor = jnp.concatenate([state.descriptor, descriptor], axis=0)          # Compute competition fitness         key_shaping, key_metrics = jax.random.split(key)         shaped_fitness = self.fitness_shaping_fn(             key_shaping,             all_fitness,             all_descriptor,             state,             params,         )          # Sort by competition fitness         indices = jnp.argsort(shaped_fitness, descending=True)         indices = indices[: self.population_size]          # Keep best         new_genotype = jax.tree.map(lambda x: x[indices], all_genotype)         new_fitness = all_fitness[indices]         new_descriptor = all_descriptor[indices]          # Mark invalid individuals as -inf         is_valid = shaped_fitness[indices] != -jnp.inf         new_fitness = jnp.where(is_valid, new_fitness, -jnp.inf)         new_descriptor = jnp.where(is_valid[:, None], new_descriptor, jnp.nan)          state = state.replace(             population=new_genotype,             fitness=new_fitness,             descriptor=new_descriptor,             generation_counter=state.generation_counter + 1,         )          # Metrics         metrics = self.metrics_fn(             key_metrics,             state.population,             state.fitness,             state.descriptor,             state,             params,         )         metrics[\"generation\"] = state.generation_counter          return state, metrics      def _init(self, key: RNGKey, params: QDParams) -&gt; QDState:         genotype = jax.tree.map(             lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),             self.solution,         )         fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)         descriptor = jnp.full(             (self.population_size, self.descriptor_size), fill_value=jnp.nan         )          state = QDState(             population=genotype,             fitness=fitness,             descriptor=descriptor,             generation_counter=0,         )         return state      def _ask(         self, key: RNGKey, state: QDState, params: QDParams     ) -&gt; tuple[Genotype, QDState]:         \"\"\"Ask for new candidate solutions.\"\"\"         # Simple Selection -&gt; Mutation         valid = state.fitness != -jnp.inf          p = valid / jnp.sum(valid)         p = jnp.where(jnp.isnan(p), 1.0 / self.population_size, p)          population = jax.tree.map(             lambda x: jax.random.choice(key, x, shape=(self.population_size,), p=p),             state.population,         )          population = gaussian_mutation(key, population, params.mutation_sigma)          return population, state In\u00a0[\u00a0]: Copied! <pre># --- Random Search ---\ndef random_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n) -&gt; Fitness:\n    \"\"\"Random Fitness.\"\"\"\n    random_fitness = jax.random.uniform(key, fitness.shape)\n    valid = fitness != -jnp.inf\n    return jnp.where(valid, random_fitness, -jnp.inf)\n</pre> # --- Random Search --- def random_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams, ) -&gt; Fitness:     \"\"\"Random Fitness.\"\"\"     random_fitness = jax.random.uniform(key, fitness.shape)     valid = fitness != -jnp.inf     return jnp.where(valid, random_fitness, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>class RandomSearch(QDAlgorithm):\n    \"\"\"Random Search: replaces individuals randomly.\"\"\"\n\n    def __init__(\n        self, population_size: int, solution: Genotype, descriptor_size: int = 2\n    ):\n        \"\"\"Initialize Random Search.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=random_fitness_shaping,\n            descriptor_size=descriptor_size,\n        )\n</pre> class RandomSearch(QDAlgorithm):     \"\"\"Random Search: replaces individuals randomly.\"\"\"      def __init__(         self, population_size: int, solution: Genotype, descriptor_size: int = 2     ):         \"\"\"Initialize Random Search.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=random_fitness_shaping,             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre># --- Genetic Algorithm ---\ndef identity_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n) -&gt; Fitness:\n    \"\"\"Raw Fitness.\"\"\"\n    return fitness\n</pre> # --- Genetic Algorithm --- def identity_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams, ) -&gt; Fitness:     \"\"\"Raw Fitness.\"\"\"     return fitness In\u00a0[\u00a0]: Copied! <pre>class GeneticAlgorithm(QDAlgorithm):\n    \"\"\"Genetic Algorithm: Standard unstructured population with identity fitness.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        fitness_shaping_fn=identity_fitness_shaping,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize Genetic Algorithm.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=fitness_shaping_fn,\n            descriptor_size=descriptor_size,\n        )\n</pre> class GeneticAlgorithm(QDAlgorithm):     \"\"\"Genetic Algorithm: Standard unstructured population with identity fitness.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         fitness_shaping_fn=identity_fitness_shaping,         descriptor_size: int = 2,     ):         \"\"\"Initialize Genetic Algorithm.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=fitness_shaping_fn,             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre># --- Novelty Search ---\ndef novelty_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n    novelty_k: int = 3,\n) -&gt; Fitness:\n    \"\"\"Novelty Score.\"\"\"\n    novelty, _ = novelty_and_dominated_novelty(\n        fitness,\n        descriptor,\n        novelty_k=novelty_k,\n    )\n    valid = fitness != -jnp.inf\n    return jnp.where(valid, novelty, -jnp.inf)\n</pre> # --- Novelty Search --- def novelty_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams,     novelty_k: int = 3, ) -&gt; Fitness:     \"\"\"Novelty Score.\"\"\"     novelty, _ = novelty_and_dominated_novelty(         fitness,         descriptor,         novelty_k=novelty_k,     )     valid = fitness != -jnp.inf     return jnp.where(valid, novelty, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>class NoveltySearch(QDAlgorithm):\n    \"\"\"Novelty Search Algorithm.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        novelty_k: int = 3,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize Novelty Search.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=partial(novelty_fitness_shaping, novelty_k=novelty_k),\n            descriptor_size=descriptor_size,\n        )\n</pre> class NoveltySearch(QDAlgorithm):     \"\"\"Novelty Search Algorithm.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         novelty_k: int = 3,         descriptor_size: int = 2,     ):         \"\"\"Initialize Novelty Search.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=partial(novelty_fitness_shaping, novelty_k=novelty_k),             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre># --- Dominated Novelty Search ---\ndef dominated_novelty_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n    novelty_k: int = 3,\n) -&gt; Fitness:\n    \"\"\"Dominated Novelty Score.\"\"\"\n    _, dominated_novelty = novelty_and_dominated_novelty(\n        fitness,\n        descriptor,\n        dominated_novelty_k=novelty_k,\n    )\n    valid = fitness != -jnp.inf\n    return jnp.where(valid, dominated_novelty, -jnp.inf)\n</pre> # --- Dominated Novelty Search --- def dominated_novelty_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams,     novelty_k: int = 3, ) -&gt; Fitness:     \"\"\"Dominated Novelty Score.\"\"\"     _, dominated_novelty = novelty_and_dominated_novelty(         fitness,         descriptor,         dominated_novelty_k=novelty_k,     )     valid = fitness != -jnp.inf     return jnp.where(valid, dominated_novelty, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>class DominatedNoveltySearch(QDAlgorithm):\n    \"\"\"Dominated Novelty Search Algorithm.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        novelty_k: int = 3,\n        descriptor_size: int = 2,\n    ):\n        \"\"\"Initialize Dominated Novelty Search.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=partial(\n                dominated_novelty_fitness_shaping, novelty_k=novelty_k\n            ),\n            descriptor_size=descriptor_size,\n        )\n</pre> class DominatedNoveltySearch(QDAlgorithm):     \"\"\"Dominated Novelty Search Algorithm.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         novelty_k: int = 3,         descriptor_size: int = 2,     ):         \"\"\"Initialize Dominated Novelty Search.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=partial(                 dominated_novelty_fitness_shaping, novelty_k=novelty_k             ),             descriptor_size=descriptor_size,         ) In\u00a0[\u00a0]: Copied! <pre># --- MAP-Elites ---\ndef get_centroid_indices(descriptors: Descriptor, centroids: Centroid) -&gt; jax.Array:\n    \"\"\"Assign descriptors to their closest centroid and return centroid indices.\"\"\"\n\n    def _get_centroid_indices(descriptor: Descriptor) -&gt; jax.Array:\n        return jnp.argmin(jnp.linalg.norm(descriptor - centroids, axis=-1))\n\n    indices = jax.vmap(_get_centroid_indices)(descriptors)\n    return indices\n</pre> # --- MAP-Elites --- def get_centroid_indices(descriptors: Descriptor, centroids: Centroid) -&gt; jax.Array:     \"\"\"Assign descriptors to their closest centroid and return centroid indices.\"\"\"      def _get_centroid_indices(descriptor: Descriptor) -&gt; jax.Array:         return jnp.argmin(jnp.linalg.norm(descriptor - centroids, axis=-1))      indices = jax.vmap(_get_centroid_indices)(descriptors)     return indices In\u00a0[\u00a0]: Copied! <pre>def get_centroids(\n    num_centroids: int,\n    descriptor_size: int,\n    descriptor_min: float | list[float],\n    descriptor_max: float | list[float],\n    num_init_cvt_samples: int,\n    key: RNGKey,\n) -&gt; jax.Array:\n    \"\"\"Compute centroids using CVT (Centroidal Voronoi Tessellation).\"\"\"\n    descriptor_min = jnp.array(descriptor_min)\n    descriptor_max = jnp.array(descriptor_max)\n\n    # Sample x uniformly in [0, 1]\n    key_x, key_kmeans = jax.random.split(key)\n    x = jax.random.uniform(key_x, (num_init_cvt_samples, descriptor_size))\n\n    # Generate an integer seed for RandomState\n    seed = jax.random.randint(key_kmeans, (), 0, 2**30, dtype=jnp.int32)\n\n    def _kmeans_host_fn(x_np, seed_np):\n        rs = RandomState(int(seed_np))\n        kmeans = KMeans(\n            init=\"k-means++\",\n            n_clusters=num_centroids,\n            n_init=1,\n            random_state=rs,\n        )\n        kmeans.fit(x_np)\n        return kmeans.cluster_centers_.astype(x_np.dtype)\n\n    # Call host function\n    centroids = jax.pure_callback(\n        _kmeans_host_fn,\n        jax.ShapeDtypeStruct((num_centroids, descriptor_size), x.dtype),\n        x,\n        seed,\n    )\n\n    # Rescale\n    return descriptor_min + (descriptor_max - descriptor_min) * centroids\n</pre> def get_centroids(     num_centroids: int,     descriptor_size: int,     descriptor_min: float | list[float],     descriptor_max: float | list[float],     num_init_cvt_samples: int,     key: RNGKey, ) -&gt; jax.Array:     \"\"\"Compute centroids using CVT (Centroidal Voronoi Tessellation).\"\"\"     descriptor_min = jnp.array(descriptor_min)     descriptor_max = jnp.array(descriptor_max)      # Sample x uniformly in [0, 1]     key_x, key_kmeans = jax.random.split(key)     x = jax.random.uniform(key_x, (num_init_cvt_samples, descriptor_size))      # Generate an integer seed for RandomState     seed = jax.random.randint(key_kmeans, (), 0, 2**30, dtype=jnp.int32)      def _kmeans_host_fn(x_np, seed_np):         rs = RandomState(int(seed_np))         kmeans = KMeans(             init=\"k-means++\",             n_clusters=num_centroids,             n_init=1,             random_state=rs,         )         kmeans.fit(x_np)         return kmeans.cluster_centers_.astype(x_np.dtype)      # Call host function     centroids = jax.pure_callback(         _kmeans_host_fn,         jax.ShapeDtypeStruct((num_centroids, descriptor_size), x.dtype),         x,         seed,     )      # Rescale     return descriptor_min + (descriptor_max - descriptor_min) * centroids In\u00a0[\u00a0]: Copied! <pre>def segment_argmax(data, segment_ids, num_segments):\n    \"\"\"Compute the argmax of data for each segment.\"\"\"\n    return jnp.argmax(\n        jax.vmap(lambda i: jnp.where(i == segment_ids, data, -jnp.inf))(\n            jnp.arange(num_segments)\n        ),\n        axis=1,\n    )\n</pre> def segment_argmax(data, segment_ids, num_segments):     \"\"\"Compute the argmax of data for each segment.\"\"\"     return jnp.argmax(         jax.vmap(lambda i: jnp.where(i == segment_ids, data, -jnp.inf))(             jnp.arange(num_segments)         ),         axis=1,     ) In\u00a0[\u00a0]: Copied! <pre>def map_elites_fitness_shaping(\n    key: RNGKey,\n    fitness: Fitness,\n    descriptor: Descriptor,\n    state: QDState,\n    params: QDParams,\n) -&gt; Fitness:\n    \"\"\"Grid Fitness.\"\"\"\n    centroids = state.centroids\n\n    # Get centroid assignments\n    centroid_indices = get_centroid_indices(descriptor, centroids)\n    num_centroids = centroids.shape[0]\n    best_index_per_centroid = segment_argmax(fitness, centroid_indices, num_centroids)\n\n    # Check which centroids have assigned individuals\n    centroid_assigned = jnp.isin(jnp.arange(num_centroids), centroid_indices)\n\n    # Handle empty centroids to avoid collision at index 0\n    best_index_per_centroid = jnp.where(\n        centroid_assigned,\n        best_index_per_centroid,\n        fitness.shape[0],  # if centroid not used, put the best index out of bounds\n    )\n\n    # Create mask for individuals that are the best in their assigned cell\n    best_index = (\n        jnp.zeros_like(fitness, dtype=bool).at[best_index_per_centroid].set(True)\n    )\n\n    return jnp.where(best_index, fitness, -jnp.inf)\n</pre> def map_elites_fitness_shaping(     key: RNGKey,     fitness: Fitness,     descriptor: Descriptor,     state: QDState,     params: QDParams, ) -&gt; Fitness:     \"\"\"Grid Fitness.\"\"\"     centroids = state.centroids      # Get centroid assignments     centroid_indices = get_centroid_indices(descriptor, centroids)     num_centroids = centroids.shape[0]     best_index_per_centroid = segment_argmax(fitness, centroid_indices, num_centroids)      # Check which centroids have assigned individuals     centroid_assigned = jnp.isin(jnp.arange(num_centroids), centroid_indices)      # Handle empty centroids to avoid collision at index 0     best_index_per_centroid = jnp.where(         centroid_assigned,         best_index_per_centroid,         fitness.shape[0],  # if centroid not used, put the best index out of bounds     )      # Create mask for individuals that are the best in their assigned cell     best_index = (         jnp.zeros_like(fitness, dtype=bool).at[best_index_per_centroid].set(True)     )      return jnp.where(best_index, fitness, -jnp.inf) In\u00a0[\u00a0]: Copied! <pre>@flax.struct.dataclass\nclass MAPElitesState(QDState):\n    \"\"\"State for MAP-Elites algorithm.\"\"\"\n\n    centroids: Centroid\n</pre> @flax.struct.dataclass class MAPElitesState(QDState):     \"\"\"State for MAP-Elites algorithm.\"\"\"      centroids: Centroid In\u00a0[\u00a0]: Copied! <pre>class MAPElites(QDAlgorithm):\n    \"\"\"MAP-Elites Algorithm.\"\"\"\n\n    def __init__(\n        self,\n        population_size: int,\n        solution: Genotype,\n        descriptor_size: int,\n        descriptor_min: float | list[float],\n        descriptor_max: float | list[float],\n        num_init_cvt_samples: int = 10000,\n    ):\n        \"\"\"Initialize MAP-Elites.\"\"\"\n        super().__init__(\n            population_size,\n            solution,\n            fitness_shaping_fn=map_elites_fitness_shaping,\n            descriptor_size=descriptor_size,\n        )\n        self.descriptor_min = descriptor_min\n        self.descriptor_max = descriptor_max\n        self.num_init_cvt_samples = num_init_cvt_samples\n\n    def _init(self, key: RNGKey, params: QDParams) -&gt; MAPElitesState:\n        genotype = jax.tree.map(\n            lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),\n            self.solution,\n        )\n        fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)\n        descriptor = jnp.full(\n            (self.population_size, self.descriptor_size), fill_value=jnp.nan\n        )\n\n        centroids = get_centroids(\n            num_centroids=self.population_size,\n            descriptor_size=self.descriptor_size,\n            descriptor_min=self.descriptor_min,\n            descriptor_max=self.descriptor_max,\n            num_init_cvt_samples=self.num_init_cvt_samples,\n            key=key,\n        )\n\n        state = MAPElitesState(\n            population=genotype,\n            fitness=fitness,\n            descriptor=descriptor,\n            centroids=centroids,\n            generation_counter=0,\n        )\n        return state\n</pre> class MAPElites(QDAlgorithm):     \"\"\"MAP-Elites Algorithm.\"\"\"      def __init__(         self,         population_size: int,         solution: Genotype,         descriptor_size: int,         descriptor_min: float | list[float],         descriptor_max: float | list[float],         num_init_cvt_samples: int = 10000,     ):         \"\"\"Initialize MAP-Elites.\"\"\"         super().__init__(             population_size,             solution,             fitness_shaping_fn=map_elites_fitness_shaping,             descriptor_size=descriptor_size,         )         self.descriptor_min = descriptor_min         self.descriptor_max = descriptor_max         self.num_init_cvt_samples = num_init_cvt_samples      def _init(self, key: RNGKey, params: QDParams) -&gt; MAPElitesState:         genotype = jax.tree.map(             lambda x: jnp.full((self.population_size,) + x.shape, fill_value=jnp.nan),             self.solution,         )         fitness = jnp.full((self.population_size,), fill_value=-jnp.inf)         descriptor = jnp.full(             (self.population_size, self.descriptor_size), fill_value=jnp.nan         )          centroids = get_centroids(             num_centroids=self.population_size,             descriptor_size=self.descriptor_size,             descriptor_min=self.descriptor_min,             descriptor_max=self.descriptor_max,             num_init_cvt_samples=self.num_init_cvt_samples,             key=key,         )          state = MAPElitesState(             population=genotype,             fitness=fitness,             descriptor=descriptor,             centroids=centroids,             generation_counter=0,         )         return state In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    from bbobax import QDBBOB\n    from bbobax.descriptor_fns import get_random_projection_descriptor\n    from bbobax.fitness_fns import bbob_fns\n\n    # Configuration\n    seed = 1\n    pop_size = 1024\n    num_generations = 100\n    dim = 2\n\n    # Setup Task\n    bbob = QDBBOB(\n        min_num_dims=dim,\n        max_num_dims=dim,\n        fitness_fns=[bbob_fns[\"sphere\"]],\n        descriptor_fns=[get_random_projection_descriptor()],\n        descriptor_size=2,\n    )\n\n    key = jax.random.key(seed)\n    key_bbob, key_init, key_qd, key_pop = jax.random.split(key, 4)\n\n    bbob_params = bbob.sample(key_bbob)\n    bbob_state = bbob.init(key_init, bbob_params)\n\n    # Solution template\n    solution_template = jnp.zeros((dim,))\n\n    # Sample initial population from task\n    keys = jax.random.split(key_pop, pop_size)\n    initial_population = jax.vmap(bbob.sample_x)(keys)\n\n    # Evaluate initial population to get fitness/descriptor for init\n    fitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None))\n    eval_keys = jax.random.split(key_pop, pop_size)\n\n    bbob_state_batch, bbob_eval = fitness_fn(\n        eval_keys, initial_population, bbob_state, bbob_params\n    )\n    bbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)\n\n    # Algorithms to test\n    algorithms = {\n        \"Random\": RandomSearch(pop_size, solution_template),\n        \"GA\": GeneticAlgorithm(pop_size, solution_template),\n        \"NoveltySearch\": NoveltySearch(pop_size, solution_template),\n        \"DominatedNoveltySearch\": DominatedNoveltySearch(pop_size, solution_template),\n        \"MAP-Elites\": MAPElites(\n            pop_size,\n            solution_template,\n            descriptor_size=2,\n            descriptor_min=[-3.0, -3.0],\n            descriptor_max=[3.0, 3.0],\n        ),\n    }\n\n    print(\n        f\"Starting benchmark on Sphere (dim={dim}) for {num_generations} generations...\"\n    )\n\n    for name, qd in algorithms.items():\n        print(f\"\\n--- {name} ---\")\n\n        # Init Algorithm\n        qd_params = qd.default_params\n\n        # Initialize with the sampled population\n        qd_state = qd.init(\n            key_qd,\n            population=initial_population,\n            fitness=-bbob_eval.fitness,\n            descriptor=bbob_eval.descriptor,\n            params=qd_params,\n        )\n\n        # Loop\n        for gen in range(num_generations):\n            key_qd, key_ask, key_eval, key_tell = jax.random.split(key_qd, 4)\n\n            # Ask\n            population, qd_state = qd.ask(key_ask, qd_state, qd_params)\n\n            # Evaluate\n            eval_keys = jax.random.split(key_eval, pop_size)\n            bbob_state_batch, bbob_eval_gen = fitness_fn(\n                eval_keys, population, bbob_state, bbob_params\n            )\n            bbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)\n\n            # Tell\n            qd_state, metrics = qd.tell(\n                key_tell,\n                population,\n                -bbob_eval_gen.fitness,\n                bbob_eval_gen.descriptor,\n                qd_state,\n                qd_params,\n            )\n\n            if gen % 20 == 0:\n                # Aggregate metrics for display\n                agg = metrics_agg_fn(metrics)\n                print(\n                    f\"Generation {gen:03d}: \"\n                    f\"population_size={agg['population_size']:.0f}, \"\n                    f\"fitness_max={agg['fitness_max']:.4f}, \"\n                    f\"novelty_mean={agg['novelty_mean']:.4f}, \"\n                    f\"dominated_novelty_mean={agg['dominated_novelty_mean']:.4f}\"\n                )\n</pre> if __name__ == \"__main__\":     from bbobax import QDBBOB     from bbobax.descriptor_fns import get_random_projection_descriptor     from bbobax.fitness_fns import bbob_fns      # Configuration     seed = 1     pop_size = 1024     num_generations = 100     dim = 2      # Setup Task     bbob = QDBBOB(         min_num_dims=dim,         max_num_dims=dim,         fitness_fns=[bbob_fns[\"sphere\"]],         descriptor_fns=[get_random_projection_descriptor()],         descriptor_size=2,     )      key = jax.random.key(seed)     key_bbob, key_init, key_qd, key_pop = jax.random.split(key, 4)      bbob_params = bbob.sample(key_bbob)     bbob_state = bbob.init(key_init, bbob_params)      # Solution template     solution_template = jnp.zeros((dim,))      # Sample initial population from task     keys = jax.random.split(key_pop, pop_size)     initial_population = jax.vmap(bbob.sample_x)(keys)      # Evaluate initial population to get fitness/descriptor for init     fitness_fn = jax.vmap(bbob.evaluate, in_axes=(0, 0, None, None))     eval_keys = jax.random.split(key_pop, pop_size)      bbob_state_batch, bbob_eval = fitness_fn(         eval_keys, initial_population, bbob_state, bbob_params     )     bbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)      # Algorithms to test     algorithms = {         \"Random\": RandomSearch(pop_size, solution_template),         \"GA\": GeneticAlgorithm(pop_size, solution_template),         \"NoveltySearch\": NoveltySearch(pop_size, solution_template),         \"DominatedNoveltySearch\": DominatedNoveltySearch(pop_size, solution_template),         \"MAP-Elites\": MAPElites(             pop_size,             solution_template,             descriptor_size=2,             descriptor_min=[-3.0, -3.0],             descriptor_max=[3.0, 3.0],         ),     }      print(         f\"Starting benchmark on Sphere (dim={dim}) for {num_generations} generations...\"     )      for name, qd in algorithms.items():         print(f\"\\n--- {name} ---\")          # Init Algorithm         qd_params = qd.default_params          # Initialize with the sampled population         qd_state = qd.init(             key_qd,             population=initial_population,             fitness=-bbob_eval.fitness,             descriptor=bbob_eval.descriptor,             params=qd_params,         )          # Loop         for gen in range(num_generations):             key_qd, key_ask, key_eval, key_tell = jax.random.split(key_qd, 4)              # Ask             population, qd_state = qd.ask(key_ask, qd_state, qd_params)              # Evaluate             eval_keys = jax.random.split(key_eval, pop_size)             bbob_state_batch, bbob_eval_gen = fitness_fn(                 eval_keys, population, bbob_state, bbob_params             )             bbob_state = jax.tree.map(lambda x: x[0], bbob_state_batch)              # Tell             qd_state, metrics = qd.tell(                 key_tell,                 population,                 -bbob_eval_gen.fitness,                 bbob_eval_gen.descriptor,                 qd_state,                 qd_params,             )              if gen % 20 == 0:                 # Aggregate metrics for display                 agg = metrics_agg_fn(metrics)                 print(                     f\"Generation {gen:03d}: \"                     f\"population_size={agg['population_size']:.0f}, \"                     f\"fitness_max={agg['fitness_max']:.4f}, \"                     f\"novelty_mean={agg['novelty_mean']:.4f}, \"                     f\"dominated_novelty_mean={agg['dominated_novelty_mean']:.4f}\"                 )"},{"location":"reference/bbob/","title":"BBOB","text":""},{"location":"reference/bbob/#bbobax.BBOB","title":"<code>bbobax.BBOB</code>","text":"<p>Black-box Optimization Benchmarking Task class (Single Objective).</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>class BBOB:\n    \"\"\"Black-box Optimization Benchmarking Task class (Single Objective).\"\"\"\n\n    def __init__(\n        self,\n        fitness_fns: list[Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]]\n        | dict[str, Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]],\n        min_num_dims: int = 2,\n        max_num_dims: int = 10,\n        x_range: list[float] = [-5.0, 5.0],\n        x_opt_range: list[float] = [-4.0, 4.0],\n        f_opt_range: list[float] = [0.0, 0.0],\n        clip_x: bool = False,\n        sample_rotation: bool = False,\n        noise_config: dict | None = None,\n    ):\n        \"\"\"Initialize the BBOB task.\n\n        Args:\n            fitness_fns: List or dictionary of fitness functions.\n            min_num_dims: Minimum number of dimensions.\n            max_num_dims: Maximum number of dimensions.\n            x_range: Range of input variables.\n            x_opt_range: Range of optimal input variables.\n            f_opt_range: Range of optimal fitness values.\n            clip_x: Whether to clip input variables.\n            sample_rotation: Whether to sample rotation matrices.\n            noise_config: Configuration for noise models.\n\n        \"\"\"\n        if isinstance(fitness_fns, dict):\n            self.fitness_fns = list(fitness_fns.values())\n        else:\n            self.fitness_fns = fitness_fns\n\n        self.min_num_dims = min_num_dims\n        self.max_num_dims = max_num_dims\n        self.x_range = x_range\n        self.x_opt_range = x_opt_range\n        self.f_opt_range = f_opt_range\n        self.clip_x = clip_x\n        self.sample_rotation = sample_rotation\n\n        # Noise\n        if noise_config is None:\n            noise_config = {\n                \"noise_model_names\": [\n                    \"noiseless\",\n                    \"gaussian\",\n                    \"uniform\",\n                    \"cauchy\",\n                    \"additive\",\n                ],\n                \"use_stabilization\": True,\n            }\n        self.noise_model = NoiseModel(**noise_config)\n\n        self.num_fns = len(self.fitness_fns)\n\n        # Prepare vectorized fitness evaluation\n        self._vmapped_fitness_fns = [\n            jax.vmap(fn, in_axes=(0, None, None)) for fn in self.fitness_fns\n        ]\n\n    def sample(self, key: jax.Array) -&gt; BBOBParams:\n        \"\"\"Sample BBOB task parameters.\"\"\"\n        key_fn, key_d, key_x, key_f, key_noise = jax.random.split(key, 5)\n\n        fn_id = jax.random.randint(key_fn, (), minval=0, maxval=self.num_fns)\n        num_dims = jax.random.randint(\n            key_d, (), minval=self.min_num_dims, maxval=self.max_num_dims\n        )\n\n        x_opt = jax.random.uniform(\n            key_x,\n            shape=(self.max_num_dims,),\n            minval=self.x_opt_range[0],\n            maxval=self.x_opt_range[1],\n        )\n        f_opt = jax.random.uniform(\n            key_f,\n            minval=self.f_opt_range[0],\n            maxval=self.f_opt_range[1],\n        )\n\n        # Sample noise model parameters\n        noise_params = self.noise_model.sample(key_noise)\n\n        return BBOBParams(fn_id, num_dims, x_opt, f_opt, noise_params)\n\n    def init(self, key: jax.Array, params: BBOBParams) -&gt; BBOBState:\n        \"\"\"Initialize the task state.\n\n        Args:\n            key: JAX random key.\n            params: Task parameters.\n\n        Returns:\n            Initial task state.\n\n        \"\"\"\n        if self.sample_rotation:\n            key_r, key_q = jax.random.split(key)\n            r = self.generate_random_rotation(key_r, self.max_num_dims, params.num_dims)\n            q = self.generate_random_rotation(key_q, self.max_num_dims, params.num_dims)\n        else:\n            r = jnp.eye(self.max_num_dims)\n            q = jnp.eye(self.max_num_dims)\n        return BBOBState(counter=0, r=r, q=q)\n\n    def evaluate(\n        self,\n        key: jax.Array,\n        x: jax.Array,\n        state: BBOBState,\n        params: BBOBParams,\n    ) -&gt; tuple[BBOBState, BBOBEval]:\n        \"\"\"Evaluate the fitness of a solution.\n\n        Args:\n            key: JAX random key.\n            x: Input solution.\n            state: Current task state.\n            params: Task parameters.\n\n        Returns:\n            Updated state and evaluation results.\n\n        \"\"\"\n        if self.clip_x:\n            x = jnp.clip(x, self.x_range[0], self.x_range[1])\n\n        # Evaluate fitness\n        # Using switch to select the correct fitness function based on fn_id\n        fn_val, fn_pen = jax.lax.switch(\n            params.fn_id,\n            self.fitness_fns,\n            x,\n            state,\n            params,\n        )\n\n        # Apply noise\n        fn_noise = self.noise_model.apply(key, fn_val, params.noise_params)\n\n        # Add boundary handling penalty and optimal function value\n        final_fitness = fn_noise + fn_pen + params.f_opt\n\n        bbob_eval = BBOBEval(fitness=final_fitness)\n        return state.replace(counter=state.counter + 1), bbob_eval\n\n    def sample_x(self, key: jax.Array) -&gt; jax.Array:\n        \"\"\"Sample a random solution.\n\n        Args:\n            key: JAX random key.\n\n        Returns:\n            Random solution within the defined range.\n\n        \"\"\"\n        return jax.random.uniform(\n            key,\n            shape=(self.max_num_dims,),\n            minval=self.x_range[0],\n            maxval=self.x_range[1],\n        )\n\n    def generate_random_rotation(\n        self, key: jax.Array, max_dims: int, num_dims: int\n    ) -&gt; jax.Array:\n        \"\"\"Generate a random (n, n) rotation matrix uniformly sampled from SO(n).\"\"\"\n        # Generate fixed-size random normal matrix but mask based on num_dims\n        random_matrix = jax.random.normal(key, (max_dims, max_dims))\n        mask = (jnp.arange(max_dims)[:, None] &lt; num_dims) &amp; (\n            jnp.arange(max_dims)[None, :] &lt; num_dims\n        )\n        random_matrix = jnp.where(mask, random_matrix, 0.0)\n\n        # Add identity matrix for masked region to ensure valid QR decomposition\n        random_matrix = random_matrix + jnp.where(~mask, jnp.eye(max_dims), 0.0)\n\n        # QR decomposition\n        orthogonal_matrix, upper_triangular = jnp.linalg.qr(random_matrix)\n\n        # Extract diagonal and create sign correction matrix\n        diagonal = jnp.diag(upper_triangular)\n        sign_correction = jnp.diag(diagonal / jnp.abs(diagonal))\n\n        # Apply sign correction\n        rotation = orthogonal_matrix @ sign_correction\n\n        # Ensure determinant is 1 by possibly flipping first row\n        determinant = jnp.linalg.det(rotation)\n        rotation = rotation.at[0].multiply(determinant)\n\n        return rotation\n\n    @classmethod\n    def create_default(cls, **kwargs):\n        \"\"\"Create a BBOB task with all standard functions.\"\"\"\n        return cls(fitness_fns=bbob_fns, **kwargs)\n</code></pre>"},{"location":"reference/bbob/#bbobax.BBOB.__init__","title":"<code>__init__(fitness_fns, min_num_dims=2, max_num_dims=10, x_range=[-5.0, 5.0], x_opt_range=[-4.0, 4.0], f_opt_range=[0.0, 0.0], clip_x=False, sample_rotation=False, noise_config=None)</code>","text":"<p>Initialize the BBOB task.</p> <p>Parameters:</p> Name Type Description Default <code>fitness_fns</code> <code>list[Callable[[Array, BBOBState, BBOBParams], Array]] | dict[str, Callable[[Array, BBOBState, BBOBParams], Array]]</code> <p>List or dictionary of fitness functions.</p> required <code>min_num_dims</code> <code>int</code> <p>Minimum number of dimensions.</p> <code>2</code> <code>max_num_dims</code> <code>int</code> <p>Maximum number of dimensions.</p> <code>10</code> <code>x_range</code> <code>list[float]</code> <p>Range of input variables.</p> <code>[-5.0, 5.0]</code> <code>x_opt_range</code> <code>list[float]</code> <p>Range of optimal input variables.</p> <code>[-4.0, 4.0]</code> <code>f_opt_range</code> <code>list[float]</code> <p>Range of optimal fitness values.</p> <code>[0.0, 0.0]</code> <code>clip_x</code> <code>bool</code> <p>Whether to clip input variables.</p> <code>False</code> <code>sample_rotation</code> <code>bool</code> <p>Whether to sample rotation matrices.</p> <code>False</code> <code>noise_config</code> <code>dict | None</code> <p>Configuration for noise models.</p> <code>None</code> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def __init__(\n    self,\n    fitness_fns: list[Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]]\n    | dict[str, Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]],\n    min_num_dims: int = 2,\n    max_num_dims: int = 10,\n    x_range: list[float] = [-5.0, 5.0],\n    x_opt_range: list[float] = [-4.0, 4.0],\n    f_opt_range: list[float] = [0.0, 0.0],\n    clip_x: bool = False,\n    sample_rotation: bool = False,\n    noise_config: dict | None = None,\n):\n    \"\"\"Initialize the BBOB task.\n\n    Args:\n        fitness_fns: List or dictionary of fitness functions.\n        min_num_dims: Minimum number of dimensions.\n        max_num_dims: Maximum number of dimensions.\n        x_range: Range of input variables.\n        x_opt_range: Range of optimal input variables.\n        f_opt_range: Range of optimal fitness values.\n        clip_x: Whether to clip input variables.\n        sample_rotation: Whether to sample rotation matrices.\n        noise_config: Configuration for noise models.\n\n    \"\"\"\n    if isinstance(fitness_fns, dict):\n        self.fitness_fns = list(fitness_fns.values())\n    else:\n        self.fitness_fns = fitness_fns\n\n    self.min_num_dims = min_num_dims\n    self.max_num_dims = max_num_dims\n    self.x_range = x_range\n    self.x_opt_range = x_opt_range\n    self.f_opt_range = f_opt_range\n    self.clip_x = clip_x\n    self.sample_rotation = sample_rotation\n\n    # Noise\n    if noise_config is None:\n        noise_config = {\n            \"noise_model_names\": [\n                \"noiseless\",\n                \"gaussian\",\n                \"uniform\",\n                \"cauchy\",\n                \"additive\",\n            ],\n            \"use_stabilization\": True,\n        }\n    self.noise_model = NoiseModel(**noise_config)\n\n    self.num_fns = len(self.fitness_fns)\n\n    # Prepare vectorized fitness evaluation\n    self._vmapped_fitness_fns = [\n        jax.vmap(fn, in_axes=(0, None, None)) for fn in self.fitness_fns\n    ]\n</code></pre>"},{"location":"reference/bbob/#bbobax.BBOB.create_default","title":"<code>create_default(**kwargs)</code>  <code>classmethod</code>","text":"<p>Create a BBOB task with all standard functions.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>@classmethod\ndef create_default(cls, **kwargs):\n    \"\"\"Create a BBOB task with all standard functions.\"\"\"\n    return cls(fitness_fns=bbob_fns, **kwargs)\n</code></pre>"},{"location":"reference/bbob/#bbobax.BBOB.evaluate","title":"<code>evaluate(key, x, state, params)</code>","text":"<p>Evaluate the fitness of a solution.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Array</code> <p>JAX random key.</p> required <code>x</code> <code>Array</code> <p>Input solution.</p> required <code>state</code> <code>BBOBState</code> <p>Current task state.</p> required <code>params</code> <code>BBOBParams</code> <p>Task parameters.</p> required <p>Returns:</p> Type Description <code>tuple[BBOBState, BBOBEval]</code> <p>Updated state and evaluation results.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def evaluate(\n    self,\n    key: jax.Array,\n    x: jax.Array,\n    state: BBOBState,\n    params: BBOBParams,\n) -&gt; tuple[BBOBState, BBOBEval]:\n    \"\"\"Evaluate the fitness of a solution.\n\n    Args:\n        key: JAX random key.\n        x: Input solution.\n        state: Current task state.\n        params: Task parameters.\n\n    Returns:\n        Updated state and evaluation results.\n\n    \"\"\"\n    if self.clip_x:\n        x = jnp.clip(x, self.x_range[0], self.x_range[1])\n\n    # Evaluate fitness\n    # Using switch to select the correct fitness function based on fn_id\n    fn_val, fn_pen = jax.lax.switch(\n        params.fn_id,\n        self.fitness_fns,\n        x,\n        state,\n        params,\n    )\n\n    # Apply noise\n    fn_noise = self.noise_model.apply(key, fn_val, params.noise_params)\n\n    # Add boundary handling penalty and optimal function value\n    final_fitness = fn_noise + fn_pen + params.f_opt\n\n    bbob_eval = BBOBEval(fitness=final_fitness)\n    return state.replace(counter=state.counter + 1), bbob_eval\n</code></pre>"},{"location":"reference/bbob/#bbobax.BBOB.generate_random_rotation","title":"<code>generate_random_rotation(key, max_dims, num_dims)</code>","text":"<p>Generate a random (n, n) rotation matrix uniformly sampled from SO(n).</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def generate_random_rotation(\n    self, key: jax.Array, max_dims: int, num_dims: int\n) -&gt; jax.Array:\n    \"\"\"Generate a random (n, n) rotation matrix uniformly sampled from SO(n).\"\"\"\n    # Generate fixed-size random normal matrix but mask based on num_dims\n    random_matrix = jax.random.normal(key, (max_dims, max_dims))\n    mask = (jnp.arange(max_dims)[:, None] &lt; num_dims) &amp; (\n        jnp.arange(max_dims)[None, :] &lt; num_dims\n    )\n    random_matrix = jnp.where(mask, random_matrix, 0.0)\n\n    # Add identity matrix for masked region to ensure valid QR decomposition\n    random_matrix = random_matrix + jnp.where(~mask, jnp.eye(max_dims), 0.0)\n\n    # QR decomposition\n    orthogonal_matrix, upper_triangular = jnp.linalg.qr(random_matrix)\n\n    # Extract diagonal and create sign correction matrix\n    diagonal = jnp.diag(upper_triangular)\n    sign_correction = jnp.diag(diagonal / jnp.abs(diagonal))\n\n    # Apply sign correction\n    rotation = orthogonal_matrix @ sign_correction\n\n    # Ensure determinant is 1 by possibly flipping first row\n    determinant = jnp.linalg.det(rotation)\n    rotation = rotation.at[0].multiply(determinant)\n\n    return rotation\n</code></pre>"},{"location":"reference/bbob/#bbobax.BBOB.init","title":"<code>init(key, params)</code>","text":"<p>Initialize the task state.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Array</code> <p>JAX random key.</p> required <code>params</code> <code>BBOBParams</code> <p>Task parameters.</p> required <p>Returns:</p> Type Description <code>BBOBState</code> <p>Initial task state.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def init(self, key: jax.Array, params: BBOBParams) -&gt; BBOBState:\n    \"\"\"Initialize the task state.\n\n    Args:\n        key: JAX random key.\n        params: Task parameters.\n\n    Returns:\n        Initial task state.\n\n    \"\"\"\n    if self.sample_rotation:\n        key_r, key_q = jax.random.split(key)\n        r = self.generate_random_rotation(key_r, self.max_num_dims, params.num_dims)\n        q = self.generate_random_rotation(key_q, self.max_num_dims, params.num_dims)\n    else:\n        r = jnp.eye(self.max_num_dims)\n        q = jnp.eye(self.max_num_dims)\n    return BBOBState(counter=0, r=r, q=q)\n</code></pre>"},{"location":"reference/bbob/#bbobax.BBOB.sample","title":"<code>sample(key)</code>","text":"<p>Sample BBOB task parameters.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def sample(self, key: jax.Array) -&gt; BBOBParams:\n    \"\"\"Sample BBOB task parameters.\"\"\"\n    key_fn, key_d, key_x, key_f, key_noise = jax.random.split(key, 5)\n\n    fn_id = jax.random.randint(key_fn, (), minval=0, maxval=self.num_fns)\n    num_dims = jax.random.randint(\n        key_d, (), minval=self.min_num_dims, maxval=self.max_num_dims\n    )\n\n    x_opt = jax.random.uniform(\n        key_x,\n        shape=(self.max_num_dims,),\n        minval=self.x_opt_range[0],\n        maxval=self.x_opt_range[1],\n    )\n    f_opt = jax.random.uniform(\n        key_f,\n        minval=self.f_opt_range[0],\n        maxval=self.f_opt_range[1],\n    )\n\n    # Sample noise model parameters\n    noise_params = self.noise_model.sample(key_noise)\n\n    return BBOBParams(fn_id, num_dims, x_opt, f_opt, noise_params)\n</code></pre>"},{"location":"reference/bbob/#bbobax.BBOB.sample_x","title":"<code>sample_x(key)</code>","text":"<p>Sample a random solution.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Array</code> <p>JAX random key.</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Random solution within the defined range.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def sample_x(self, key: jax.Array) -&gt; jax.Array:\n    \"\"\"Sample a random solution.\n\n    Args:\n        key: JAX random key.\n\n    Returns:\n        Random solution within the defined range.\n\n    \"\"\"\n    return jax.random.uniform(\n        key,\n        shape=(self.max_num_dims,),\n        minval=self.x_range[0],\n        maxval=self.x_range[1],\n    )\n</code></pre>"},{"location":"reference/descriptor_fns/","title":"Descriptor Functions","text":""},{"location":"reference/descriptor_fns/#bbobax.descriptor_fns","title":"<code>bbobax.descriptor_fns</code>","text":"<p>Black-box Optimization Benchmarking Descriptors Definitions.</p>"},{"location":"reference/descriptor_fns/#bbobax.descriptor_fns.get_random_projection_descriptor","title":"<code>get_random_projection_descriptor()</code>","text":"<p>Return a random projection descriptor function.</p> <p>Returns:</p> Type Description <code>Callable[[Array, Any, Any], Array]</code> <p>A descriptor function that takes (x, state, params) and returns the</p> <code>Callable[[Array, Any, Any], Array]</code> <p>descriptor.</p> Source code in <code>src/bbobax/descriptor_fns.py</code> <pre><code>def get_random_projection_descriptor() -&gt; Callable[[jax.Array, Any, Any], jax.Array]:\n    \"\"\"Return a random projection descriptor function.\n\n    Returns:\n        A descriptor function that takes (x, state, params) and returns the\n        descriptor.\n\n    \"\"\"\n\n    def descriptor_fn(x: jax.Array, state: Any, params: Any) -&gt; jax.Array:\n        # x shape: (batch_size, max_num_dims)\n        # params.descriptor_params shape: (descriptor_size, max_num_dims)\n        # Output shape: (batch_size, descriptor_size)\n        return x @ params.descriptor_params.T\n\n    return descriptor_fn\n</code></pre>"},{"location":"reference/fitness_fns/","title":"Fitness Functions","text":""},{"location":"reference/fitness_fns/#bbobax.fitness_fns","title":"<code>bbobax.fitness_fns</code>","text":"<p>Black-box Optimization Benchmarking Functions Definitions.</p>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.attractive_sector","title":"<code>attractive_sector(x, state, params)</code>","text":"<p>Attractive Sector Function (Hansen et al., 2010, p. 30).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def attractive_sector(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Attractive Sector Function (Hansen et al., 2010, p. 30).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = state.r @ (x - params.x_opt)\n    z = _lambda_alpha_vector(10.0, max_num_dims, params.num_dims) * z\n    z = state.q @ z\n\n    s = jnp.where(z * params.x_opt &gt; 0.0, 100.0, 1.0)\n\n    out = jnp.sum(jnp.square(s * z) * mask)\n    return jnp.power(transform_osz(out), 0.9), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.bent_cigar","title":"<code>bent_cigar(x, state, params)</code>","text":"<p>Bent Cigar Function (Hansen et al., 2010, p. 60).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def bent_cigar(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Bent Cigar Function (Hansen et al., 2010, p. 60).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = state.r @ (x - params.x_opt)\n    z = transform_asy(z, 0.5, params.num_dims)\n    z = state.r @ z\n\n    z_squared = jnp.square(z)\n    out = z_squared.at[1:].multiply(10**6)\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.bueche_rastrigin","title":"<code>bueche_rastrigin(x, state, params)</code>","text":"<p>Bueche-Rastrigin Function (Hansen et al., 2010, p. 20).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def bueche_rastrigin(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Bueche-Rastrigin Function (Hansen et al., 2010, p. 20).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    # TODO: in \"Real-Parameter Black-Box Optimization Benchmarking 2009: Noiseless\n    # Functions Definitions\", circular definition between z and s.\n    z = transform_osz(x - params.x_opt)\n\n    exp = (\n        jnp.where(\n            params.num_dims &gt; 1,\n            0.5 * jnp.arange(max_num_dims) / (params.num_dims - 1),\n            0.5,\n        )\n        * mask\n    )\n    cond = (z &gt; 0.0) &amp; (jnp.arange(max_num_dims) % 2 == 1)\n    s = jnp.where(cond, jnp.power(10.0, exp + 1), jnp.power(10.0, exp))\n\n    z = s * z\n\n    out_1 = jnp.cos(2 * jnp.pi * z)\n    out_2 = jnp.square(z)\n\n    return 10 * (params.num_dims - jnp.sum(out_1 * mask)) + jnp.sum(\n        out_2 * mask\n    ), 100 * f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.different_powers","title":"<code>different_powers(x, state, params)</code>","text":"<p>Different Powers Function (Hansen et al., 2010, p. 70).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def different_powers(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Different Powers Function (Hansen et al., 2010, p. 70).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = state.r @ (x - params.x_opt)\n\n    exp = (\n        jnp.where(\n            params.num_dims &gt; 1,\n            2.0 + 4.0 * jnp.arange(max_num_dims) / (params.num_dims - 1),\n            6.0,\n        )\n        * mask\n    )\n    out = jnp.power(jnp.abs(z), exp)\n    return jnp.sqrt(jnp.sum(out * mask)), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.discus","title":"<code>discus(x, state, params)</code>","text":"<p>Discus Function (Hansen et al., 2010, p. 55).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def discus(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Discus Function (Hansen et al., 2010, p. 55).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = state.r @ (x - params.x_opt)\n    z = transform_osz(z)\n\n    z_squared = jnp.square(z)\n    out = z_squared.at[0].multiply(10**6)\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.ellipsoidal","title":"<code>ellipsoidal(x, state, params)</code>","text":"<p>Ellipsoidal Function (Hansen et al., 2010, p. 10).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def ellipsoidal(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Ellipsoidal Function (Hansen et al., 2010, p. 10).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = transform_osz(x - params.x_opt)\n\n    exp = (\n        jnp.where(\n            params.num_dims &gt; 1,\n            6.0 * jnp.arange(max_num_dims) / (params.num_dims - 1),\n            6.0,\n        )\n        * mask\n    )\n    out = jnp.power(10.0, exp) * jnp.square(z)\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.ellipsoidal_rotated","title":"<code>ellipsoidal_rotated(x, state, params)</code>","text":"<p>Ellipsoidal Function (Hansen et al., 2010, p. 50).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def ellipsoidal_rotated(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Ellipsoidal Function (Hansen et al., 2010, p. 50).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = state.r @ (x - params.x_opt)\n    z = transform_osz(z)\n\n    exp = (\n        jnp.where(\n            params.num_dims &gt; 1,\n            6.0 * jnp.arange(max_num_dims) / (params.num_dims - 1),\n            6.0,\n        )\n        * mask\n    )\n    out = jnp.power(10.0, exp) * jnp.square(z)\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.f_pen","title":"<code>f_pen(x, num_dims)</code>","text":"<p>Boundary penalty.</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def f_pen(x: jax.Array, num_dims: int) -&gt; jax.Array:\n    \"\"\"Boundary penalty.\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; num_dims\n\n    out = jnp.abs(x) - 5.0\n    return jnp.sum(jnp.square(jnp.maximum(0.0, out * mask)))\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.gallagher_101_me","title":"<code>gallagher_101_me(x, state, params)</code>","text":"<p>Gallagher's Gaussian 101-me Peaks Function (Hansen et al., 2010, p. 105).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def gallagher_101_me(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Gallagher's Gaussian 101-me Peaks Function (Hansen et al., 2010, p. 105).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    num_optima = 101\n    key = jax.random.key(0)\n    key = jax.random.fold_in(key, state.q[0, 0])\n\n    w = jnp.where(\n        jnp.arange(num_optima) == 0,\n        10.0,\n        1.1 + 8.0 * (jnp.arange(num_optima) - 1.0) / (num_optima - 2.0),\n    )\n\n    alpha = jnp.zeros(num_optima)\n    alpha_set = jnp.power(1000.0, 2.0 * jnp.arange(num_optima - 1) / (num_optima - 2))\n    key, subkey = jax.random.split(key)\n    alpha_permuted = jax.random.permutation(subkey, alpha_set)\n    alpha = alpha.at[0].set(1000.0)\n    alpha = alpha.at[1:].set(alpha_permuted)\n    c = jax.vmap(\n        lambda alpha: lambda_alpha(alpha, max_num_dims, params.num_dims) / alpha**0.25\n    )(alpha)\n\n    key, subkey = jax.random.split(key)\n    keys = jax.random.split(subkey, num_optima)\n\n    def permute_diag(c_i, key):\n        perm = jax.random.choice(\n            key, jnp.arange(max_num_dims), shape=(max_num_dims,), replace=False, p=mask\n        )\n        diag = jnp.diag(c_i)\n        new_diag = diag[perm]\n        return c_i.at[jnp.arange(max_num_dims), jnp.arange(max_num_dims)].set(new_diag)\n\n    c = jax.vmap(permute_diag)(c, keys)\n\n    key, subkey = jax.random.split(key)\n    y = jax.random.uniform(\n        subkey,\n        shape=(\n            num_optima,\n            max_num_dims,\n        ),\n        minval=-5.0,\n        maxval=5.0,\n    )\n    y = y.at[0].set(params.x_opt) * mask\n\n    def f(c_i, y_i, w_i):\n        out = state.r @ (x - y_i)\n        out = c_i @ out\n        out = state.r.T @ out\n        out = jnp.dot(x - y_i, out * mask)\n        return w_i * jnp.exp(-out / (2 * params.num_dims))\n\n    out = jax.vmap(f)(c, y, w)\n    return jnp.square(transform_osz(10.0 - jnp.max(out))), f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.gallagher_21_hi","title":"<code>gallagher_21_hi(x, state, params)</code>","text":"<p>Gallagher's Gaussian 21-hi Peaks Function (Hansen et al., 2010, p. 110).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def gallagher_21_hi(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Gallagher's Gaussian 21-hi Peaks Function (Hansen et al., 2010, p. 110).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    x_opt = params.x_opt * 3.92 / 4.0\n\n    num_optima = 21\n    key = jax.random.key(0)\n    key = jax.random.fold_in(key, state.q[0, 0])\n\n    w = jnp.where(\n        jnp.arange(num_optima) == 0,\n        10.0,\n        1.1 + 8.0 * (jnp.arange(num_optima) - 1.0) / (num_optima - 2.0),\n    )\n\n    alpha = jnp.zeros(num_optima)\n    alpha_set = jnp.power(1000.0, 2.0 * jnp.arange(num_optima - 1) / (num_optima - 2))\n    key, subkey = jax.random.split(key)\n    alpha_permuted = jax.random.permutation(subkey, alpha_set)\n    alpha = alpha.at[0].set(1000.0**2)\n    alpha = alpha.at[1:].set(alpha_permuted)\n    c = jax.vmap(\n        lambda alpha: lambda_alpha(alpha, max_num_dims, params.num_dims) / alpha**0.25\n    )(alpha)\n\n    key, subkey = jax.random.split(key)\n    keys = jax.random.split(subkey, num_optima)\n\n    def permute_diag(c_i, key):\n        perm = jax.random.choice(\n            key, jnp.arange(max_num_dims), shape=(max_num_dims,), replace=False, p=mask\n        )\n        diag = jnp.diag(c_i)\n        new_diag = diag[perm]\n        return c_i.at[jnp.arange(max_num_dims), jnp.arange(max_num_dims)].set(new_diag)\n\n    c = jax.vmap(permute_diag)(c, keys)\n\n    key, subkey = jax.random.split(key)\n    y = jax.random.uniform(\n        subkey,\n        shape=(\n            num_optima,\n            max_num_dims,\n        ),\n        minval=-4.9,\n        maxval=4.9,\n    )\n    y = y.at[0].set(x_opt) * mask\n\n    def f(c_i, y_i, w_i):\n        out = state.r @ (x - y_i)\n        out = c_i @ out\n        out = state.r.T @ out\n        out = jnp.dot(x - y_i, out * mask)\n        return w_i * jnp.exp(-out / (2 * params.num_dims))\n\n    out = jax.vmap(f)(c, y, w)\n    return jnp.square(transform_osz(10.0 - jnp.max(out))), f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.griewank_rosenbrock","title":"<code>griewank_rosenbrock(x, state, params)</code>","text":"<p>Composite Griewank-Rosenbrock Function F8F2 (Hansen et al., 2010, p. 95).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def griewank_rosenbrock(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Composite Griewank-Rosenbrock Function F8F2 (Hansen et al., 2010, p. 95).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims - 1) &lt; (params.num_dims - 1)\n\n    z = (\n        jnp.maximum(1.0, jnp.sqrt(params.num_dims) / 8.0)\n        * (state.r @ (x - params.x_opt))\n        + 1.0\n    )  # TODO: check if correct\n    # z = jnp.maximum(1.0, jnp.sqrt(num_dims) / 8.0) * jnp.matmul(r, x - x_opt) + 1.0\n    z_i = z[:-1]\n    z_ip1 = jnp.roll(z, -1)[:-1]\n\n    s = 100.0 * jnp.square(jnp.square(z_i) - z_ip1) + jnp.square(z_i - 1)\n    out = s / 4000.0 - jnp.cos(s)\n    return 10.0 * jnp.sum(out * mask) / (params.num_dims - 1) + 10, jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.katsuura","title":"<code>katsuura(x, state, params)</code>","text":"<p>Katsuura Function (Hansen et al., 2010, p. 115).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def katsuura(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Katsuura Function (Hansen et al., 2010, p. 115).\"\"\"\n    # NOTE: Overflow in float32 because of the terms 2**31 and 2**32 but works with\n    # higher precision\n    # float64 with jax.config.update(\"jax_enable_x64\", True)\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    # num_terms = 32 in Hansen et al., 2010, but set to 30 for numerical stability\n    num_terms = 30\n\n    z = state.r @ (x - params.x_opt)\n    z = _lambda_alpha_vector(100.0, max_num_dims, params.num_dims) * z\n    z = state.q @ z\n\n    two_pow_j = jnp.power(2.0, jnp.arange(1, num_terms + 1))\n    sum_term = jnp.sum(\n        jnp.abs(two_pow_j * z[:, None] - jnp.round(two_pow_j * z[:, None])) / two_pow_j,\n        axis=1,\n    )\n    prod = jnp.prod(1.0 + jnp.arange(1, max_num_dims + 1) * sum_term * mask)\n    return (10.0 / params.num_dims**2) * (\n        jnp.power(prod, 10.0 / params.num_dims**1.2) - 1.0\n    ), f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.lambda_alpha","title":"<code>lambda_alpha(alpha, max_num_dims, num_dims)</code>","text":"<p>Masked lambda alpha matrix.</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def lambda_alpha(alpha: float, max_num_dims: int, num_dims: int) -&gt; jax.Array:\n    \"\"\"Masked lambda alpha matrix.\"\"\"\n    return jnp.diag(_lambda_alpha_vector(alpha, max_num_dims, num_dims))\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.linear_slope","title":"<code>linear_slope(x, state, params)</code>","text":"<p>Linear Slope (Hansen et al., 2010, p. 25).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def linear_slope(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Linear Slope (Hansen et al., 2010, p. 25).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    # x_opt = 5.0 * (2 * jax.random.bernoulli(subkey, shape=(max_num_dims,)) - 1)\n    x_opt = jnp.where(params.x_opt &gt; 0.0, 5.0, -5.0)\n\n    z = jnp.where(x * x_opt &lt; 25.0, x, x_opt)\n\n    exp = (\n        jnp.where(\n            params.num_dims &gt; 1, jnp.arange(max_num_dims) / (params.num_dims - 1), 0.5\n        )\n        * mask\n    )\n    s = jnp.sign(x_opt) * jnp.power(10.0, exp)\n\n    out = 5.0 * jnp.abs(s) - s * z\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.lunacek","title":"<code>lunacek(x, state, params)</code>","text":"<p>Lunacek bi-Rastrigin Function (Hansen et al., 2010, p. 120).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def lunacek(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Lunacek bi-Rastrigin Function (Hansen et al., 2010, p. 120).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    mu_0 = 2.5\n    d = 1.0\n    s = 1.0 - 1.0 / (2.0 * jnp.sqrt(params.num_dims + 20.0) - 8.2)\n    mu_1 = -jnp.sqrt((mu_0**2 - d) / s)\n\n    x_opt = jnp.where(params.x_opt &gt; 0.0, mu_0 / 2.0, -mu_0 / 2.0)\n    x_hat = 2.0 * jnp.sign(x_opt) * x\n\n    z = state.r @ (x_hat - mu_0)\n    z = _lambda_alpha_vector(100.0, max_num_dims, params.num_dims) * z\n    z = state.q @ z\n\n    s_1 = jnp.sum(jnp.square(x_hat - mu_0) * mask)\n    s_2 = jnp.sum(jnp.square(x_hat - mu_1) * mask)\n    s_3 = jnp.sum(jnp.cos(2 * jnp.pi * z) * mask)\n    return jnp.minimum(s_1, d * params.num_dims + s * s_2) + 10.0 * (\n        params.num_dims - s_3\n    ), 10.0**4 * f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.rastrigin","title":"<code>rastrigin(x, state, params)</code>","text":"<p>Rastrigin Function (Hansen et al., 2010, p. 15).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def rastrigin(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Rastrigin Function (Hansen et al., 2010, p. 15).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = transform_asy(transform_osz(x - params.x_opt), 0.2, params.num_dims)\n    z = _lambda_alpha_vector(10.0, max_num_dims, params.num_dims) * z\n\n    out_1 = jnp.cos(2 * jnp.pi * z)\n    out_2 = jnp.square(z)\n\n    return 10 * (params.num_dims - jnp.sum(out_1 * mask)) + jnp.sum(\n        out_2 * mask\n    ), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.rastrigin_rotated","title":"<code>rastrigin_rotated(x, state, params)</code>","text":"<p>Rastrigin Function (Hansen et al., 2010, p. 75).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def rastrigin_rotated(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Rastrigin Function (Hansen et al., 2010, p. 75).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = state.r @ (x - params.x_opt)\n    z = transform_asy(transform_osz(z), 0.2, params.num_dims)\n    z = state.q @ z\n    z = _lambda_alpha_vector(10.0, max_num_dims, params.num_dims) * z\n    z = state.r @ z\n\n    out_1 = jnp.cos(2 * jnp.pi * z)\n    out_2 = jnp.square(z)\n    return 10 * (params.num_dims - jnp.sum(out_1 * mask)) + jnp.sum(\n        out_2 * mask\n    ), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.rosenbrock","title":"<code>rosenbrock(x, state, params)</code>","text":"<p>Rosenbrock Function, original (Hansen et al., 2010, p. 40).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def rosenbrock(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Rosenbrock Function, original (Hansen et al., 2010, p. 40).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims - 1) &lt; (params.num_dims - 1)\n\n    x_opt = params.x_opt * 3 / 4\n    z = jnp.maximum(1.0, jnp.sqrt(params.num_dims) / 8.0) * (x - x_opt) + 1.0\n    z_i = z[:-1]\n    z_ip1 = jnp.roll(z, -1)[:-1]\n\n    out = 100.0 * jnp.square(jnp.square(z_i) - z_ip1) + jnp.square(z_i - 1)\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.rosenbrock_rotated","title":"<code>rosenbrock_rotated(x, state, params)</code>","text":"<p>Rosenbrock Function, rotated (Hansen et al., 2010, p. 45).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def rosenbrock_rotated(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Rosenbrock Function, rotated (Hansen et al., 2010, p. 45).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims - 1) &lt; (params.num_dims - 1)\n\n    z = (\n        jnp.maximum(1.0, jnp.sqrt(params.num_dims) / 8.0)\n        * (state.r @ (x - params.x_opt))\n        + 1.0\n    )  # TODO: check if correct\n    z_i = z[:-1]\n    z_ip1 = jnp.roll(z, -1)[:-1]\n\n    out = 100.0 * jnp.square(jnp.square(z_i) - z_ip1) + jnp.square(z_i - 1)\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.schaffers_f7","title":"<code>schaffers_f7(x, state, params)</code>","text":"<p>Schaffers F7 Function (Hansen et al., 2010, p. 85).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def schaffers_f7(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Schaffers F7 Function (Hansen et al., 2010, p. 85).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims - 1) &lt; (params.num_dims - 1)\n\n    if max_num_dims == 1:\n        return jnp.array(0.0), jnp.array(0.0)\n\n    z = state.r @ (x - params.x_opt)\n    z = transform_asy(z, 0.5, params.num_dims)\n    z = state.q @ z\n    z = _lambda_alpha_vector(10.0, max_num_dims, params.num_dims) * z\n\n    z_i = z[:-1]\n    z_ip1 = jnp.roll(z, -1)[:-1]\n    s = jnp.sqrt(jnp.square(z_i) + jnp.square(z_ip1))\n\n    out = jnp.sum((jnp.sqrt(s) + jnp.sqrt(s) * jnp.sin(50 * s**0.2) ** 2) * mask)\n    return (out / (params.num_dims - 1.0)) ** 2, 10 * f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.schaffers_f7_ill_conditioned","title":"<code>schaffers_f7_ill_conditioned(x, state, params)</code>","text":"<p>Schaffers F7 Function, ill-conditioned (Hansen et al., 2010, p. 90).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def schaffers_f7_ill_conditioned(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Schaffers F7 Function, ill-conditioned (Hansen et al., 2010, p. 90).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims - 1) &lt; (params.num_dims - 1)\n\n    if max_num_dims == 1:\n        return jnp.array(0.0), jnp.array(0.0)\n\n    z = state.r @ (x - params.x_opt)\n    z = transform_asy(z, 0.5, params.num_dims)\n    z = state.q @ z\n    z = _lambda_alpha_vector(1000.0, max_num_dims, params.num_dims) * z\n\n    z_i = z[:-1]\n    z_ip1 = jnp.roll(z, -1)[:-1]\n    s = jnp.sqrt(jnp.square(z_i) + jnp.square(z_ip1))\n\n    out = jnp.sum((jnp.sqrt(s) + jnp.sqrt(s) * jnp.sin(50 * s**0.2) ** 2) * mask)\n    return (out / (params.num_dims - 1.0)) ** 2, 10 * f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.schwefel","title":"<code>schwefel(x, state, params)</code>","text":"<p>Schwefel Function (Hansen et al., 2010, p. 100).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def schwefel(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Schwefel Function (Hansen et al., 2010, p. 100).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    # x_opt = 4.2096874633 * (2 * jax.random.bernoulli(subkey,\n    # shape=(max_num_dims,)) - 1) / 2\n    bernoulli = jnp.where(params.x_opt &gt; 0.0, 1.0, -1.0)\n    x_opt = 4.2096874633 * bernoulli / 2.0\n\n    x_hat = 2.0 * bernoulli * x\n    x_hat_i = x_hat\n    x_hat_im1 = jnp.roll(x_hat, 1).at[0].set(0.0)\n    x_opt_im1 = jnp.roll(x_opt, 1).at[0].set(0.0)\n    z_hat = x_hat_i + 0.25 * (x_hat_im1 - 2 * jnp.abs(x_opt_im1))\n    z = 100 * (\n        _lambda_alpha_vector(10.0, max_num_dims, params.num_dims)\n        * (z_hat - 2 * jnp.abs(x_opt))\n        + 2 * jnp.abs(x_opt)\n    )\n\n    out = z * jnp.sin(jnp.sqrt(jnp.abs(z)))\n    return -(\n        jnp.sum(out * mask) / (100.0 * params.num_dims)\n    ) + 4.189828872724339, 100 * f_pen(z / 100, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.sharp_ridge","title":"<code>sharp_ridge(x, state, params)</code>","text":"<p>Sharp Ridge Function (Hansen et al., 2010, p. 65).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def sharp_ridge(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Sharp Ridge Function (Hansen et al., 2010, p. 65).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims - 1) &lt; (params.num_dims - 1)\n\n    z = state.r @ (x - params.x_opt)\n    z = _lambda_alpha_vector(10.0, max_num_dims, params.num_dims) * z\n    z = state.q @ z\n\n    z_squared = jnp.square(z)\n    return z_squared[0] + 100 * jnp.sqrt(jnp.sum(z_squared[1:] * mask)), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.sphere","title":"<code>sphere(x, state, params)</code>","text":"<p>Sphere Function (Hansen et al., 2010, p. 5).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def sphere(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Sphere Function (Hansen et al., 2010, p. 5).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = x - params.x_opt\n\n    out = jnp.square(z)\n    return jnp.sum(out * mask), jnp.array(0.0)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.step_ellipsoidal","title":"<code>step_ellipsoidal(x, state, params)</code>","text":"<p>Step Ellipsoidal Function (Hansen et al., 2010, p. 35).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def step_ellipsoidal(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Step Ellipsoidal Function (Hansen et al., 2010, p. 35).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z_hat = state.r @ (x - params.x_opt)\n    z_hat = _lambda_alpha_vector(10.0, max_num_dims, params.num_dims) * z_hat\n\n    z_tilde = jnp.where(\n        jnp.abs(z_hat) &gt; 0.5,\n        jnp.floor(0.5 + z_hat),\n        jnp.floor(0.5 + 10.0 * z_hat) / 10.0,\n    )\n\n    z = state.q @ z_tilde\n\n    exp = (\n        jnp.where(\n            params.num_dims &gt; 1,\n            2.0 * jnp.arange(max_num_dims) / (params.num_dims - 1.0),\n            2.0,\n        )\n        * mask\n    )\n    out = jnp.sum(100.0 * jnp.power(10.0, exp) * jnp.square(z) * mask)\n    return 0.1 * jnp.maximum(jnp.abs(z_hat[0]) / 1e4, out), f_pen(x, params.num_dims)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.transform_asy","title":"<code>transform_asy(x, beta, num_dims)</code>","text":"<p>Asymmetry transformation function.</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def transform_asy(x: jax.Array, beta: float, num_dims: int) -&gt; jax.Array:\n    \"\"\"Asymmetry transformation function.\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; num_dims\n\n    exp = (\n        1.0\n        + beta\n        * jnp.where(num_dims &gt; 1, jnp.arange(max_num_dims) / (num_dims - 1), 1.0)\n        * jnp.sqrt(x)\n        * mask\n    )\n    return jnp.where(x &gt; 0.0, jnp.power(x, exp), x)\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.transform_osz","title":"<code>transform_osz(element)</code>","text":"<p>Oscillation transformation function.</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def transform_osz(element: jax.Array) -&gt; jax.Array:\n    \"\"\"Oscillation transformation function.\"\"\"\n    # Avoid log(0) by substituting 0 with 1 (log(1) = 0), handling the 0 case\n    # explicitly with where.\n    safe_element = jnp.abs(element) + (element == 0.0)\n    x_hat = jnp.where(element == 0.0, 0.0, jnp.log(safe_element))\n\n    c_1 = jnp.where(element &gt; 0.0, 10.0, 5.5)\n    c_2 = jnp.where(element &gt; 0.0, 7.9, 3.1)\n\n    return jnp.sign(element) * jnp.exp(\n        x_hat + 0.049 * (jnp.sin(c_1 * x_hat) + jnp.sin(c_2 * x_hat))\n    )\n</code></pre>"},{"location":"reference/fitness_fns/#bbobax.fitness_fns.weierstrass","title":"<code>weierstrass(x, state, params)</code>","text":"<p>Weierstrass Function (Hansen et al., 2010, p. 80).</p> Source code in <code>src/bbobax/fitness_fns.py</code> <pre><code>def weierstrass(\n    x: jax.Array, state: BBOBState, params: BBOBParams\n) -&gt; tuple[jax.Array, jax.Array]:\n    \"\"\"Weierstrass Function (Hansen et al., 2010, p. 80).\"\"\"\n    max_num_dims = x.shape[0]\n    mask = jnp.arange(max_num_dims) &lt; params.num_dims\n\n    z = state.r @ (x - params.x_opt)\n    z = transform_osz(z)\n    z = state.q @ z\n    z = _lambda_alpha_vector(0.01, max_num_dims, params.num_dims) * z\n    z = state.r @ z\n\n    k_order = 12\n    half_pow_k = jnp.power(0.5, jnp.arange(k_order))\n    three_pow_k = jnp.power(3.0, jnp.arange(k_order))\n    f_0 = jnp.sum(half_pow_k * jnp.cos(jnp.pi * three_pow_k))\n\n    out = jnp.sum(\n        half_pow_k\n        * jnp.cos(2 * jnp.pi * three_pow_k * (z[:, None] + 0.5))\n        * mask[:, None]\n    )\n    return 10 * (out / params.num_dims - f_0) ** 3, 10 * f_pen(\n        x, params.num_dims\n    ) / params.num_dims\n</code></pre>"},{"location":"reference/noise/","title":"Noise Models","text":""},{"location":"reference/noise/#bbobax.noise","title":"<code>bbobax.noise</code>","text":"<p>Black-box Optimization Benchmarking Noise Models.</p>"},{"location":"reference/noise/#bbobax.noise.NoiseModel","title":"<code>NoiseModel</code>","text":"<p>Black-box Optimization Benchmarking Noise Models class.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>class NoiseModel:\n    \"\"\"Black-box Optimization Benchmarking Noise Models class.\"\"\"\n\n    def __init__(\n        self,\n        noise_model_names: list[str] = [\n            \"noiseless\",\n            \"gaussian\",\n            \"uniform\",\n            \"cauchy\",\n            \"additive\",\n        ],\n        noise_ranges: dict[str, tuple[float, float]] = {\n            \"gaussian_beta\": None,\n            \"uniform_alpha\": None,\n            \"uniform_beta\": None,\n            \"cauchy_alpha\": None,\n            \"cauchy_p\": None,\n            \"additive_std\": None,\n        },\n        use_stabilization: bool = False,\n    ):\n        \"\"\"Initialize the noise model.\n\n        Args:\n            noise_model_names: List of noise model names to use.\n            noise_ranges: Dictionary of noise parameter ranges.\n            use_stabilization: Whether to use noise stabilization.\n\n        \"\"\"\n        # Collect active noise models\n        self.noise_ids, self.noise_models, counter = [], [], 0\n        for noise_model_name, noise_model in all_noise_models.items():\n            if noise_model_name in noise_model_names:\n                self.noise_ids.append(counter)\n                self.noise_models.append(noise_model)\n                counter += 1\n        self.noise_ids = jnp.array(self.noise_ids)\n\n        # Default ranges for noise model parameters between moderate and severe\n        self.noise_ranges = {\n            \"gaussian_beta\": noise_ranges[\"gaussian_beta\"]\n            if noise_ranges[\"gaussian_beta\"]\n            else (0.01, 1.0),\n            \"uniform_alpha\": noise_ranges[\"uniform_alpha\"]\n            if noise_ranges[\"uniform_alpha\"]\n            else (0.005, 0.5),\n            \"uniform_beta\": noise_ranges[\"uniform_beta\"]\n            if noise_ranges[\"uniform_beta\"]\n            else (0.01, 1.0),\n            \"cauchy_alpha\": noise_ranges[\"cauchy_alpha\"]\n            if noise_ranges[\"cauchy_alpha\"]\n            else (0.01, 1.0),\n            \"cauchy_p\": noise_ranges[\"cauchy_p\"]\n            if noise_ranges[\"cauchy_p\"]\n            else (0.05, 0.2),\n            \"additive_std\": noise_ranges[\"additive_std\"]\n            if noise_ranges[\"additive_std\"]\n            else (0.0, 0.1),\n        }\n\n        # Use noise stabilization close to optimal value\n        self.use_stabilization = use_stabilization\n\n    def sample(self, key: jax.Array) -&gt; NoiseParams:\n        \"\"\"Sample a noise model and its parameter settings.\"\"\"\n        (\n            key_id,\n            key_gaussian,\n            key_uniform_1,\n            key_uniform_2,\n            key_cauchy_1,\n            key_cauchy_2,\n            key_additive,\n        ) = jax.random.split(key, 7)\n\n        noise_id = jax.random.choice(key_id, self.noise_ids)\n\n        # Sample uniformly between moderate and severe divided by 2\n        gaussian_beta = jax.random.uniform(\n            key_gaussian,\n            minval=self.noise_ranges[\"gaussian_beta\"][0],\n            maxval=self.noise_ranges[\"gaussian_beta\"][1],\n        )\n\n        uniform_alpha = jax.random.uniform(\n            key_uniform_1,\n            minval=self.noise_ranges[\"uniform_alpha\"][0],\n            maxval=self.noise_ranges[\"uniform_alpha\"][1],\n        )\n        uniform_beta = jax.random.uniform(\n            key_uniform_2,\n            minval=self.noise_ranges[\"uniform_beta\"][0],\n            maxval=self.noise_ranges[\"uniform_beta\"][1],\n        )\n\n        cauchy_alpha = jax.random.uniform(\n            key_cauchy_1,\n            minval=self.noise_ranges[\"cauchy_alpha\"][0],\n            maxval=self.noise_ranges[\"cauchy_alpha\"][1],\n        )\n        cauchy_p = jax.random.uniform(\n            key_cauchy_2,\n            minval=self.noise_ranges[\"cauchy_p\"][0],\n            maxval=self.noise_ranges[\"cauchy_p\"][1],\n        )\n\n        additive_std = jax.random.uniform(\n            key_additive,\n            minval=self.noise_ranges[\"additive_std\"][0],\n            maxval=self.noise_ranges[\"additive_std\"][1],\n        )\n\n        return NoiseParams(\n            noise_id,\n            gaussian_beta,\n            uniform_alpha,\n            uniform_beta,\n            cauchy_alpha,\n            cauchy_p,\n            additive_std,\n        )\n\n    def apply(\n        self, key: jax.Array, fn_val: jax.Array, noise_params: NoiseParams\n    ) -&gt; jax.Array:\n        \"\"\"Apply a noise model given its parameter settings.\"\"\"\n        fn_noise = jax.lax.switch(\n            noise_params.noise_id,\n            self.noise_models,\n            key,\n            fn_val,\n            noise_params,\n        )\n\n        if self.use_stabilization:\n            fn_noise = stabilize(fn_val, fn_noise)\n        return fn_noise\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.NoiseModel.__init__","title":"<code>__init__(noise_model_names=['noiseless', 'gaussian', 'uniform', 'cauchy', 'additive'], noise_ranges={'gaussian_beta': None, 'uniform_alpha': None, 'uniform_beta': None, 'cauchy_alpha': None, 'cauchy_p': None, 'additive_std': None}, use_stabilization=False)</code>","text":"<p>Initialize the noise model.</p> <p>Parameters:</p> Name Type Description Default <code>noise_model_names</code> <code>list[str]</code> <p>List of noise model names to use.</p> <code>['noiseless', 'gaussian', 'uniform', 'cauchy', 'additive']</code> <code>noise_ranges</code> <code>dict[str, tuple[float, float]]</code> <p>Dictionary of noise parameter ranges.</p> <code>{'gaussian_beta': None, 'uniform_alpha': None, 'uniform_beta': None, 'cauchy_alpha': None, 'cauchy_p': None, 'additive_std': None}</code> <code>use_stabilization</code> <code>bool</code> <p>Whether to use noise stabilization.</p> <code>False</code> Source code in <code>src/bbobax/noise.py</code> <pre><code>def __init__(\n    self,\n    noise_model_names: list[str] = [\n        \"noiseless\",\n        \"gaussian\",\n        \"uniform\",\n        \"cauchy\",\n        \"additive\",\n    ],\n    noise_ranges: dict[str, tuple[float, float]] = {\n        \"gaussian_beta\": None,\n        \"uniform_alpha\": None,\n        \"uniform_beta\": None,\n        \"cauchy_alpha\": None,\n        \"cauchy_p\": None,\n        \"additive_std\": None,\n    },\n    use_stabilization: bool = False,\n):\n    \"\"\"Initialize the noise model.\n\n    Args:\n        noise_model_names: List of noise model names to use.\n        noise_ranges: Dictionary of noise parameter ranges.\n        use_stabilization: Whether to use noise stabilization.\n\n    \"\"\"\n    # Collect active noise models\n    self.noise_ids, self.noise_models, counter = [], [], 0\n    for noise_model_name, noise_model in all_noise_models.items():\n        if noise_model_name in noise_model_names:\n            self.noise_ids.append(counter)\n            self.noise_models.append(noise_model)\n            counter += 1\n    self.noise_ids = jnp.array(self.noise_ids)\n\n    # Default ranges for noise model parameters between moderate and severe\n    self.noise_ranges = {\n        \"gaussian_beta\": noise_ranges[\"gaussian_beta\"]\n        if noise_ranges[\"gaussian_beta\"]\n        else (0.01, 1.0),\n        \"uniform_alpha\": noise_ranges[\"uniform_alpha\"]\n        if noise_ranges[\"uniform_alpha\"]\n        else (0.005, 0.5),\n        \"uniform_beta\": noise_ranges[\"uniform_beta\"]\n        if noise_ranges[\"uniform_beta\"]\n        else (0.01, 1.0),\n        \"cauchy_alpha\": noise_ranges[\"cauchy_alpha\"]\n        if noise_ranges[\"cauchy_alpha\"]\n        else (0.01, 1.0),\n        \"cauchy_p\": noise_ranges[\"cauchy_p\"]\n        if noise_ranges[\"cauchy_p\"]\n        else (0.05, 0.2),\n        \"additive_std\": noise_ranges[\"additive_std\"]\n        if noise_ranges[\"additive_std\"]\n        else (0.0, 0.1),\n    }\n\n    # Use noise stabilization close to optimal value\n    self.use_stabilization = use_stabilization\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.NoiseModel.apply","title":"<code>apply(key, fn_val, noise_params)</code>","text":"<p>Apply a noise model given its parameter settings.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def apply(\n    self, key: jax.Array, fn_val: jax.Array, noise_params: NoiseParams\n) -&gt; jax.Array:\n    \"\"\"Apply a noise model given its parameter settings.\"\"\"\n    fn_noise = jax.lax.switch(\n        noise_params.noise_id,\n        self.noise_models,\n        key,\n        fn_val,\n        noise_params,\n    )\n\n    if self.use_stabilization:\n        fn_noise = stabilize(fn_val, fn_noise)\n    return fn_noise\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.NoiseModel.sample","title":"<code>sample(key)</code>","text":"<p>Sample a noise model and its parameter settings.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def sample(self, key: jax.Array) -&gt; NoiseParams:\n    \"\"\"Sample a noise model and its parameter settings.\"\"\"\n    (\n        key_id,\n        key_gaussian,\n        key_uniform_1,\n        key_uniform_2,\n        key_cauchy_1,\n        key_cauchy_2,\n        key_additive,\n    ) = jax.random.split(key, 7)\n\n    noise_id = jax.random.choice(key_id, self.noise_ids)\n\n    # Sample uniformly between moderate and severe divided by 2\n    gaussian_beta = jax.random.uniform(\n        key_gaussian,\n        minval=self.noise_ranges[\"gaussian_beta\"][0],\n        maxval=self.noise_ranges[\"gaussian_beta\"][1],\n    )\n\n    uniform_alpha = jax.random.uniform(\n        key_uniform_1,\n        minval=self.noise_ranges[\"uniform_alpha\"][0],\n        maxval=self.noise_ranges[\"uniform_alpha\"][1],\n    )\n    uniform_beta = jax.random.uniform(\n        key_uniform_2,\n        minval=self.noise_ranges[\"uniform_beta\"][0],\n        maxval=self.noise_ranges[\"uniform_beta\"][1],\n    )\n\n    cauchy_alpha = jax.random.uniform(\n        key_cauchy_1,\n        minval=self.noise_ranges[\"cauchy_alpha\"][0],\n        maxval=self.noise_ranges[\"cauchy_alpha\"][1],\n    )\n    cauchy_p = jax.random.uniform(\n        key_cauchy_2,\n        minval=self.noise_ranges[\"cauchy_p\"][0],\n        maxval=self.noise_ranges[\"cauchy_p\"][1],\n    )\n\n    additive_std = jax.random.uniform(\n        key_additive,\n        minval=self.noise_ranges[\"additive_std\"][0],\n        maxval=self.noise_ranges[\"additive_std\"][1],\n    )\n\n    return NoiseParams(\n        noise_id,\n        gaussian_beta,\n        uniform_alpha,\n        uniform_beta,\n        cauchy_alpha,\n        cauchy_p,\n        additive_std,\n    )\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.NoiseParams","title":"<code>NoiseParams</code>","text":"<p>Noise parameters.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>@dataclass\nclass NoiseParams:\n    \"\"\"Noise parameters.\"\"\"\n\n    noise_id: jax.Array\n    gaussian_beta: jax.Array\n    uniform_alpha: jax.Array\n    uniform_beta: jax.Array\n    cauchy_alpha: jax.Array\n    cauchy_p: jax.Array\n    additive_std: jax.Array\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.additive_noise","title":"<code>additive_noise(key, fn_val, noise_params)</code>","text":"<p>Apply additive noisification.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def additive_noise(\n    key: jax.Array, fn_val: jax.Array, noise_params: NoiseParams\n) -&gt; jax.Array:\n    \"\"\"Apply additive noisification.\"\"\"\n    # Moderate noise: std = 0.01\n    # Severe noise: std = 1\n    return fn_val + noise_params.additive_std * jax.random.normal(\n        key, shape=fn_val.shape\n    )\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.cauchy_noise","title":"<code>cauchy_noise(key, fn_val, noise_params)</code>","text":"<p>Apply Cauchy noise.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def cauchy_noise(\n    key: jax.Array, fn_val: jax.Array, noise_params: NoiseParams\n) -&gt; jax.Array:\n    \"\"\"Apply Cauchy noise.\"\"\"\n    # Moderate noise: alpha = 0.01, p = 0.05\n    # Severe noise: alpha = 1, p = 0.2\n    key_1, key_2, key_3 = jax.random.split(key, 3)\n    indicator = jax.random.uniform(key_1, shape=fn_val.shape) &lt; noise_params.cauchy_p\n    cauchy = jax.random.normal(key_2, shape=fn_val.shape) / (\n        jnp.abs(jax.random.uniform(key_3, shape=fn_val.shape)) + 1e-8\n    )\n    return fn_val + noise_params.cauchy_alpha * jnp.maximum(\n        0.0, 1000.0 + indicator * cauchy\n    )\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.gaussian_noise","title":"<code>gaussian_noise(key, fn_val, noise_params)</code>","text":"<p>Apply Gaussian noise.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def gaussian_noise(\n    key: jax.Array, fn_val: jax.Array, noise_params: NoiseParams\n) -&gt; jax.Array:\n    \"\"\"Apply Gaussian noise.\"\"\"\n    # Moderate noise: beta = 0.01\n    # Severe noise: beta = 1\n    return fn_val * jnp.exp(\n        noise_params.gaussian_beta * jax.random.normal(key, shape=fn_val.shape)\n    )\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.noiseless_noise","title":"<code>noiseless_noise(key, fn_val, noise_params)</code>","text":"<p>Apply noiseless noise.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def noiseless_noise(\n    key: jax.Array, fn_val: jax.Array, noise_params: NoiseParams\n) -&gt; jax.Array:\n    \"\"\"Apply noiseless noise.\"\"\"\n    return fn_val\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.stabilize","title":"<code>stabilize(fn_val, fn_noise, target_value=1e-08)</code>","text":"<p>Stabilize final function value.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def stabilize(\n    fn_val: jax.Array, fn_noise: jax.Array, target_value: float = 1e-08\n) -&gt; jax.Array:\n    \"\"\"Stabilize final function value.\"\"\"\n    # Return undisturbed function value if f is smaller than target value\n    return (fn_noise + 1.01 * target_value) * (fn_val &gt;= target_value) + fn_val * (\n        fn_val &lt; target_value\n    )\n</code></pre>"},{"location":"reference/noise/#bbobax.noise.uniform_noise","title":"<code>uniform_noise(key, fn_val, noise_params)</code>","text":"<p>Apply uniform noise.</p> Source code in <code>src/bbobax/noise.py</code> <pre><code>def uniform_noise(\n    key: jax.Array, fn_val: jax.Array, noise_params: NoiseParams\n) -&gt; jax.Array:\n    \"\"\"Apply uniform noise.\"\"\"\n    # Moderate noise: alpha = 0.01 * (0.49 + 1/D), beta = 0.01\n    # Severe noise: alpha = 0.49 + 1/D, beta = 1.0\n    key_1, key_2 = jax.random.split(key)\n    f_1 = jnp.power(\n        jax.random.uniform(key_1, shape=fn_val.shape), noise_params.uniform_beta\n    )\n    f_2 = jnp.power(\n        1e9 / (fn_val + 1e-8),\n        noise_params.uniform_alpha * jax.random.uniform(key_2, shape=fn_val.shape),\n    )\n    return fn_val * f_1 * jnp.maximum(1.0, f_2)\n</code></pre>"},{"location":"reference/qdbbob/","title":"QDBBOB","text":""},{"location":"reference/qdbbob/#bbobax.QDBBOB","title":"<code>bbobax.QDBBOB</code>","text":"<p>               Bases: <code>BBOB</code></p> <p>Quality-Diversity Black-box Optimization Benchmarking Task class.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>class QDBBOB(BBOB):\n    \"\"\"Quality-Diversity Black-box Optimization Benchmarking Task class.\"\"\"\n\n    def __init__(\n        self,\n        descriptor_fns: list[Callable[[jax.Array, BBOBState, QDBBOBParams], jax.Array]]\n        | dict[str, Callable[[jax.Array, BBOBState, QDBBOBParams], jax.Array]],\n        fitness_fns: list[Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]]\n        | dict[str, Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]],\n        descriptor_size: int = 2,\n        **kwargs,\n    ):\n        \"\"\"Initialize the QD-BBOB task.\n\n        Args:\n            descriptor_fns: List or dictionary of descriptor functions.\n            fitness_fns: List or dictionary of fitness functions.\n            descriptor_size: Size of the descriptor vector.\n            **kwargs: Additional arguments for BBOB.\n\n        \"\"\"\n        super().__init__(fitness_fns=fitness_fns, **kwargs)\n\n        if isinstance(descriptor_fns, dict):\n            self.descriptor_fns = list(descriptor_fns.values())\n        else:\n            self.descriptor_fns = descriptor_fns\n\n        self.descriptor_size = descriptor_size\n\n        # Vectorize descriptors\n        self._vmapped_descriptor_fns = [\n            jax.vmap(fn, in_axes=(0, None, None)) for fn in self.descriptor_fns\n        ]\n\n        self.num_descriptors = len(self.descriptor_fns)\n\n    def sample(self, key: jax.Array) -&gt; QDBBOBParams:\n        \"\"\"Sample BBOB task parameters including descriptor params.\"\"\"\n        key_base, key_desc_id, key_desc_params = jax.random.split(key, 3)\n\n        base_params = super().sample(key_base)\n\n        desc_id = jax.random.randint(\n            key_desc_id, (), minval=0, maxval=self.num_descriptors\n        )\n\n        # Descriptor params\n        descriptor_params = self.gaussian_random_projection(\n            key_desc_params, base_params.num_dims\n        )\n\n        return QDBBOBParams(\n            fn_id=base_params.fn_id,\n            num_dims=base_params.num_dims,\n            x_opt=base_params.x_opt,\n            f_opt=base_params.f_opt,\n            noise_params=base_params.noise_params,\n            descriptor_params=descriptor_params,\n            descriptor_id=desc_id,\n        )\n\n    def evaluate(\n        self,\n        key: jax.Array,\n        x: jax.Array,\n        state: BBOBState,\n        params: QDBBOBParams,\n    ) -&gt; tuple[BBOBState, QDBBOBEval]:\n        \"\"\"Evaluate the fitness and descriptor of a solution.\n\n        Args:\n            key: JAX random key.\n            x: Input solution.\n            state: Current task state.\n            params: Task parameters.\n\n        Returns:\n            Updated state and evaluation results.\n\n        \"\"\"\n        state, bbob_eval = super().evaluate(key, x, state, params)\n\n        descriptor = jax.lax.switch(\n            params.descriptor_id, self.descriptor_fns, x, state, params\n        )\n\n        bbob_eval = QDBBOBEval(fitness=bbob_eval.fitness, descriptor=descriptor)\n        return state, bbob_eval\n\n    def gaussian_random_projection(self, key: jax.Array, num_dims: int) -&gt; jax.Array:\n        \"\"\"Generate a random Gaussian projection matrix.\n\n        Args:\n            key: JAX random key.\n            num_dims: Number of dimensions.\n\n        Returns:\n            Random projection matrix.\n\n        \"\"\"\n        descriptor_params = jax.random.normal(\n            key,\n            shape=(self.descriptor_size, self.max_num_dims),\n        ) / jnp.sqrt(self.descriptor_size)\n        mask = jnp.arange(self.max_num_dims) &lt; num_dims\n        descriptor_params = jnp.where(mask, descriptor_params, 0)\n        return descriptor_params\n</code></pre>"},{"location":"reference/qdbbob/#bbobax.QDBBOB.__init__","title":"<code>__init__(descriptor_fns, fitness_fns, descriptor_size=2, **kwargs)</code>","text":"<p>Initialize the QD-BBOB task.</p> <p>Parameters:</p> Name Type Description Default <code>descriptor_fns</code> <code>list[Callable[[Array, BBOBState, QDBBOBParams], Array]] | dict[str, Callable[[Array, BBOBState, QDBBOBParams], Array]]</code> <p>List or dictionary of descriptor functions.</p> required <code>fitness_fns</code> <code>list[Callable[[Array, BBOBState, BBOBParams], Array]] | dict[str, Callable[[Array, BBOBState, BBOBParams], Array]]</code> <p>List or dictionary of fitness functions.</p> required <code>descriptor_size</code> <code>int</code> <p>Size of the descriptor vector.</p> <code>2</code> <code>**kwargs</code> <p>Additional arguments for BBOB.</p> <code>{}</code> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def __init__(\n    self,\n    descriptor_fns: list[Callable[[jax.Array, BBOBState, QDBBOBParams], jax.Array]]\n    | dict[str, Callable[[jax.Array, BBOBState, QDBBOBParams], jax.Array]],\n    fitness_fns: list[Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]]\n    | dict[str, Callable[[jax.Array, BBOBState, BBOBParams], jax.Array]],\n    descriptor_size: int = 2,\n    **kwargs,\n):\n    \"\"\"Initialize the QD-BBOB task.\n\n    Args:\n        descriptor_fns: List or dictionary of descriptor functions.\n        fitness_fns: List or dictionary of fitness functions.\n        descriptor_size: Size of the descriptor vector.\n        **kwargs: Additional arguments for BBOB.\n\n    \"\"\"\n    super().__init__(fitness_fns=fitness_fns, **kwargs)\n\n    if isinstance(descriptor_fns, dict):\n        self.descriptor_fns = list(descriptor_fns.values())\n    else:\n        self.descriptor_fns = descriptor_fns\n\n    self.descriptor_size = descriptor_size\n\n    # Vectorize descriptors\n    self._vmapped_descriptor_fns = [\n        jax.vmap(fn, in_axes=(0, None, None)) for fn in self.descriptor_fns\n    ]\n\n    self.num_descriptors = len(self.descriptor_fns)\n</code></pre>"},{"location":"reference/qdbbob/#bbobax.QDBBOB.evaluate","title":"<code>evaluate(key, x, state, params)</code>","text":"<p>Evaluate the fitness and descriptor of a solution.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Array</code> <p>JAX random key.</p> required <code>x</code> <code>Array</code> <p>Input solution.</p> required <code>state</code> <code>BBOBState</code> <p>Current task state.</p> required <code>params</code> <code>QDBBOBParams</code> <p>Task parameters.</p> required <p>Returns:</p> Type Description <code>tuple[BBOBState, QDBBOBEval]</code> <p>Updated state and evaluation results.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def evaluate(\n    self,\n    key: jax.Array,\n    x: jax.Array,\n    state: BBOBState,\n    params: QDBBOBParams,\n) -&gt; tuple[BBOBState, QDBBOBEval]:\n    \"\"\"Evaluate the fitness and descriptor of a solution.\n\n    Args:\n        key: JAX random key.\n        x: Input solution.\n        state: Current task state.\n        params: Task parameters.\n\n    Returns:\n        Updated state and evaluation results.\n\n    \"\"\"\n    state, bbob_eval = super().evaluate(key, x, state, params)\n\n    descriptor = jax.lax.switch(\n        params.descriptor_id, self.descriptor_fns, x, state, params\n    )\n\n    bbob_eval = QDBBOBEval(fitness=bbob_eval.fitness, descriptor=descriptor)\n    return state, bbob_eval\n</code></pre>"},{"location":"reference/qdbbob/#bbobax.QDBBOB.gaussian_random_projection","title":"<code>gaussian_random_projection(key, num_dims)</code>","text":"<p>Generate a random Gaussian projection matrix.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Array</code> <p>JAX random key.</p> required <code>num_dims</code> <code>int</code> <p>Number of dimensions.</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Random projection matrix.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def gaussian_random_projection(self, key: jax.Array, num_dims: int) -&gt; jax.Array:\n    \"\"\"Generate a random Gaussian projection matrix.\n\n    Args:\n        key: JAX random key.\n        num_dims: Number of dimensions.\n\n    Returns:\n        Random projection matrix.\n\n    \"\"\"\n    descriptor_params = jax.random.normal(\n        key,\n        shape=(self.descriptor_size, self.max_num_dims),\n    ) / jnp.sqrt(self.descriptor_size)\n    mask = jnp.arange(self.max_num_dims) &lt; num_dims\n    descriptor_params = jnp.where(mask, descriptor_params, 0)\n    return descriptor_params\n</code></pre>"},{"location":"reference/qdbbob/#bbobax.QDBBOB.sample","title":"<code>sample(key)</code>","text":"<p>Sample BBOB task parameters including descriptor params.</p> Source code in <code>src/bbobax/bbob.py</code> <pre><code>def sample(self, key: jax.Array) -&gt; QDBBOBParams:\n    \"\"\"Sample BBOB task parameters including descriptor params.\"\"\"\n    key_base, key_desc_id, key_desc_params = jax.random.split(key, 3)\n\n    base_params = super().sample(key_base)\n\n    desc_id = jax.random.randint(\n        key_desc_id, (), minval=0, maxval=self.num_descriptors\n    )\n\n    # Descriptor params\n    descriptor_params = self.gaussian_random_projection(\n        key_desc_params, base_params.num_dims\n    )\n\n    return QDBBOBParams(\n        fn_id=base_params.fn_id,\n        num_dims=base_params.num_dims,\n        x_opt=base_params.x_opt,\n        f_opt=base_params.f_opt,\n        noise_params=base_params.noise_params,\n        descriptor_params=descriptor_params,\n        descriptor_id=desc_id,\n    )\n</code></pre>"},{"location":"reference/types/","title":"Types","text":""},{"location":"reference/types/#bbobax.types","title":"<code>bbobax.types</code>","text":"<p>Black-box Optimization Benchmarking Types.</p>"},{"location":"reference/types/#bbobax.types.BBOBEval","title":"<code>BBOBEval</code>","text":"<p>BBOB evaluation results.</p> Source code in <code>src/bbobax/types.py</code> <pre><code>@dataclass\nclass BBOBEval:\n    \"\"\"BBOB evaluation results.\"\"\"\n\n    fitness: jax.Array\n</code></pre>"},{"location":"reference/types/#bbobax.types.BBOBParams","title":"<code>BBOBParams</code>","text":"<p>BBOB task parameters.</p> Source code in <code>src/bbobax/types.py</code> <pre><code>@dataclass\nclass BBOBParams:\n    \"\"\"BBOB task parameters.\"\"\"\n\n    fn_id: jax.Array\n    num_dims: jax.Array\n    x_opt: jax.Array\n    f_opt: jax.Array\n    noise_params: NoiseParams\n</code></pre>"},{"location":"reference/types/#bbobax.types.BBOBState","title":"<code>BBOBState</code>","text":"<p>BBOB task state.</p> Source code in <code>src/bbobax/types.py</code> <pre><code>@dataclass\nclass BBOBState:\n    \"\"\"BBOB task state.\"\"\"\n\n    r: jax.Array\n    q: jax.Array\n    counter: int = 0\n</code></pre>"},{"location":"reference/types/#bbobax.types.QDBBOBEval","title":"<code>QDBBOBEval</code>","text":"<p>               Bases: <code>BBOBEval</code></p> <p>QD-BBOB evaluation results.</p> Source code in <code>src/bbobax/types.py</code> <pre><code>@dataclass\nclass QDBBOBEval(BBOBEval):\n    \"\"\"QD-BBOB evaluation results.\"\"\"\n\n    descriptor: jax.Array\n</code></pre>"},{"location":"reference/types/#bbobax.types.QDBBOBParams","title":"<code>QDBBOBParams</code>","text":"<p>               Bases: <code>BBOBParams</code></p> <p>QD-BBOB task parameters.</p> Source code in <code>src/bbobax/types.py</code> <pre><code>@dataclass\nclass QDBBOBParams(BBOBParams):\n    \"\"\"QD-BBOB task parameters.\"\"\"\n\n    descriptor_params: jax.Array\n    descriptor_id: jax.Array\n</code></pre>"}]}